<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Wendi's Blog]]></title>
  <link href="http://blog.ifyouseewendy.com/atom.xml" rel="self"/>
  <link href="http://blog.ifyouseewendy.com/"/>
  <updated>2016-05-29T00:39:28+08:00</updated>
  <id>http://blog.ifyouseewendy.com/</id>
  <author>
    <name><![CDATA[wendi]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Name Driven Development]]></title>
    <link href="http://blog.ifyouseewendy.com/blog/2016/05/26/name-driven-development/"/>
    <updated>2016-05-26T18:53:08+08:00</updated>
    <id>http://blog.ifyouseewendy.com/blog/2016/05/26/name-driven-development</id>
    <content type="html"><![CDATA[<blockquote>
  <p>‚ÄúAny fool can write code that a computer can understand. Good programmers write code that humans can understand.‚Äù - Martin Fowler</p>
</blockquote>

<blockquote>
  <p>‚ÄúThere are only two hard things in Computer Science: cache invalidation and naming things.‚Äù ‚Äî Phil Karlton</p>
</blockquote>

<p>‚ÄúName Driven Development‚Äù, this is a ghost topic you can‚Äôt find on wiki. I just use it to remind me how much importance a good name can give. Maybe it‚Äôs just another bad nameüòÇ.</p>

<p>In a nutshell, why naming matters a lot is that it‚Äôs so closely related to refactoring. Here are some basic ideas I conclude</p>

<ul>
  <li>Good name reveals intention, shows legibility, and keeps clarity.</li>
  <li>Keep refactoring, until the name reveals the intention in an easy way.</li>
  <li>Don‚Äôt bother about naming too much when developing. Let the test and implementation help reveal it‚Äôs purpose. Then make a good name.</li>
</ul>

<p>To tackle this non-existing topic, I‚Äôve googled around, reading and thinking. Here are some notes I made (to be updated).</p>

<hr />

<blockquote>
  <p><a href="https://ilinkuo.wordpress.com/2013/05/07/whats-in-a-name/#more-137">What‚Äôs in a Name? - ilinkuo</a></p>
</blockquote>

<p>Your Names Tell a Story about Your Design</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/name-drive-development/your_names_tell_a_story_about_your_design.png" alt="your_names_tell_a_story_about_your_design" /></p>

<blockquote>
  <p><a href="http://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882">Clean Code: Chapter 2, ‚ÄúMeaningful Names‚Äù - Uncle Bob</a></p>

  <p>The ‚Äúdefinitive‚Äù guide</p>
</blockquote>

<p><em>Good</em></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/name-drive-development/meaningful_names_basic.png" alt="meaningful_names_basic" /></p>

<p><em>Better</em></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/name-drive-development/meaningful_names_advanced.png" alt="meaningful_names_advanced" /></p>

<blockquote>
  <p><a href="http://arlobelshee.com/good-naming-is-a-process-not-a-single-step/">Good naming is a process, not a single step - Arlo Belshee</a></p>

  <p>This serial posts provide a methodology, which explains the naming process in a clear and specific way. The first four steps aim at how to better name considering implementation, then move to thinking of intent, and domain abstraction.</p>
</blockquote>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/name-drive-development/good_naming_is_a_process.png" alt="good_naming_is_a_process" /></p>

<h3 id="summary">Summary</h3>

<ul>
  <li>Missing</li>
  <li>Nonsense</li>
  <li>Honest</li>
  <li>Honest and Complete</li>
  <li>Does the Right Thing</li>
  <li>Intent</li>
  <li>Domain Abstraction</li>
</ul>

<h3 id="why">Why</h3>

<p>The answer to that question lies at the heart of understanding, preventing, and paying off technical debt.</p>

<ul>
  <li>Indebted code is any code that is hard to scan.</li>
  <li>Technical debt is anything that increases the difficulty of reading code.</li>
</ul>

<p><em>Shouldn‚Äôt the definition of technical debt be something about the cost and risk of changing code?</em></p>

<p>It turns out that the largest single thing developers <strong>spend time doing is reading code</strong>. More than design, more than writing code, more than scanning, even more than meetings (well, probably).</p>

<p><strong>Bugs come from incomplete understanding</strong>. Incomplete understanding arises when the system is harder to understand than we can store in our heads at once.</p>

<p>So if our definition of technical debt is code that is difficult, expensive, or risky to change, then the root cause of that is code that is hard to scan. And how do we make code easy to scan? Use good names to encapsulate details.</p>

<h3 id="how">How</h3>

<p>If we want to make code more scannable, we need to increase the percentage of relevant information that it screams at you. Which also means hiding the irrelevant information.</p>

<p>The process of reducing debt is simple:</p>

<ul>
  <li>Look at something.</li>
  <li>Have an insight.</li>
  <li>Write it down.
    <ul>
      <li>Ccomment. But <strong>comments</strong> aren‚Äôt actually part of the code. They duplicate the code, which causes all the usual duplication problems.</li>
      <li>If your insight is structural then it belongs in a <strong>name</strong>. If it is a runtime insight then use an <strong>assertion</strong>.</li>
      <li>Assertions need to be easy to find. So don‚Äôt litter them around your core code. Express your insight as an example and write it down in a test. And name the test about the insight (not about what code it happens to execute).</li>
      <li>So, insights belong in names.</li>
    </ul>
  </li>
  <li>Check it in.
    <ul>
      <li>Express your intent by naming your commit using a message.</li>
    </ul>
  </li>
</ul>

<p>The insight loop is all there is</p>

<ul>
  <li>Refactoring legacy code is running this loop and writing stuff down in names.</li>
  <li>Understanding legacy code is running this loop and writing stuff down as examples in tests.</li>
  <li>TDD is running this loop three times:
    <ul>
      <li>First a loop where we look at the customer interview and we write it down as one example in a test.</li>
      <li>Second a loop where we look at the test and we write it down in names in the code.</li>
      <li>Third a loop of refactoring the (new) legacy code.</li>
    </ul>
  </li>
  <li>Design is a loop where the place you look is ‚Äúhow hard was it to write this test‚Äù and you write down insights by changing names (usually fixing the Does the Right Thing step).</li>
</ul>

<h3 id="steps">Steps</h3>

<p>Each transition is about refactoring.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/name-drive-development/good_naming_is_a_process_table.png" alt="good_naming_is_a_process_table" /></p>

<blockquote>
  <p><a href="https://stackoverflow.com/posts/422093/revisions">krosenvold</a> answer on <a href="https://stackoverflow.com/questions/421965/anyone-else-find-naming-classes-and-methods-one-of-the-most-difficult-part-in-pr/423140#423140">Stack Overflow - Anyone else find naming classes and methods one of the most difficult part in programming?</a></p>
</blockquote>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class=""><span class="line">function programming_job(){
</span><span class="line">    while (i make classes){
</span><span class="line">         Give each class a name quickly; always fairly long and descriptive.
</span><span class="line">         Implement and test each class to see what they really are.
</span><span class="line">         while (not satisfied){
</span><span class="line">            Re-visit each class and make small adjustments
</span><span class="line">         }
</span><span class="line">    }
</span><span class="line">}</span></code></pre></td></tr></table></div></figure></notextile></div>

<blockquote>
  <p><a href="http://programmers.stackexchange.com/users/31260/gnat">gnat</a> answered on <a href="http://programmers.stackexchange.com/questions/129961/are-there-good-techniques-or-tests-for-naming-types">Stack Exchange - Are there good techniques or tests for naming types?</a></p>
</blockquote>

<p>For naming, there are six techniques that were proven to work for me:</p>

<ul>
  <li>spend a lot of time on inventing names</li>
  <li>use code reviews</li>
  <li>don‚Äôt hesitate to rename</li>
  <li>spend a lot of time on inventing names</li>
  <li>use code reviews</li>
  <li>don‚Äôt hesitate to rename</li>
</ul>

<blockquote>
  <p><a href="http://www.gameproducer.net/2008/11/11/the-7-worst-verbs-programmers-use-in-function-calls/">The 7 Worst Verbs Programmers Use In Function Calls - Juuso Hietalahti</a></p>
</blockquote>

<ul>
  <li>dispatch</li>
  <li>do</li>
  <li>resolve</li>
  <li>handle</li>
  <li>manage</li>
  <li>perform</li>
  <li>populate</li>
</ul>

<blockquote>
  <p><a href="http://objology.blogspot.com/2011/09/one-of-best-bits-of-programming-advice.html">One of the Best Bits of Programming Advice I ever Got</a></p>
</blockquote>

<p>Don‚Äôt make objects that end with ‚Äòer‚Äô.</p>

<ul>
  <li>Managers - Every time I see one of these, I cringe. People will usually tell me what it does, long before they can tell me what it is. Is it a registry? Fine call it a registry. Is it a history or a log? Call it that. Is it a factory? Call it that.</li>
  <li>Controllers - Only good controller object I‚Äôve made in the last 20 years was an interface to a BallastVoltageController that represented a real world object. The fact that every single MVC implementation in the world has had a different role for Controller ought to tell us something about how well that idea fit.</li>
  <li>Organizer (and many like them) - Focus is on what it does. This is a great example of how easy it is to turn many of these ‚Äòers‚Äô into nouns. Call it an Organization. Now we‚Äôre focusing on what it is.</li>
  <li>Analyzer/Renderer/etc - Definitely examples of ‚Äúworker‚Äù objects. What if they had been Analysis/Rendering/etc.</li>
  <li>Builder/Loader/Reader/Writer/etc - Remove the focus from the objects being manipulated, and tend assume to much responsibility themselves.</li>
</ul>

<blockquote>
  <p><a href="http://www.carlopescio.com/2011/04/your-coding-conventions-are-hurting-you.html">Your coding conventions are hurting you - Carlo Pescio</a></p>

  <p>Great article explaining four harmful conventions with obvious examples. There is a following post, <a href="http://www.carlopescio.com/2012/03/life-without-controller-case-1.html">Life without a controller</a></p>
</blockquote>

<p>From a distance, everything is object oriented, extra-cool, modern-flexible-etc, but as you get closer, you realize it‚Äôs just a thin veneer over procedural thinking (and don‚Äôt even get me started about being ‚Äúmodern‚Äù).</p>

<p>Fake OO names and harmful conventions</p>

<ul>
  <li>the -er suffix</li>
  <li>the -able suffix</li>
  <li>the -Object suffix</li>
  <li>the I- prefix</li>
</ul>

<p><strong>Manager, Helper, Handler‚Ä¶</strong></p>

<p>Good ol‚Äô Peter Coad used to say: Challenge any class name that ends in ‚Äú-er‚Äù (e.g. Manager or Controller). If it has no parts, change the name of the class to what each object is managing. If it has parts, put as much work in the parts that the parts know enough to do themselves (that was the ‚Äú<strong>er-er Principle</strong>‚Äù).</p>

<ul>
  <li>Manager. When you need a Manager, it‚Äôs often a sign that the Managed are just plain old data structures, and that the Manager is the smart procedure doing the real work.</li>
  <li>Handler, again, is an obvious resurrection of procedural thinking. What is an handler if not a damn procedure?</li>
</ul>

<p><strong>Something-able</strong></p>

<p>It‚Äôs like calling a nail ‚ÄúHammerable‚Äù, because you known, that‚Äôs what you do with a nail, you hammer it. It encourages procedural thinking, and leads to ineffective abstractions.</p>

<p><strong>Something-Object</strong></p>

<p>When you don‚Äôt know how to name something, pick some dominant trait and add Object to the end. Again, the problem is that the ‚Äúdominant trait‚Äù is moving us away from the concept of an object. Object is dropped in just to avoid more careful thinking about the underlying concept.</p>

<p><strong>ISomething</strong></p>

<p>The problem is that it‚Äôs too easy to fall into the trap, and just take a concrete class name, put an I in front of it, and lo and behold!, you got an interface name. Sort of calling a concept IDollar instead of Currency.</p>

<p>Eg.</p>

<ul>
  <li>IList to RandomAccessContainer</li>
  <li>IEnumerable to Sequence.
    <ul>
      <li>A List is an IEnumerable (what??)</li>
      <li>A List is a Sequence (well, all right!)</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>How to Name Things: the solution to the hardest problem in programming - Peter Hilton <a href="https://skillsmatter.com/skillscasts/5747-how-to-name-things-the-solution-to-the-hardest-problem-in-programming">video</a>, <a href="http://www.slideshare.net/pirhilton/how-to-name-things-the-hardest-problem-in-programming">slide</a></p>

  <p>Taking advice from writers, funny quotes, like Stephen King on refactoring, Hemingway on modelling with personas, .etc.</p>
</blockquote>

<p>Remember: ‚Äúrename‚Äù is the simplest but most effective refactoring. Use it.</p>

<p><strong>Gater domain-specific vocabulary</strong>. Scan the domain model entities Wikipedia pages for names of related concepts. Read novels set in your customer‚Äôs domain to learn their jargon. Find out what they really mean.</p>

<p>Comments: the basics</p>

<ul>
  <li>Don‚Äôt say what the code does (because the code already says that)</li>
  <li>Don‚Äôt explain awkward logic (improve the code to make it clear)</li>
  <li>Don‚Äôt add too many comments (it‚Äôs messy and they‚Äôll get out of date)</li>
  <li>Explain why the code exists
    <ul>
      <li>When should I use this code?</li>
      <li>When shouldn‚Äôt I use it?</li>
      <li>What are the alternatives to this code?</li>
    </ul>
  </li>
</ul>

<p>How to write good comments</p>

<ul>
  <li>Try to write good code first</li>
  <li>Try to write a one-sentence comment</li>
  <li>Refactor the code until the comment is easy to write</li>
  <li>Now write a good comment</li>
  <li>Don‚Äôt forget the rules of good writing. (eg. remove unnecessary comments)</li>
</ul>

<p>P.S. Peter also has several posts talking about commenting, check <a href="http://hilton.org.uk/blog/how-to-comment-code">How to comment code</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ruby Concurrency Article Collection]]></title>
    <link href="http://blog.ifyouseewendy.com/blog/2016/02/16/ruby-concurrency-article-collection/"/>
    <updated>2016-02-16T20:04:50+08:00</updated>
    <id>http://blog.ifyouseewendy.com/blog/2016/02/16/ruby-concurrency-article-collection</id>
    <content type="html"><![CDATA[<p>This an article collection about concurrency in Ruby, which benefits me a lot and to be continued.</p>

<blockquote>
  <p><a href="http://www.jstorimer.com/blogs/workingwithcode/7766063-threads-not-just-for-optimizations">Threads, Not Just for Optimisations - Jesse Storimer</a></p>
</blockquote>

<p>Threads can help us organize our programs.</p>

<p>When a signal is delivered to a multithreaded process that has established a signal handler, the kernel arbitrarily selects one thread in the process to which to deliver the signal and invokes the handler in that thread. So Ruby uses a dedicated thread to handle incoming Unix signals. This has nothing to do with speeding things up, it‚Äôs just good programming practice.</p>

<p>When you spawn a new Unix process using fork, you really should either wait for it to finish using Process.wait, or detach from it using Process.detach. The reason is that when the process exits, it leaves behind some information about its exit status. This status info can‚Äôt be cleaned up until it‚Äôs been consumed by the parent process using Process.wait. When you use something like Process.spawn or backticks, Process.wait is called internally to cleanup the aforementioned status info. So Process.detach is just a thin wrapper around Process.wait, using a background thread to wait for the return value of Process.wait, while the main thread continues execution concurrently. Again, this has nothing to do with speed, but allows the proper housekeeping to be done without burdening the program with extra state.</p>

<blockquote>
  <p><a href="http://concur.rspace.googlecode.com/hg/talk/concur.html#title-slide">Concurrency is not Parallelism (it‚Äôs better) - Rob Pike</a></p>
</blockquote>

<p>Go provides</p>

<ul>
  <li>concurrent execution (coroutines. They‚Äôre a bit like threads, but they‚Äôre much cheaper. Goroutines are multiplexed onto OS threads as required. When a goroutine blocks, that thread blocks but no other goroutine blocks.)</li>
  <li>synchronization and messaging (channels)</li>
  <li>multi-way concurrent control (select)</li>
</ul>

<p>Concurrency vs. Paralelism</p>

<ul>
  <li>Concurrency is about dealing with lots of things at once.</li>
  <li>Parallelism is about doing lots of things at once.</li>
  <li>Not the same, but related.</li>
  <li>One is about structure (design), one is about execution.</li>
  <li>Concurrency provides a way to structure a solution to solve a problem that may (but not necessarily) be parallelizable.</li>
</ul>

<p>Concurrency plus communication</p>

<ul>
  <li>Concurrency is a way to structure a program by breaking it into pieces that can be executed independently.</li>
  <li>Communication is the means to coordinate the independent executions.</li>
  <li>This is the Go model and (like Erlang and others) it‚Äôs based on CSP (Communicating Sequential Processes)</li>
</ul>

<blockquote>
  <p><a href="https://blog.engineyard.com/2011/ruby-concurrency-and-you">Ruby, Concurrency, and You - Engine Yard</a></p>
</blockquote>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/RCAC-ruby_support.png" alt="RCAC-ruby_support.png" /></p>

<blockquote>
  <p><a href="https://github.com/jruby/jruby/wiki/Concurrency-in-jruby">Concurrency in JRuby</a></p>
</blockquote>

<p>In general, the safest path to writing concurrent code in JRuby is the same as on any other platform:</p>

<ul>
  <li>Don‚Äôt do it, if you can avoid it.</li>
  <li>If you must do it, don‚Äôt share data across threads.</li>
  <li>If you must share data across threads, don‚Äôt share mutable data.</li>
  <li>If you must share mutable data across threads, synchronize access to that data.</li>
</ul>

<p>Thread Safety refers to the ability to perform operations against a shared structure across multiple threads and know there will be no resulting errors or data integrity issues.</p>

<p>Volatility refers to the visibility of changes across threads on multi-core systems that may have thread or core-specific views of system memory.</p>

<p>Atomicity refers to the ability to perform a write to memory based on some view of that memory and to know the write happens before the view is invalid.</p>

<blockquote>
  <ul>
    <li><a href="http://www.jstorimer.com/blogs/workingwithcode/8085491-nobody-understands-the-gil%0A">Nobody understands the GIL - Part 1 - Jesse Storimer</a></li>
    <li><a href="http://www.jstorimer.com/blogs/workingwithcode/8100871-nobody-understands-the-gil-part-2-implementation">Nobody understands the GIL - Part 2: Implementation - Jesse Storimer</a></li>
    <li><a href="http://www.rubyinside.com/does-the-gil-make-your-ruby-code-thread-safe-6051.html">Does the GIL Make Your Ruby Code Thread-Safe? - Jesse Storimer</a></li>
  </ul>
</blockquote>

<p>It‚Äôs possible for all of the Ruby implementations to provide thread-safe data structures, but that requires extra overhead that would make single-threaded code slower.</p>

<p>For the MRI core team, the GIL protects the internal state of the system. With a GIL, they don‚Äôt require any locks or synchronization around the internal data structures. If two threads can‚Äôt be mutating the internals at the same time, then no race conditions can occur. For you, the developer, this will severely limit the parallelism you get from running your Ruby code on MRI.</p>

<p>All that the GIL guarantees is that MRI‚Äôs native C implementations of Ruby methods will be executed atomically (but even this has caveats). This behaviour can sometimes help us as Ruby developers, but the GIL is really there for the protection of MRI internals, not as a dependable API for Ruby developers. So the GIL doesn‚Äôt ‚Äòsolve‚Äô thread-safety issues.</p>

<p>Don‚Äôt communicate by sharing state; share state by communicating.</p>

<blockquote>
  <p><a href="https://www.igvita.com/2008/11/13/concurrency-is-a-myth-in-ruby/">Parallelism is a Myth in Ruby - Ilya Grigorik</a></p>
</blockquote>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/RCAC-ruby_gil.png" alt="RCAC-ruby_gil.png" /></p>

<blockquote>
  <p><a href="https://github.com/jdantonio/Everything-You-Know-About-the-GIL-is-Wrong-RubyConf-2015">Everything You Know About GIL is Wrong - Jerry D‚ÄôAntonio</a></p>
</blockquote>

<p>Summary</p>

<ul>
  <li>Concurrency is not parallelism</li>
  <li>The GIL protects Ruby‚Äôs internal state when the operating system context switches
    <ul>
      <li>The GIL does not provide thread safety guarantees to user code</li>
      <li>But it imposes an implicit memory model</li>
    </ul>
  </li>
  <li>The GIL prevents true parallelism in Ruby</li>
  <li>But Ruby is pretty good at multiplexing threads performing blocking I/O</li>
</ul>

<p>Concurrency vs. Parallelism</p>

<p>Non-concurrent programs gain no benefit from running on multiple processors. Concurrent programs get parallelism for free when the runtime supports it.</p>

<ul>
  <li>Parallelism requires two processor cores. No matter the language/runtime, a processor core can only execute one instruction at a time.</li>
  <li>Concurrency can happen when there is only one core. Concurrency is about design, improved performance is a side effect</li>
</ul>

<p>Ruby is selfish</p>

<ul>
  <li>Ruby is an interpreted language
    <ul>
      <li>Ruby is compiled to bytecode within the interpreter</li>
      <li>Ruby is free to optimize and reorder your code</li>
    </ul>
  </li>
  <li>Every Ruby operation is implemented in C</li>
  <li>The Ruby runtime is just another program; it is under the control of the compiler and the operating system
    <ul>
      <li>The C compiler is free to optimize and reorder instructions during compilation</li>
      <li>An operating system context switch can occur at any point in the running C code</li>
    </ul>
  </li>
  <li>The GIL protects Ruby, not your code</li>
</ul>

<p>Ruby is thread safe, your code isn‚Äôt.</p>

<ul>
  <li>Every individual read and write to memory is guaranteed to be thread-safe in Ruby
    <ul>
      <li>The GIL prevents interleaved access to memory used by the runtime</li>
      <li>The GIL prevents interleaved access to individual variables</li>
      <li>Ruby itself will never become corrupt</li>
    </ul>
  </li>
  <li>Ruby makes no guarantees about your code</li>
</ul>

<p><a href="https://www.wikiwand.com/en/Memory_model_(programming)">Memory model</a></p>

<ul>
  <li>‚ÄúIn computing, a memory model describes the interactions of threads through memory and their shared use of the data.‚Äù Wikipedia</li>
  <li>Defines visibility, volatility, atomicity, and synchronization barriers
    <ul>
      <li>Java‚Äôs current memory model was adopted in 2004 as part of Java</li>
      <li>The C and C++ memory models were adopted in 2011 with C11 and C++11</li>
      <li><a href="https://golang.org/ref/mem">The Go Memory Model</a></li>
    </ul>
  </li>
  <li>Ruby does NOT have a documented memory model. The GIL provides an implied memory model but no guarantees</li>
</ul>

<p>I/O</p>

<p>Ruby programs which perform significant I/O generally benefit from concurrency.</p>

<ul>
  <li>I/O in Ruby programs is blocking</li>
  <li>I/O within Ruby is asynchronous</li>
</ul>

<p>You can‚Äôt spell GIL without I/O. The GIL exists to maintain the internal consistency of the Ruby runtime. I/O operations are slow, which is why asynchronous I/O was invented. While I/O is in progress the Ruby thread is blocked so it cannot change the internal state, so Ruby allows other threads to do useful work. All Ruby I/O calls unlock the GIL, as do backtick and <code>system</code> calls. When Ruby thread is waiting on I/O it does not block other threads.</p>

<blockquote>
  <p><a href="http://merbist.com/2011/02/22/concurrency-in-ruby-explained/">Ruby concurrency explained - Matt Aimonetti</a></p>
</blockquote>

<p>The thing to keep in mind is that the concurrency models are often defined by the programming language you use. The advantage of the Java threaded approach is that the memory is shared between the threads so you are saving in memory (and startup time), each thread can easily talk to each other via the shared memory. The advantage of PHP is that you don‚Äôt have to worry about locks, deadlocks, threadsafe code and all that mess hidden behind threads.</p>

<p>Others programming languages like Erlang and Scala use a third approach: the actor model. The actor model is somewhat a bit of a mix of both solutions, the difference is that actors are a like threads which don‚Äôt share the same memory context. Communication between actors is done via exchanged messages ensuring that each actor handles its own state and therefore avoiding corrupt data (two threads can modify the same data at the same time, but an actor can‚Äôt receive two messages at the exact same time).</p>

<p>Actors/Fibers</p>

<p>Ruby 1.9, developers now have access to a new type of ‚Äúlightweight‚Äù threads called Fibers. Fibers are not actors and Ruby doesn‚Äôt have a native Actor model implementation but some people wrote some actor libs on top of fibers. A fiber is like a simplified thread which isn‚Äôt scheduled by the VM but by the programmer. Fibers are like blocks which can be paused and resumed from the outside of from within themselves.</p>

<p>How do fibers help with concurrency? The answer is that they are part of a bigger solution. Ruby 1.9 gave us fibers which allow for a more granular control over the concurrency scheduling, combined with non-blocking IO, high concurrency can be achieved. Fiber allow developers to manually control the scheduling of ‚Äúconcurrent‚Äù code but also to have the code within the fiber to auto schedule itself.  Well, the only problem is that if you are doing any type of blocking IO in a fiber, the entire thread is blocked and the other fibers aren‚Äôt running. So avoid blocking IOs.</p>

<p>Non blocking IOs/Reactor pattern</p>

<p>The reactor pattern is quite simple to understand really. The heavy work of making blocking IO calls is delegated to an external service (reactor) which can receive concurrent requests. The service handler (reactor) is given callback methods to trigger asynchronously based on the type of response received.</p>

<p>When a request comes in and your code makes a DB query, you are blocking any other requests from being processed. To avoid that, we could wrap our request in a fiber, trigger an async DB call and pause the fiber so another request can get processed as we are waiting for the DB. Once the DB query comes back, it wakes up the fiber it was trigger from, which then sends the response back to the client. Technically, the server can still only send one response at a time, but now fibers can run in parallel and don‚Äôt block the main tread by doing blocking IOs (since it‚Äôs done by the reactor).</p>

<p>This is the approach used by Twisted, EventMachine and Node.js. Ruby developers can use EventMachine or an EventMachine based webserver like Thin as well as EM clients/drivers to make non blocking async calls.</p>

<blockquote>
  <p><a href="https://www.quora.com/Node-js/What-is-a-good-comparison-of-the-reactor-pattern-vs-actor-model">Node.js: What is a good comparison of the reactor pattern vs actor model? - Sean Byrnes</a></p>
</blockquote>

<p>The reactor model follows a purely event driven system where the entire system can be implemented as a single-threaded process with a series of event generators and event handlers. In most implementations there is a ‚Äúevent loop‚Äù that continues to run which takes all of the generated events, sends them to all registered event handles and then starts over again.</p>

<p>An actor model is a more abstract method of breaking up execution into different processes that interact with each other. While it is possible to do this similarly to the reactor model, I see this mostly as a series of processes running in different threads and exchanging information through messages or protocols.</p>

<blockquote>
  <p><a href="http://www.toptal.com/ruby/ruby-concurrency-and-parallelism-a-practical-primer?utm_source=rubyweekly&amp;utm_medium=email">Ruby Concurrency and Parallelism: A Practical Tutorial</a></p>
</blockquote>

<ul>
  <li>Ruby concurrency is when two tasks can start, run, and complete in overlapping time periods. It doesn‚Äôt necessarily mean, though, that they‚Äôll ever both be running at the same instant (e.g., multiple threads on a single-core machine).</li>
  <li>Parallelism is when two tasks literally run at the same time.</li>
</ul>

<blockquote>
  <p><a href="http://oldmoe.blogspot.jp/2008/08/ruby-fibers-vs-ruby-threads.html">Ruby Fibers Vs Ruby Threads</a></p>
</blockquote>

<p>Fibers are much faster to create than threads, they eat much less memory too.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ruby Concurrency In Practice]]></title>
    <link href="http://blog.ifyouseewendy.com/blog/2016/02/16/ruby-concurrency-in-practice/"/>
    <updated>2016-02-16T19:58:54+08:00</updated>
    <id>http://blog.ifyouseewendy.com/blog/2016/02/16/ruby-concurrency-in-practice</id>
    <content type="html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#guidance">Guidance</a>    <ul>
      <li><a href="#safest-path-to-concurrency">Safest path to concurrency</a></li>
      <li><a href="#writing-thread-safe-code">Writing Thread-safe Code</a></li>
    </ul>
  </li>
  <li><a href="#into-the-wild">Into the Wild</a></li>
</ul>

<h2 id="guidance">Guidance</h2>

<h3 id="safest-path-to-concurrency">Safest path to concurrency</h3>

<blockquote>
  <p>from <a href="https://github.com/jruby/jruby/wiki/Concurrency-in-jruby">JRuby wiki</a></p>
</blockquote>

<ol>
  <li>Don‚Äôt do it.</li>
  <li>If you must do it, don‚Äôt share data across threads.</li>
  <li>If you must share data across threads, don‚Äôt share mutable data.</li>
  <li>If you must share mutable data across threads, synchronize access to that data.</li>
</ol>

<p>Do not communicate by sharing data; instead, share data by communicating</p>

<h3 id="writing-thread-safe-code">Writing Thread-safe Code</h3>

<p><strong>Avoid mutating globals</strong></p>

<ul>
  <li>Constants</li>
  <li>The AST</li>
  <li>Class variables/methods</li>
</ul>

<p><strong>Create more objects, rather than sharing one</strong></p>

<ul>
  <li>Thread-locals</li>
  <li>Connection pools</li>
</ul>

<p><strong>Avoid lazy loading</strong></p>

<ul>
  <li>No autoload</li>
</ul>

<p><strong>Prefer data structures over mutexes</strong></p>

<p>Mutexes are notoriously hard to use correctly. For better or worse, you have a lot of things to decide when using a mutex.</p>

<ul>
  <li>How coarse or fine should this mutex be?</li>
  <li>Which lines of code need to be in the critical section?</li>
  <li>Is a deadlock possible here?</li>
  <li>Do I need a per-instance mutex? Or a global one?</li>
</ul>

<p>By leaning on a data structure, you remove the burden of correct synchronization from your code and depend on the semantics of the data structure to keep things consistent.</p>

<p><strong>Wrap your threads in an abstraction</strong></p>

<ul>
  <li>Actor model</li>
  <li>Reactor Pattern, event-driven I/O</li>
</ul>

<h2 id="into-the-wild">Into the Wild</h2>

<p><strong>Primitives</strong></p>

<ul>
  <li><a href="http://ruby-doc.org/core-2.2.2/Thread.html">Thread</a></li>
  <li><a href="http://ruby-doc.org/core-2.2.2/Mutex.html">Mutex</a></li>
  <li><a href="http://ruby-doc.org/core-2.2.2/ConditionVariable.html">ConditionVariable</a></li>
</ul>

<p><strong>Thread-safe Data Structure</strong></p>

<ul>
  <li><a href="https://github.com/hamstergem/hamster">hamster</a> - Efficient, Immutable, Thread-Safe Collection classes for Ruby</li>
  <li><a href="https://github.com/ruby-concurrency/thread_safe">thread_safe</a> - Thread-safe collections for Ruby</li>
  <li><a href="https://github.com/ruby-concurrency/atomic">atomic</a> - Atomic references for Ruby (merged with concurrent-ruby)</li>
  <li><a href="https://github.com/mperham/connection_pool">connection_pool</a> - Generic connection pooling for Ruby</li>
</ul>

<p><strong>Abstraction / Framework</strong></p>

<p><a href="https://github.com/celluloid/celluloid">celluloid</a></p>

<p>Actor-based concurrent object framework for Ruby.</p>

<ul>
  <li><a href="https://github.com/celluloid/reel/">Reel</a> - An ‚Äúevented‚Äù web server based on Celluloid::IO</li>
  <li><a href="https://github.com/kenichi/angelo">angelo</a> - Sinatra-like DSL for Reel that supports WebSockets and SSE</li>
</ul>

<p><a href="https://github.com/eventmachine/eventmachine">eventmachine</a></p>

<p>EventMachine is an event-driven I/O and lightweight concurrency library for Ruby. It provides event-driven I/O using the Reactor pattern.</p>

<ul>
  <li><a href="http://code.macournoyer.com/thin/">Thin</a>, <a href="https://github.com/postrank-labs/goliath/">Goliath</a> - Scalable event-driven servers. Examples:</li>
  <li><a href="https://github.com/igrigorik/em-http-request">em-http-request</a> - Asynchronous HTTP Client (EventMachine + Ruby)</li>
  <li><a href="https://github.com/igrigorik/em-synchrony">em-synchrony</a> - Fiber aware EventMachine clients and convenience classes</li>
</ul>

<p><a href="https://github.com/puma/puma">puma</a></p>

<p>A ruby web server built for concurrency</p>

<p><a href="https://github.com/ruby-concurrency/concurrent-ruby">concurrent-ruby</a></p>

<p>Modern concurrency tools including agents, futures, promises, thread pools, supervisors, and more. Inspired by Erlang, Clojure, Scala, Go, Java, JavaScript, and classic concurrency patterns.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ruby Concurrency In Theory]]></title>
    <link href="http://blog.ifyouseewendy.com/blog/2016/02/16/ruby-concurrency-in-theory/"/>
    <updated>2016-02-16T19:35:19+08:00</updated>
    <id>http://blog.ifyouseewendy.com/blog/2016/02/16/ruby-concurrency-in-theory</id>
    <content type="html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#what-is-concurrency">What is concurrency?</a>    <ul>
      <li><a href="#concurrency-vs-paralelism">Concurrency vs. Paralelism</a></li>
      <li><a href="#concurrency-plus-communication">Concurrency plus communication</a></li>
    </ul>
  </li>
  <li><a href="#what-does-ruby-support">What does Ruby support?</a>    <ul>
      <li><a href="#gil">GIL</a></li>
      <li><a href="#ruby-support">Ruby Support</a></li>
      <li><a href="#fiber">Fiber</a></li>
    </ul>
  </li>
  <li><a href="#how-to-enhance-concurrency-by-ruby">How to enhance concurrency by Ruby?</a>    <ul>
      <li><a href="#basics">Basics</a></li>
      <li><a href="#concurrency-model-software-transactional-memory">Concurrency Model: Software Transactional Memory</a></li>
      <li><a href="#concurrency-model-actor-model">Concurrency Model: Actor Model</a></li>
    </ul>
  </li>
</ul>

<h2 id="what-is-concurrency">What is concurrency?</h2>

<h3 id="concurrency-vs-paralelism">Concurrency vs. Paralelism</h3>

<ul>
  <li>Concurrency is about dealing with lots of things at once.</li>
  <li>Parallelism is about doing lots of things at once.</li>
  <li>Not the same, but related.</li>
  <li>One is about structure (design), one is about execution.</li>
  <li>Concurrency provides a way to structure a solution to solve a problem that may (but not necessarily) be parallelizable.</li>
</ul>

<h3 id="concurrency-plus-communication">Concurrency plus communication</h3>

<ul>
  <li>Concurrency is a way to structure a program by breaking it into pieces that can be executed independently.</li>
  <li>Communication is the means to coordinate the independent executions.</li>
  <li>This is the Go model and (like Erlang and others) it‚Äôs based on CSP (Communicating Sequential Processes)</li>
</ul>

<p><em>Reference</em></p>

<ul>
  <li><a href="http://concur.rspace.googlecode.com/hg/talk/concur.html#title-slide">Concurrency is not Parallelism (it‚Äôs better) - Rob Pike</a></li>
</ul>

<h2 id="what-does-ruby-support">What does Ruby support?</h2>

<h3 id="gil">GIL</h3>

<p>A global interpreter lock (GIL) is a mutual-exclusion lock held by a programming language interpreter thread to avoid sharing code that is not thread-safe with other threads. In implementations with a GIL, there is always one GIL for each interpreter process.</p>

<p>Global interpreter lock (GIL) is a mechanism used in computer language interpreters to synchronize the execution of threads so that only one native thread can execute at a time. An interpreter that uses GIL always allows exactly one thread to execute at a time, even if run on a multi-core processor.</p>

<p><strong>Benefits</strong></p>

<ul>
  <li>increased speed of single-threaded programs (no necessity to acquire or release locks on all data structures separately)</li>
  <li>easy integration of C libraries that usually are not thread-safe</li>
  <li>ease of implementation</li>
</ul>

<p><strong>Drawbacks</strong></p>

<p>Limits the amount of parallelism reachable through concurrency of a single interpreter process with multiple threads. Hence a significant slowdown for CPU-bound thread.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/RCIT-native_threads.png" alt="RCIT-native_threads.png" /></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/RCIT-threads_with_GIL.png" alt="RCIT-threads_with_GIL.png" /></p>

<p><em>Reference</em></p>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Global_interpreter_lock">Global Interpreter Lock - Wikipedia</a></li>
</ul>

<h3 id="ruby-support">Ruby Support</h3>

<p>Ruby 1.8, uses only a single native thread and runs all Ruby threads within that one native thread. A single OS thread is allocated for the Ruby interpreter, a GIL lock is instantiated, and Ruby threads (‚ÄòGreen Threads‚Äô), are spooled up by our program. This means that threads can never run in parallel, even on multicore CPUs.</p>

<p>Ruby 1.9, allocates a native thread for each Ruby thread. But because some of the C libraries used in this implementation are not themselves thread-safe. Ruby never allows more than one of its native threads to run at the same time. Now the GIL is the bottleneck, and Ruby will never take advantage of multiple cores!</p>

<p>Ruby 1.9, also provides Fiber.</p>

<p>Ruby concurrency without parallelism can still be very useful, though, for tasks that are IO-heavy (e.g., network I/O, disk I/O).  Ruby can release the lock on the GIL on that thread while it blocks on I/O. There is a reason threads were, after all, invented and used even before multi-core servers were common.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/RCIT-ruby_support.png" alt="RCIT-ruby_support.png" /></p>

<p><em>Reference</em></p>

<ul>
  <li><a href="https://blog.engineyard.com/2011/ruby-concurrency-and-you">Ruby, Concurrency, and You - Engine Yard</a></li>
</ul>

<h3 id="fiber">Fiber</h3>

<p>Fibers are primitives for implementing light weight cooperative concurrency in Ruby (think lightweight threads, minus the thread scheduler and less overhead). Basically they are a means of creating code blocks that can be paused and resumed, much like threads. A fiber is a unit of execution that must be manually scheduled by the application. Fibers run in the context of the threads that schedule them. Each thread can schedule multiple fibers.</p>

<p>As opposed to other stackless light weight concurrency models, each fiber comes with a small 4KB stack. This enables the fiber to be paused from deeply nested function calls within the fiber block.</p>

<p>Normal usage: start an async operation, yield the fiber, and then make the callback resume the fiber once the operation is complete.</p>

<p><strong>Compered to Thread</strong></p>

<p>Fibers are never preempted, the scheduling must be done by the programmer and not the VM.</p>

<p><strong>Why Fiber?</strong></p>

<p>In general, fibers do not provide advantages over a well-designed multithreaded application. However, using fibers can make it easier to port applications that were designed to schedule their own threads. The availability of Fibers allows Actor-style programming, without having to worry about overhead.</p>

<p><strong>Why Fiber is called a semi-coroutine?</strong></p>

<p>Coroutines (cooperative multitasking) are computer program components that generalize subroutines for nonpreemptive multitasking, by allowing multiple entry points for suspending and resuming execution at certain locations. Coroutines are well-suited for implementing more familiar program components such as cooperative tasks, exceptions, event loop, iterators, infinite lists and pipes.</p>

<p>Asymmetric Coroutines can only transfer control back to their caller, where Coroutines are free to transfer control to any other Coroutine, as long as they have a handle to it.</p>

<p>We may infer that Ruby encapsulate a Fiber::Core which supports coroutine, and only expose Fiber as a semi-coroutine data structure.</p>

<p><strong>What‚Äôs the performance of Fiber?</strong></p>

<p>Fibers are much faster to create than threads, they eat much less memory too.</p>

<p><em>Reference</em></p>

<ul>
  <li><a href="http://ruby-doc.org/core-2.2.2/Fiber.html">Fiber - Ruby Doc</a></li>
  <li><a href="http://www.infoq.com/news/2007/08/ruby-1-9-fibers">Ruby 1.9 adds Fibers for lightweight concurrency - Werner Schuster</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Coroutine#Implementations_for_Ruby">Coroutine - Wikipedia</a></li>
  <li><a href="http://oldmoe.blogspot.jp/2008/08/ruby-fibers-vs-ruby-threads.html">Ruby Fibers Vs Ruby Threads - oldmoe</a></li>
</ul>

<h2 id="how-to-enhance-concurrency-by-ruby">How to enhance concurrency by Ruby?</h2>

<h3 id="basics">Basics</h3>

<p><strong>How to provide more concurrency?</strong></p>

<ul>
  <li>Multi processing (parallelism), like Resque, Unicorn. Simply to fork a running process to multiply its processing power.</li>
  <li>Multi threading, like Sidekiq, Puma and Thin. Lighter than processes, requiring less overhead. At some point, you may find it necessary to use a thread pool.</li>
  <li>Background processing</li>
  <li>Rely on other concurrency models (event, actor, message-passing)</li>
</ul>

<p><strong>Multi-processing vs. Multi-threading</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/RCIT-multi_processing_vs_multi_threading.png" alt="RCIT-multi_processing_vs_multi_threading.png" /></p>

<p><strong>Thread Pooling</strong></p>

<p>A key configuration parameter for a thread pool is typically the number of threads in the pool. These threads can either be instantiated all at once (i.e., when the pool is created) or lazily (i.e., as needed until the maximum number of threads in the pool has been created).</p>

<p><code>Queue</code> and <code>SizedQueue</code> are thread-safe data structures in Ruby, maybe the only two.</p>

<p><a href="https://gist.github.com/ifyouseewendy/a8fc663ae575843f9e8f">demo snippet</a></p>

<p><em>Reference</em></p>

<ul>
  <li><a href="https://www.igvita.com/2010/08/18/multi-core-threads-message-passing/">Multi-core, Threads &amp; Message Passing - Ilya Grigorik</a></li>
  <li><a href="http://adam.herokuapp.com/past/2009/8/13/threads_suck/">Threads Suck -  Adam Wiggins</a></li>
  <li><a href="https://www.usenix.org/legacy/events/hotos03/tech/full_papers/vonbehren/vonbehren_html/index.html">Why Events Are A Bad Idea - Rob von Behren, Jeremy Condit and Eric Brewer</a></li>
</ul>

<h3 id="concurrency-model-software-transactional-memory">Concurrency Model: Software Transactional Memory</h3>

<p>Software transactional memory (STM) is a concurrency control mechanism analogous to database transactions for controlling access to shared memory in concurrent computing. It is an alternative to lock-based synchronization. STM is a strategy implemented in software, rather than as a hardware component.</p>

<ul>
  <li>A thread completes modifications to shared memory without regard for what other threads might be doing, recording every read and write that it is performing in a log.</li>
  <li>Instead of placing the onus on the writer to make sure it does not adversely affect other operations in progress, it is placed on the reader, who after completing an entire transaction verifies that other threads have not concurrently made changes to memory that it accessed in the past.</li>
  <li>This final operation, in which the changes of a transaction are validated and, if validation is successful, made permanent, is called a commit. A transaction may also abort at any time, causing all of its prior changes to be rolled back or undone. If a transaction cannot be committed due to conflicting changes, it is typically aborted and re-executed from the beginning until it succeeds.</li>
</ul>

<p>Clojure has STM support built into the core language.</p>

<p><em>Reference</em></p>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Software_transactional_memory">Software transactional memory - Wikipedia</a></li>
</ul>

<h3 id="concurrency-model-actor-model">Concurrency Model: Actor Model</h3>

<p>The actor model has its theoretical roots in concurrency modelling and message passing concepts.</p>

<p>The basic operation of an Actor is easy to understand: like a thread, it runs concurrently with other Actors. However, unlike threads it is not pre-emptable. Instead, each Actor has a mailbox and can call a routine named ‚Äúreceive‚Äù to check its mailbox for new messages. The ‚Äúreceive‚Äù routine takes a filter, and if no messages in an Actor‚Äôs mailbox matches the filter, the Actor sleeps until it receives new messages, at which time it‚Äôs rescheduled for execution.</p>

<p>Well, that‚Äôs a bit of a naive description. In reality the important part about Actors is that they cannot mutate shared state simultaneously. That means there are no race conditions or deadlocks because there are no mutexes, conditions, and semaphores, only messages and mailboxes.</p>

<p>Actors are an approach to concurrency which has proven remarkably successful in languages like Erlang and Scala. They emphasize message passing as the only means of exchanging state, as opposed to threaded approaches like mutexes, conditions, and semaphores which hopefully guard access and mutation of any shared state, emphasis on the hopefully. Using messaging eliminates several problems in multithreaded programming, including many types of race conditions and deadlocks which result from hope dying in the cold light of reality.</p>

<p><strong>Message Passing</strong></p>

<p>The fundamental idea of the actor model is to use actors as concurrent primitives that can act upon receiving messages in different ways:</p>

<ul>
  <li>Send a finite number of messages to other actors.</li>
  <li>Spawn a finite number of new actors.</li>
  <li>Change its own internal behavior, taking effect when the next incoming message is handled.</li>
</ul>

<p>For communication, the actor model uses asynchronous message passing. In particular, it does not use any intermediate entities such as channels. Instead, each actor possesses a mailbox and can be addressed. These addresses are not to be confused with identities, and each actor can have no, one or multiple addresses. When an actor sends a message, it must know the address of the recipient. In addition, actors are allowed to send messages to themselves, which they will receive and handle later in a future step.</p>

<p>Messages are sent asynchronously and can take arbitrarily long to eventually arrive in the mailbox of the receiver. Also, the actor models makes no guarantees on the ordering of messages. Queuing and dequeuing of messages in a mailbox are atomic operations, so there cannot be a race condition.</p>

<p>There is no shared state and the interaction between actors is purely based on asynchronous messages.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/RCIT-actor_message_passing.png" alt="RCIT-actor_message_passing.png" /></p>

<p><strong>Implementation</strong></p>

<ul>
  <li>Thread-based Actors - the actor is internally backed by a dedicated thread. This obviously limits scalability and requires the thread to suspend and block when waiting for new messages.</li>
  <li>Event-driven Actors - which does not directly couple actors to threads. Instead, a thread pool can be used for a number of actors. This approach uses a continuation closure to encapsulate the actor and its state. Conceptually, this implementation is very similar to an event loop backed by a threadpool.</li>
</ul>

<p><strong>Reactor Pattern</strong></p>

<p>The reactor design pattern is an event handling pattern for handling service requests delivered concurrently to a service handler by one or more inputs. The service handler then demultiplexes the incoming requests and dispatches them synchronously to the associated request handlers.</p>

<p>The reactor pattern completely separates application specific code from the reactor implementation, which means that application components can be divided into modular, reusable parts. Also, due to the synchronous calling of request handlers, the reactor pattern allows for simple coarse-grain concurrency while not adding the complexity of multiple threads to the system.</p>

<p><em>Reference</em></p>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Actor_model">Actor Model - Wikipedia</a></li>
  <li><a href="http://revactor.github.io/philosophy/">Philosophy - Revactor</a></li>
  <li><a href="http://on-ruby.blogspot.jp/2008/01/ruby-concurrency-with-actors.html">Ruby Concurrency with Actors - Pat Eyler</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Reactor_pattern">Reactor Pattern - Wikipedia</a></li>
  <li><a href="http://berb.github.io/diploma-thesis/original/054_actors.html#02">Actor-based Concurrency - Benjamin Erb</a></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Review] Working With Ruby Threads]]></title>
    <link href="http://blog.ifyouseewendy.com/blog/2016/02/16/review-working-with-ruby-threads/"/>
    <updated>2016-02-16T13:07:05+08:00</updated>
    <id>http://blog.ifyouseewendy.com/blog/2016/02/16/review-working-with-ruby-threads</id>
    <content type="html"><![CDATA[<table class="custom">
  <tbody>
    <tr>
      <td><strong>Book</strong></td>
      <td>Working With Ruby Threads</td>
    </tr>
    <tr>
      <td><strong>Author</strong></td>
      <td><a href="http://www.jstorimer.com/">Jesse Storimer</a></td>
    </tr>
    <tr>
      <td><strong>Link</strong></td>
      <td><a href="http://www.jstorimer.com/products/working-with-ruby-threads">www.jstorimer.com/products/working-with-ruby-threads</a></td>
    </tr>
  </tbody>
</table>

<ul id="markdown-toc">
  <li><a href="#concurrent--parallel">Concurrent != Parallel</a></li>
  <li><a href="#the-gil-and-mri">The GIL and MRI</a></li>
  <li><a href="#thread-execution">Thread Execution</a></li>
  <li><a href="#mutual-exclusion">Mutual Exclusion</a></li>
  <li><a href="#signaling-threads-with-condition-variables">Signaling Threads with Condition Variables</a></li>
  <li><a href="#thread-safe-data-structures">Thread-safe Data Structures</a></li>
  <li><a href="#writing-thread-safe-code">Writing Thread-safe Code</a></li>
  <li><a href="#wrap-your-threads-in-an-abstraction">Wrap Your Threads in an Abstraction</a></li>
  <li><a href="#into-the-wild">Into The Wild</a></li>
  <li><a href="#closing">Closing</a></li>
</ul>

<h2 id="concurrent--parallel">Concurrent != Parallel</h2>

<ul>
  <li>Making it execute in parallel is out of your hands. That responsibility is left to the underlying thread scheduler.</li>
  <li>Making it concurrent, you enable it to be parallelized when the underlying system allows it.</li>
</ul>

<p>Example</p>

<ol>
  <li>You could complete Project A today, then complete Project B tomorrow. (Serial)</li>
  <li>You could work on Project A for a few hours this morning, then switch to Project B for a few hours this afternoon, and then do the same thing tomorrow. Both projects will be finished at the end of the second day. (Concurrent)</li>
  <li>Your agency could hire another programmer. He could work on Project B and you could work on Project A. Both projects will be finished at the end of the first day. (Concurrent &amp;&amp; Parallel)</li>
</ol>

<h2 id="the-gil-and-mri">The GIL and MRI</h2>

<p><strong>MRI allows concurrent execution of Ruby code, but prevents parallel execution of Ruby code.</strong></p>

<p>The GIL prevents parallel execution of Ruby code, but it doesn‚Äôt prevent concurrent execution of Ruby code. Remember that concurrent code execution is possible even on a single core CPU by giving each thread a turn with the resources.</p>

<p>MRI doesn‚Äôt let a thread hog the GIL when it hits blocking IO. This is a no-brainer optimization for MRI. When a thread is blocked waiting for IO, it won‚Äôt be executing any Ruby code. Hence, when a thread is blocking on IO, it releases the GIL so another thread can execute Ruby code.</p>

<p>Example</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="nb">require</span> <span class="s1">&#39;open-uri&#39;</span>
</span><span class="line"><span class="mi">3</span><span class="o">.</span><span class="n">times</span><span class="o">.</span><span class="n">map</span> <span class="k">do</span>
</span><span class="line">  <span class="no">Thread</span><span class="o">.</span><span class="n">new</span> <span class="k">do</span>
</span><span class="line">    <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;http://zombo.com&#39;</span><span class="p">)</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line"><span class="k">end</span><span class="o">.</span><span class="n">each</span><span class="p">(</span><span class="o">&amp;</span><span class="ss">:value</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Thread A gets the GIL. It starts executing Ruby code. It gets down to Ruby‚Äôs Socket APIs and attempts to open a connection to zombo.com. At this point, while Thread A is waiting for its response, it releases the GIL. Now Thread B acquires the GIL and goes through the same steps.</p>

<p>Meanwhile, Thread A is still waiting for its response. Remember that the threads can execute in parallel, so long as they‚Äôre not executing Ruby code. So it‚Äôs quite possible for Thread A and Thread B to both have initiated their connections, and both be waiting for a response.</p>

<p>Under the hood, each thread is using a ppoll(2) system call to be notified when their connection attempt succeeds or fails. When the ppoll(2) call returns, the socket will have some data ready for consumption. At this point, the threads will need to execute Ruby code to process the data. So now the whole process starts over again.</p>

<p><strong>Why GIL Exists?</strong></p>

<p>MRI core developers have been calling the GIL a feature for some time now, rather than a bug. There are three reasons that the GIL exists:</p>

<ul>
  <li>To protect MRI internals from race conditions. The same issues that can happen in your Ruby code can happen in MRI‚Äôs C code. When it‚Äôs running in a multithreaded context, it will need to protect critical parts of the internals with some kind of synchronization mechanism.</li>
  <li>To facilitate the C extension API</li>
  <li>To reduce the likelihood of race conditions in your Ruby code. It‚Äôs important to note that the GIL only reduces entropy here; it can‚Äôt rule it out all together. It‚Äôs a bit like wearing fully body armour to walk down the street: it really helps if you get attacked, but most of the time it‚Äôs just confining.</li>
</ul>

<p><strong>MRI with blocking IO encourages a context switch while waiting for the thread to print to stdout</strong></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="vi">@counter</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class="line">
</span><span class="line"><span class="mi">5</span><span class="o">.</span><span class="n">times</span><span class="o">.</span><span class="n">map</span> <span class="k">do</span>
</span><span class="line">  <span class="no">Thread</span><span class="o">.</span><span class="n">new</span> <span class="k">do</span>
</span><span class="line">    <span class="n">temp</span> <span class="o">=</span> <span class="vi">@counter</span>
</span><span class="line">    <span class="n">temp</span> <span class="o">=</span> <span class="n">temp</span> <span class="o">+</span> <span class="mi">1</span>
</span><span class="line">    <span class="vi">@counter</span> <span class="o">=</span> <span class="n">temp</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line"><span class="k">end</span><span class="o">.</span><span class="n">each</span><span class="p">(</span><span class="o">&amp;</span><span class="ss">:join</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="nb">puts</span> <span class="vi">@counter</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>With no synchronization, even with a GIL, it‚Äôs possible that a context switch happens between incrementing temp and assigning it back to counter. If this is the case, it‚Äôs possible that two threads assign the same value to counter. In the end the result of this little snippet could be less than 5.</p>

<p>It‚Äôs rare to get an incorrect answer using MRI with this snippet, but almost guaranteed if you use JRuby or Rubinius. If you insert a puts in the middle of the block passed to Thread.new, then it‚Äôs very likely that MRI will produce an incorrect result. Its behaviour with blocking IO encourages a context switch while waiting for the thread to print to stdout.</p>

<p><strong>Compare to JRuby, and Rubinius</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/WWRT-multi_thread_prime_number_generation.png" alt="WWRT-multi_thread_prime_number_generation.png" /></p>

<p>GIL makes MRI run faster in single-threaded way, as no need to accquire or release locks for data structures. But also makes MRI run slower in multi-threaded way, as disabling on parellelism.</p>

<p>JRuby and Rubinius do indeed protect their internals from race conditions. But rather than wrapping a lock around the execution of all Ruby code, they protect their internal data structures with many fine-grained locks. Rubinius, for instance, replaced their GIL with about 50 fine-grained locks.</p>

<h2 id="thread-execution">Thread Execution</h2>

<p><strong>Threads in Ruby</strong></p>

<p>There‚Äôs always at least one: the main thread. The main thread has one special property that‚Äôs different from other threads. When the main thread exits, all other threads are immediately terminated and the Ruby process exits.</p>

<p>The most important concept to grasp is that threads have a shared address space. A race condition involves two threads racing to perform an operation on some shared state.</p>

<p><code>Thread#join</code></p>

<p>When one thread raises an unhandled exception, it terminates the thread where the exception was raised, but doesn‚Äôt affect other threads. Similarly, a thread that crashes from an unhandled exception won‚Äôt be noticed until another thread attempts to join it.</p>

<p><code>Thread#status</code></p>

<ul>
  <li>run: Threads currently running have this status.</li>
  <li>sleep: Threads currently sleeping, blocked waiting for a mutex, or waiting on IO, have this status.</li>
  <li>false: Threads that finished executing their block of code, or were successfully killed, have this status.</li>
  <li>nil: Threads that raised an unhandled exception have this status.</li>
  <li>aborting: Threads that are currently running, yet dying, have this status.</li>
</ul>

<p><code>Thread.stop</code></p>

<p>This method puts the current thread to sleep and tells the thread scheduler to schedule some other thread. It will remain in this sleeping state until its alternate, Thread#wakeup is invoked.</p>

<p><code>Thread.pass</code></p>

<p>It asks the thread scheduler to schedule some other thread. Since the current thread doesn‚Äôt sleep, it can‚Äôt guarantee that the thread scheduler will take the hint.</p>

<p>Avoid <code>Thread#raise</code> and <code>Thread#kill</code></p>

<p>It doesn‚Äôt properly respect ensure blocks, which can lead to nasty problems in your code.</p>

<p><strong>How Many Threads Are Too Many?</strong></p>

<p>It depends, there will be a sweet spot between utilizing available resources and context switching overhead.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/WWRT-io_bound.png" alt="WWRT-io_bound.png" />
<img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/WWRT-cpu_bound.png" alt="WWRT-cpu_bound.png" /></p>

<p>CPU-bound code is inherently bound by the rate at which the CPU can execute instructions. Creating more threads isn‚Äôt necessarily faster. On the other hand, introducing more threads improved performance in these two examples by anywhere between 100% and 600%. Finding that sweet spot is certainly worth it.</p>

<p><strong>Thread safety</strong></p>

<p>When your code isn‚Äôt thread-safe, the worst that can happen is that your underlying data becomes incorrect, yet your program continues as if it were correct.</p>

<p>The computer is unaware of thread-safety issues. The onus is on you to notice these problems and deal with them. This is one of the hardest problems when it comes to thread safety. There are no exceptions raised or alarm bells rung when the underlying data is no longer correct. Even worse, sometimes it takes a heavy load to expose a race condition like this.</p>

<p>Any concurrent modifications to the same object are not thread-safe.</p>

<h2 id="mutual-exclusion">Mutual Exclusion</h2>

<p><strong>Demo Snippet</strong></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="c1"># This class represents an ecommerce order</span>
</span><span class="line"><span class="k">class</span> <span class="nc">Order</span>
</span><span class="line">  <span class="kp">attr_accessor</span> <span class="ss">:amount</span><span class="p">,</span> <span class="ss">:status</span>
</span><span class="line">
</span><span class="line">  <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="n">amount</span><span class="p">,</span> <span class="n">status</span><span class="p">)</span>
</span><span class="line">    <span class="vi">@amount</span><span class="p">,</span> <span class="vi">@status</span> <span class="o">=</span> <span class="n">amount</span><span class="p">,</span> <span class="n">status</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line">
</span><span class="line">  <span class="k">def</span> <span class="nf">pending?</span>
</span><span class="line">    <span class="n">status</span> <span class="o">==</span> <span class="s1">&#39;pending&#39;</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line">
</span><span class="line">  <span class="k">def</span> <span class="nf">collect_payment</span>
</span><span class="line">    <span class="nb">puts</span> <span class="s2">&quot;Collecting payment...&quot;</span>
</span><span class="line">    <span class="nb">self</span><span class="o">.</span><span class="n">status</span> <span class="o">=</span> <span class="s1">&#39;paid&#39;</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line"><span class="k">end</span>
</span><span class="line">
</span><span class="line"><span class="c1"># Create a pending order for $100</span>
</span><span class="line"><span class="n">order</span> <span class="o">=</span> <span class="no">Order</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="mi">100</span><span class="o">.</span><span class="mo">00</span><span class="p">,</span> <span class="s1">&#39;pending&#39;</span><span class="p">)</span>
</span><span class="line"><span class="n">mutex</span> <span class="o">=</span> <span class="no">Mutex</span><span class="o">.</span><span class="n">new</span>
</span><span class="line">
</span><span class="line"><span class="c1"># Ask 5 threads to check the status, and collect</span>
</span><span class="line"><span class="c1"># payment if it&#39;s &#39;pending&#39;</span>
</span><span class="line"><span class="mi">5</span><span class="o">.</span><span class="n">times</span><span class="o">.</span><span class="n">map</span> <span class="k">do</span>
</span><span class="line">  <span class="no">Thread</span><span class="o">.</span><span class="n">new</span> <span class="k">do</span>
</span><span class="line">    <span class="n">mutex</span><span class="o">.</span><span class="n">synchronize</span> <span class="k">do</span>
</span><span class="line">      <span class="k">if</span> <span class="n">order</span><span class="o">.</span><span class="n">pending?</span>
</span><span class="line">        <span class="n">order</span><span class="o">.</span><span class="n">collect_payment</span>
</span><span class="line">      <span class="k">end</span>
</span><span class="line">    <span class="k">end</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line"><span class="k">end</span><span class="o">.</span><span class="n">each</span><span class="p">(</span><span class="o">&amp;</span><span class="ss">:join</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The block of code inside of a <code>Mutex#synchronize</code> call is often called a critical section, pointing to the fact that this code accesses a shared resource and must be handled correctly.</p>

<p><strong>Memory Visibility (Volatility)</strong></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="c1"># With this line, it&#39;s possible that another thread</span>
</span><span class="line"><span class="c1"># updated the status already and this value is stale</span>
</span><span class="line"><span class="n">status</span> <span class="o">=</span> <span class="n">order</span><span class="o">.</span><span class="n">status</span>
</span><span class="line">
</span><span class="line"><span class="c1"># With this line, it&#39;s guaranteed that this value is</span>
</span><span class="line"><span class="c1"># consistent with any changes in other threads</span>
</span><span class="line"><span class="n">status</span> <span class="o">=</span> <span class="n">mutex</span><span class="o">.</span><span class="n">synchronize</span> <span class="p">{</span> <span class="n">order</span><span class="o">.</span><span class="n">status</span> <span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The reason for this is due to low-level details. The kernel can cache in, for instance, L2 cache before it‚Äôs visible in main memory. It‚Äôs possible that after the status has been set to ‚Äòpaid,‚Äô by one thread, another thread could still see the Order#status as ‚Äòpending‚Äô by reading the value from main memory before the change has propagated there.</p>

<p>The solution to this is something called a memory barrier. Mutexes are implemented with memory barriers, such that when a mutex is locked, a memory barrier provides the proper memory visibility semantics.</p>

<p>Scenarios around memory visibility are difficult to understand and reason about. That‚Äôs one reason other programming languages have defined something called a memory model, a well-defined specification describing how and when changes to memory are visible in other threads.</p>

<p>Ruby has no such specification yet, so situations like this are tricky to reason about and may even yield different results with different runtimes. That being said, <strong>mutexes carry an implicit memory barrier</strong>. So, if one thread holds a mutex to write a value, other threads can lock the same mutex to read it and they will see the correct, most recent value.</p>

<p><strong>Performance</strong></p>

<p>Mutexes inhibit parallelism. Restrict the critical section to be as small as possible, while still preserving the safety of your data.</p>

<p><strong>The dreaded deadlock</strong></p>

<p>The <code>try_lock</code> method attempts to acquire the mutex, just like the lock method. But unlike lock, try_lock will not wait if the mutex isn‚Äôt available. If another thread already owns the mutex, try_lock will return false. If it successfully acquires the mutex, try_lock will return true.</p>

<p>The downside to this approach is that another kind of issue can arise: <strong>livelocking</strong>. A livelock is similar to a deadlock in that the system is not progressing, but rather than threads stuck sleeping, they would be stuck in some loop with each other with none progressing.</p>

<p>A better solution is to define a mutex hierarchy. In other words, <strong>any time that two threads both need to acquire multiple mutexes, make sure they do it in the same order</strong>.</p>

<h2 id="signaling-threads-with-condition-variables">Signaling Threads with Condition Variables</h2>

<p>Condition variables provide an inter-thread control flow mechanism. A classic usage pattern is Producer-Consumer.</p>

<p><strong>Demo Snippet</strong></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
<span class="line-number">34</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="nb">require</span> <span class="s1">&#39;thread&#39;</span>
</span><span class="line"><span class="nb">require</span> <span class="s1">&#39;net/http&#39;</span>
</span><span class="line">
</span><span class="line"><span class="n">mutex</span>    <span class="o">=</span> <span class="no">Mutex</span><span class="o">.</span><span class="n">new</span>
</span><span class="line"><span class="n">condvar</span>  <span class="o">=</span> <span class="no">ConditionVariable</span><span class="o">.</span><span class="n">new</span>
</span><span class="line"><span class="n">results</span>  <span class="o">=</span> <span class="nb">Array</span><span class="o">.</span><span class="n">new</span>
</span><span class="line">
</span><span class="line"><span class="no">Thread</span><span class="o">.</span><span class="n">new</span> <span class="k">do</span>
</span><span class="line">  <span class="mi">10</span><span class="o">.</span><span class="n">times</span> <span class="k">do</span>
</span><span class="line">    <span class="n">response</span> <span class="o">=</span> <span class="ss">Net</span><span class="p">:</span><span class="ss">:HTTP</span><span class="o">.</span><span class="n">get_response</span><span class="p">(</span><span class="s1">&#39;dynamic.xkcd.com&#39;</span><span class="p">,</span> <span class="s1">&#39;/random/comic/&#39;</span><span class="p">)</span>
</span><span class="line">    <span class="n">random_comic_url</span> <span class="o">=</span> <span class="n">response</span><span class="o">[</span><span class="s1">&#39;Location&#39;</span><span class="o">]</span>
</span><span class="line">
</span><span class="line">    <span class="n">mutex</span><span class="o">.</span><span class="n">synchronize</span> <span class="k">do</span>
</span><span class="line">      <span class="n">results</span> <span class="o">&lt;&lt;</span> <span class="n">random_comic_url</span>
</span><span class="line">      <span class="nb">puts</span> <span class="s1">&#39;Produced result&#39;</span>
</span><span class="line">      <span class="n">condvar</span><span class="o">.</span><span class="n">signal</span> <span class="c1"># Signal the ConditionVariable</span>
</span><span class="line">    <span class="k">end</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line"><span class="k">end</span>
</span><span class="line">
</span><span class="line"><span class="n">comics_received</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class="line">
</span><span class="line"><span class="k">until</span> <span class="n">comics_received</span> <span class="o">&gt;=</span> <span class="mi">10</span>
</span><span class="line">  <span class="n">mutex</span><span class="o">.</span><span class="n">synchronize</span> <span class="k">do</span>
</span><span class="line">    <span class="k">while</span> <span class="n">results</span><span class="o">.</span><span class="n">empty?</span>
</span><span class="line">      <span class="n">condvar</span><span class="o">.</span><span class="n">wait</span><span class="p">(</span><span class="n">mutex</span><span class="p">)</span>
</span><span class="line">    <span class="k">end</span>
</span><span class="line">
</span><span class="line">    <span class="n">url</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">shift</span>
</span><span class="line">    <span class="nb">puts</span> <span class="s2">&quot;You should check out </span><span class="si">#{</span><span class="n">url</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line">
</span><span class="line">  <span class="n">comics_received</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class="line"><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<ol>
  <li><code>ConditionVariable#signal</code> will wake up exactly one thread that‚Äôs waiting on this ConditionVariable.</li>
  <li><code>ConditionVariable#broadcast</code> will wake up all threads currently waiting on this ConditionVariable.</li>
</ol>

<h2 id="thread-safe-data-structures">Thread-safe Data Structures</h2>

<p><strong>Implementing a thread-safe, blocking queue</strong></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
<span class="line-number">34</span>
<span class="line-number">35</span>
<span class="line-number">36</span>
<span class="line-number">37</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="nb">require</span> <span class="s1">&#39;thread&#39;</span>
</span><span class="line">
</span><span class="line"><span class="k">class</span> <span class="nc">BlockingQueue</span>
</span><span class="line">  <span class="kp">attr_reader</span> <span class="ss">:queue</span><span class="p">,</span> <span class="ss">:mutex</span><span class="p">,</span> <span class="ss">:cv</span>
</span><span class="line">
</span><span class="line">  <span class="k">def</span> <span class="nf">initialize</span>
</span><span class="line">    <span class="vi">@queue</span> <span class="o">=</span> <span class="nb">Array</span><span class="o">.</span><span class="n">new</span>
</span><span class="line">    <span class="vi">@mutex</span> <span class="o">=</span> <span class="no">Mutex</span><span class="o">.</span><span class="n">new</span>
</span><span class="line">    <span class="vi">@cv</span>    <span class="o">=</span> <span class="no">ConditionVariable</span><span class="o">.</span><span class="n">new</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line">
</span><span class="line">  <span class="k">def</span> <span class="nf">push</span><span class="p">(</span><span class="n">ele</span><span class="p">)</span>
</span><span class="line">    <span class="vi">@mutex</span><span class="o">.</span><span class="n">synchronize</span> <span class="k">do</span>
</span><span class="line">      <span class="vi">@queue</span><span class="o">.</span><span class="n">push</span> <span class="n">ele</span>
</span><span class="line">      <span class="vi">@cv</span><span class="o">.</span><span class="n">signal</span>
</span><span class="line">    <span class="k">end</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line">
</span><span class="line">  <span class="k">def</span> <span class="nf">pop</span>
</span><span class="line">    <span class="vi">@mutex</span><span class="o">.</span><span class="n">synchronize</span> <span class="k">do</span>
</span><span class="line">      <span class="k">while</span> <span class="vi">@queue</span><span class="o">.</span><span class="n">empty?</span>
</span><span class="line">        <span class="vi">@cv</span><span class="o">.</span><span class="n">wait</span><span class="p">(</span><span class="vi">@mutex</span><span class="p">)</span>
</span><span class="line">      <span class="k">end</span>
</span><span class="line">
</span><span class="line">      <span class="vi">@queue</span><span class="o">.</span><span class="n">pop</span>
</span><span class="line">    <span class="k">end</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line"><span class="k">end</span>
</span><span class="line">
</span><span class="line"><span class="n">bq</span> <span class="o">=</span> <span class="no">BlockingQueue</span><span class="o">.</span><span class="n">new</span>
</span><span class="line">
</span><span class="line"><span class="n">bq</span><span class="o">.</span><span class="n">push</span> <span class="s1">&#39;a&#39;</span>
</span><span class="line"><span class="n">bq</span><span class="o">.</span><span class="n">push</span> <span class="s1">&#39;b&#39;</span>
</span><span class="line">
</span><span class="line"><span class="kp">loop</span> <span class="k">do</span>
</span><span class="line">  <span class="nb">puts</span> <span class="n">bq</span><span class="o">.</span><span class="n">pop</span>
</span><span class="line"><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><strong>Queue, from the standard lib</strong></p>

<p>This is the only thread-safe data structure that ships with Ruby. Queue is very useful because of its blocking behaviour. Typically, you would use a Queue to distribute workloads to multiple threads, with one thread pushing to the queue, and multiple threads popping.</p>

<p><strong>Array and Hash</strong></p>

<p>Ruby doesn‚Äôt ship with any thread-safe Array or Hash implementations. Thread-safety concerns would add overhead to their implementation, which would hurt performance for single-threaded use cases.</p>

<p>You might be thinking: ‚ÄúWith all of the great concurrency support available to Java on the JVM, surely the JRuby Array and Hash are thread-safe?‚Äù They‚Äôre not. For the exact reason mentioned above, using a thread-safe data structure in a single-threaded context would reduce performance.</p>

<p><strong>Immutable data structures</strong></p>

<p>When you need to share objects between threads, share immutable objects. It‚Äôs very easy to pass out immutable objects to share, but if you need to have multiple threads modifying an immutable object you still need some form of synchronization.</p>

<p>Immutability is a nice guarantee to have, it‚Äôs the simplest path to thread safety when sharing objects.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="nb">require</span> <span class="s1">&#39;hamster/queue&#39;</span>
</span><span class="line"><span class="nb">require</span> <span class="s1">&#39;atomic&#39;</span>
</span><span class="line">
</span><span class="line"><span class="vi">@queue_wrapper</span> <span class="o">=</span> <span class="no">Atomic</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="ss">Hamster</span><span class="p">:</span><span class="ss">:Queue</span><span class="o">.</span><span class="n">new</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="mi">30</span><span class="o">.</span><span class="n">times</span> <span class="k">do</span>
</span><span class="line">  <span class="vi">@queue_wrapper</span><span class="o">.</span><span class="n">update</span> <span class="p">{</span> <span class="o">|</span><span class="n">queue</span><span class="o">|</span>
</span><span class="line">    <span class="n">queue</span><span class="o">.</span><span class="n">enqueue</span><span class="p">(</span><span class="nb">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span>
</span><span class="line">  <span class="p">}</span>
</span><span class="line"><span class="k">end</span>
</span><span class="line">
</span><span class="line"><span class="n">consumers</span> <span class="o">=</span> <span class="o">[]</span>
</span><span class="line">
</span><span class="line"><span class="mi">3</span><span class="o">.</span><span class="n">times</span> <span class="k">do</span>
</span><span class="line">  <span class="n">consumers</span> <span class="o">&lt;&lt;</span> <span class="no">Thread</span><span class="o">.</span><span class="n">new</span> <span class="k">do</span>
</span><span class="line">    <span class="mi">10</span><span class="o">.</span><span class="n">times</span> <span class="k">do</span>
</span><span class="line">      <span class="n">number</span> <span class="o">=</span> <span class="kp">nil</span>
</span><span class="line">      <span class="vi">@queue_wrapper</span><span class="o">.</span><span class="n">update</span> <span class="p">{</span> <span class="o">|</span><span class="n">queue</span><span class="o">|</span>
</span><span class="line">        <span class="n">number</span> <span class="o">=</span> <span class="n">queue</span><span class="o">.</span><span class="n">head</span>
</span><span class="line">        <span class="n">queue</span><span class="o">.</span><span class="n">dequeue</span>
</span><span class="line">      <span class="p">}</span>
</span><span class="line">
</span><span class="line">      <span class="nb">puts</span> <span class="s2">&quot;The cubed root of </span><span class="si">#{</span><span class="n">number</span><span class="si">}</span><span class="s2"> is </span><span class="si">#{</span><span class="no">Math</span><span class="o">.</span><span class="n">cbrt</span><span class="p">(</span><span class="n">number</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span class="line">    <span class="k">end</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line"><span class="k">end</span>
</span><span class="line">
</span><span class="line"><span class="n">consumers</span><span class="o">.</span><span class="n">each</span><span class="p">(</span><span class="o">&amp;</span><span class="ss">:join</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="writing-thread-safe-code">Writing Thread-safe Code</h2>

<p>Any guideline has exceptions, but it‚Äôs good to know when you‚Äôre breaking one, and why.</p>

<p>Idiomatic Ruby code is most often thread-safe Ruby code.</p>

<p><strong>Avoid mutating globals</strong></p>

<p>Any time there is only one shared instance (aka. singleton), it‚Äôs a global.</p>

<p>There are other things that fit this definition in Ruby:</p>

<ul>
  <li>Constants</li>
  <li>The AST</li>
  <li>Class variables/methods</li>
</ul>

<p>A slightly more nefarious example is the AST. Ruby, being such a dynamic language, allows you to change this at runtime. I don‚Äôt imagine this would be a common problem, but I saw it come up as an issue with the kaminari rubygem. Some part of the code was defining a method dynamically, then calling alias_method with that method, then removing it.</p>

<p>Again, this has to be a rare example, but it‚Äôs good to keep in mind that modifying the AST at runtime is almost always a bad idea, especially when multiple threads are involved. When I say ‚Äòruntime‚Äô, I mean during the course of the lifecycle of the application. In other words, it‚Äôs expected that the AST will be modified at startup time, most Ruby libraries depend on this behaviour in some way. However, in the case of a Rails application, once it‚Äôs been initialized, changes to the AST shouldn‚Äôt happen at runtime, just as it‚Äôs rare to require new files in the midst of a controller action.</p>

<p><strong>Create more objects, rather than sharing one</strong></p>

<ul>
  <li>Thread-locals</li>
  <li>Connection pools</li>
</ul>

<p>A thread-local lets you define a variable that is global to the scope of the current thread. In other words, it‚Äôs a global variable that is locally scoped on a per-thread basis.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="c1"># Instead of</span>
</span><span class="line"><span class="vg">$redis</span> <span class="o">=</span> <span class="no">Redis</span><span class="o">.</span><span class="n">new</span>
</span><span class="line"><span class="c1"># use</span>
</span><span class="line"><span class="no">Thread</span><span class="o">.</span><span class="n">current</span><span class="o">[</span><span class="ss">:redis</span><span class="o">]</span> <span class="o">=</span> <span class="no">Redis</span><span class="o">.</span><span class="n">new</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>It‚Äôs perfectly acceptable to tell users of your API that they should create one object for each thread, rather than trying to write difficult, thread-safe code that will increase your maintainenace costs.</p>

<p>This N:N connection mapping is fine for small numbers of threads, but gets out of hand when the number of threads starts to increase. For connections, a pool is often a better abstraction.</p>

<p>Resource pool still ensures that your threads aren‚Äôt sharing a single connection, but doesn‚Äôt require each thread to have its own. Implementing a connection pool is a good exercise in thread-safe programming, you‚Äôll probably need to make use of both thread-locals and mutexes to do it safely.</p>

<p><strong>Avoid lazy loading</strong></p>

<p>A common idiom in Ruby on Rails applications is to lazily load constants at runtime, using something similar to Ruby‚Äôs <code>autoload</code>. But <code>autoload</code> in MRI is not thread-safe. It is thread-safe in recent versions of JRuby, but the best practice is simply to eager load files before spawning worker threads. This is done implicitly in Rails 4+, and can be enabled in Rails 3.x using the ` config.threadsafe!` configuration setting.</p>

<p><strong>Prefer data structures over mutexes</strong></p>

<p>Mutexes are notoriously hard to use correctly. For better or worse, you have a lot of things to decide when using a mutex.</p>

<ul>
  <li>How coarse or fine should this mutex be?</li>
  <li>Which lines of code need to be in the critical section?</li>
  <li>Is a deadlock possible here?</li>
  <li>Do I need a per-instance mutex? Or a global one?</li>
</ul>

<p>By leaning on a data structure, you remove the burden of correct synchronization from your code and depend on the semantics of the data structure to keep things consistent.</p>

<p>This only works if you choose not to share objects between threads directly. Rather than letting threads access shared objects and implementing the necessary synchronization, you pass shared objects through data structures.</p>

<p><strong>Finding bugs</strong></p>

<p>Like most bugs, if you can reproduce the issue, you can almost certainly track it down and fix it. However, some thread-safety issues may appear in production under heavy load, but can‚Äôt be reproduced locally. In this case, there‚Äôs no better solution than grokking the code.</p>

<p>Look at the code and assume that 2 threads will be accessing it simulatneously. Step through the possible scenarios. It can be helpful to jot these things down somewhere.</p>

<p><strong>Thread-safety on Rails</strong></p>

<ul>
  <li>Gem dependencies</li>
  <li>The request is the boundary. Don‚Äôt share objects between requests.</li>
</ul>

<p>A good example of this is something like a <code>User.current</code> reference.</p>

<p>If you really need a global reference, follow the guidelines from the last chapter. Try using a thread-local, or else a thread-aware object that will preserve data correctness.</p>

<p>The same heuristic is applicable to a background job processor. Each job will be handled by a separate thread. A thread may process multiple jobs in its lifetime, but a job will only be processed by a single thread in its lifecycle.</p>

<p>Again, the path to thread safety is clear: create the necessary objects that you need in the body of the job, rather than sharing any global state.</p>

<h2 id="wrap-your-threads-in-an-abstraction">Wrap Your Threads in an Abstraction</h2>

<p><strong>Single level of abstraction</strong></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="k">module</span> <span class="nn">Enumerable</span>
</span><span class="line">  <span class="k">def</span> <span class="nf">concurrent_each</span>
</span><span class="line">    <span class="n">threads</span> <span class="o">=</span> <span class="o">[]</span>
</span><span class="line">    <span class="n">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">element</span><span class="o">|</span>
</span><span class="line">      <span class="n">threads</span> <span class="o">&lt;&lt;</span> <span class="no">Thread</span><span class="o">.</span><span class="n">new</span> <span class="p">{</span> <span class="k">end</span> <span class="k">yield</span> <span class="n">element</span> <span class="p">}</span>
</span><span class="line">      <span class="n">threads</span><span class="o">.</span><span class="n">each</span><span class="p">(</span><span class="o">&amp;</span><span class="ss">:join</span><span class="p">)</span>
</span><span class="line">    <span class="k">end</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line"><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>This is a simple wrapper around Enumerable#each that will spawn a thread for each element being iterated over. It wouldn‚Äôt be wise to use this code in production yet because it has no upper bound on the number of threads it will spawn.</p>

<p><strong>Actor model</strong></p>

<p>At a high level, an Actor is a long-lived ‚Äòentity‚Äô that communicates by sending messages.</p>

<p>In the Actor model, each Actor has an ‚Äòaddress‚Äô. If you know the address of an Actor, you can send it a message. These messages go to the Actor‚Äôs mailbox, where they‚Äôre processed asynchronously when the Actor gets around to it.</p>

<p>What sets Celluloid apart is that it takes this conceptual idea of the Actor model and marries it to Ruby‚Äôs object model.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="nb">require</span> <span class="s1">&#39;celluloid/autostart&#39;</span>
</span><span class="line"><span class="nb">require</span> <span class="s1">&#39;net/http&#39;</span>
</span><span class="line">
</span><span class="line"><span class="k">class</span> <span class="nc">XKCDFetcher</span>
</span><span class="line">  <span class="kp">include</span> <span class="no">Celluloid</span>
</span><span class="line">
</span><span class="line">  <span class="k">def</span> <span class="nf">next</span>
</span><span class="line">    <span class="n">response</span> <span class="o">=</span> <span class="ss">Net</span><span class="p">:</span><span class="ss">:HTTP</span><span class="o">.</span><span class="n">get_response</span><span class="p">(</span><span class="s1">&#39;dynamic.xkcd.com&#39;</span><span class="p">,</span> <span class="s1">&#39;/random/comic/&#39;</span><span class="p">)</span>
</span><span class="line">    <span class="n">random_comic_url</span> <span class="o">=</span> <span class="n">response</span><span class="o">[</span><span class="s1">&#39;Location&#39;</span><span class="o">]</span>
</span><span class="line">
</span><span class="line">    <span class="n">random_comic_url</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line"><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Including the Celluloid module into any Ruby class will turn instances of that class into full-fledged Celluloid actors. When you create a new actor, you immediately know its ‚Äòaddress‚Äô. So long as you hold a reference to that object, you can send it messages. In Celluloid, sending messages to an actor equates to calling methods on an object.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="c1"># this spawns a new thread containing a Celluloid actor</span>
</span><span class="line"><span class="n">fetcher</span> <span class="o">=</span> <span class="no">XKCDFetcher</span><span class="o">.</span><span class="n">new</span>
</span><span class="line">
</span><span class="line"><span class="c1"># these behave like regular method calls</span>
</span><span class="line"><span class="n">fetcher</span><span class="o">.</span><span class="n">object_id</span>
</span><span class="line"><span class="n">fetcher</span><span class="o">.</span><span class="n">inspect</span>
</span><span class="line">
</span><span class="line"><span class="c1"># this will fire the `next` method without</span>
</span><span class="line"><span class="c1"># waiting for its result</span>
</span><span class="line"><span class="n">fetcher</span><span class="o">.</span><span class="n">async</span><span class="o">.</span><span class="n">next</span>
</span><span class="line"><span class="n">fetcher</span><span class="o">.</span><span class="n">async</span><span class="o">.</span><span class="n">next</span>
</span><span class="line">
</span><span class="line"><span class="c1"># Celluloid kicks off that method asynchronously and returns you a Celluloid::Future object.</span>
</span><span class="line"><span class="n">futures</span> <span class="o">=</span> <span class="o">[]</span>
</span><span class="line"><span class="mi">10</span><span class="o">.</span><span class="n">times</span> <span class="k">do</span>
</span><span class="line">  <span class="n">futures</span> <span class="o">&lt;&lt;</span> <span class="n">fetcher</span><span class="o">.</span><span class="n">future</span><span class="o">.</span><span class="n">next</span>
</span><span class="line"><span class="k">end</span>
</span><span class="line">
</span><span class="line"><span class="c1"># Calling #value on that future object will block until the value has been computed.</span>
</span><span class="line"><span class="n">futures</span><span class="o">.</span><span class="n">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">future</span><span class="o">|</span>
</span><span class="line">  <span class="nb">puts</span> <span class="s2">&quot;You should check out </span><span class="si">#{</span><span class="n">future</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span class="line"><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="into-the-wild">Into The Wild</h2>

<p><strong>How Sidekiq Uses Celluloid</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/WWRT-how_sidekiq_uses_celluloid.png" alt="WWRT-how_sidekiq_uses_celluloid.png" /></p>

<p>The most obvious difference I see between the Sidekiq codebase and a more traditional Ruby codebase is the lack of dependence upon return values.</p>

<p><strong>Puma‚Äôs Thread Pool Implementation</strong></p>

<p>At Puma‚Äôs multi-threaded core is a thread pool implementation. Once initialized, the pool is responsible for receiving work and feeding it to an available worker thread. The ThreadPool also has an auto-trimming feature, whereby the number of active threads is kept to a minimum, but more threads can be spawned during times of high load. Afterwards, the thread pool would be trimmed down to the minimum again.</p>

<h2 id="closing">Closing</h2>

<p>The safest path to concurrency: (from JRuby wiki)</p>

<ol>
  <li>Don‚Äôt do it.</li>
  <li>If you must do it, don‚Äôt share data across threads.</li>
  <li>If you must share data across threads, don‚Äôt share mutable data.</li>
  <li>If you must share mutable data across threads, synchronize access to that data.</li>
</ol>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ËæûËÅåÂçäÂπ¥ËÆ∞]]></title>
    <link href="http://blog.ifyouseewendy.com/blog/2016/02/05/ci-zhi-ban-nian-ji/"/>
    <updated>2016-02-05T15:10:31+08:00</updated>
    <id>http://blog.ifyouseewendy.com/blog/2016/02/05/ci-zhi-ban-nian-ji</id>
    <content type="html"><![CDATA[<blockquote>
  <p>2012Âπ¥7Êúà19Êó•ÔºåÂú®ÂèãÁõüÂÖ•ËÅå„ÄÇ
2015Âπ¥7Êúà20Êó•ÔºåËæûËÅåÂõûÂÆ∂„ÄÇ</p>
</blockquote>

<p>‰ªäÂ§©Ôºå2016Âπ¥2Êúà5Êó•ÔºåÁ¨¨199Â§©„ÄÇÂçäÂπ¥Êó∂Èó¥ÔºåËΩ¨Áû¨Âç≥ÈÄù„ÄÇÊØèËøá‰∏Ä‰∏™ÊúàÔºåËá™Â∑±ÈÉΩ‰ºöÂÜôÁØáÂæàÈïøÁöÑÊó•ËÆ∞‰Ωú‰∏∫ÂõûÈ°æ„ÄÇ‰ªäÂ§©ÔºåÊääËøô‰∫õÊãºÂáëÂú®‰∏ÄËµ∑Ôºå‰Ωú‰∏∫ËøôÂçäÂπ¥ÁöÑËæûËÅåÂêéËÆ∞„ÄÇ</p>

<h3 id="section">Â∑•‰Ωú</h3>

<p>‰∏äÂçäÂπ¥Á≠îÂ∫î‰∫ÜÂÆ∂Èáå‰∫≤ÊàöÁöÑÂ§ñÂåÖÂ∑•‰ΩúÔºåÂÖ´Êúà‰ªΩÂºÄÂßãÁùÄÊâãÂáÜÂ§á„ÄÇÊú¨Êù•‰ª•‰∏∫‰∏Ä‰∏§‰∏™ÊúàÂèØ‰ª•ÊêûÂÆöÔºåÁªìÊûúÁõ¥Âà∞Êò®Â§©ÊâçÁÆóÂÖ®ÈÉ®ÂÆåÊàêÔºå‰ø®ÁÑ∂Êàê‰∫ÜÊàëÊï¥‰∏™ÂÅáÊúüÁöÑÂô©Ê¢¶„ÄÇËøôÊòØËá™Â∑±Á¨¨‰∏ÄÊ¨°‰ªéÂ§¥Âà∞Â∞æÂÆåÊàê‰∏Ä‰∏™Áõ∏ÂØπÂ§çÊùÇÊàêÁÜüÁöÑ Web ‰∫ßÂìÅÔºåÂõûÈ¶ñÊï¥‰∏™ËøáÁ®ãÂÖ®ÊòØË°ÄÊ≥™„ÄÇ‰ªéÂâçÁü•ÈÅìÁöÑÈÇ£‰∫õÊâÄË∞ìÈÅìÁêÜÔºåËøôÊ¨°ÂÖ®ÈÉ®ÂàáË∫´‰Ωì‰ºö„ÄÇ</p>

<p>ÂØπÈúÄÊ±Ç„ÄÅÂØπÊó∂Èó¥ÁöÑÈîôËØØÈ¢Ñ‰º∞„ÄÇÂõ†‰∏∫Êä±ÁùÄÂ∏ÆÂà´‰∫∫„ÄÅÊó†ËÆ∫Â¶Ç‰ΩïË¶ÅÊää‰∫ãÊÉÖÂÆåÊàêÂ•ΩÁöÑÊÄÅÂ∫¶ÔºåÊ≤°ÊúâÂØπÊúÄÂºÄÂßãÁöÑÈúÄÊ±ÇÊúâÁªÜËá¥ÁöÑÂàÜÊûê„ÄÇÊãøÁùÄÂÆ¢Êà∑ÁªôÁöÑÊñáÊ°£Ôºå‰ª•‰∏∫Â∞±ÊòØÂÖ®ÈÉ®„ÄÇÂØπÁùÄÂ§ßÊ°ÜÈ¢Ñ‰º∞Êó∂Èó¥ÔºåÊä±ÁùÄ„Äé‰∏§‰∏™ÊúàÂêéËÇØÂÆöËÉΩÂπ≤ÂÆå„ÄèÁöÑÂÇªÈÄºÂøÉÁêÜÔºåÁªìÊûúÊØèÊ¨°Èù¢ÂØπ‰∏ÄÂùóÊñ∞ÂäüËÉΩÔºåÈÉΩËÉΩÁúãÂà∞‰∏ÄÊ£µËãçÂ§©Â§ßÊ†ë‰ªéÊñáÊ°£ÊãîÂú∞ËÄåËµ∑ÔºåÊûùÁπÅÂè∂ËåÇÊêûÂæóÊàëÁÑ¶Â§¥ÁÉÇÈ¢ù„ÄÇÂª∂ÊúüÔºå‰∏çÊñ≠Âú∞Âª∂ÊúüÔºåËÄΩËØØ‰∫ÜËá™Â∑±Â§™Â§öËÆ°ÂàíÔºåÂà∞ÊúÄÁªàÂÆåÊàêËä±‰∫ÜÊàë 124 ‰∏™Â∑•‰ΩúÊó•Ôºå‰ª•ÂèäÊï∞‰∏çÊ∏ÖÂ§öÂ∞ëÁÑ¶ËôëÁöÑÊó∂ÂÖâ„ÄÇÂπ¥Â∞ëÊó†Áü•Ôºå simple naive„ÄÇ‰∏¥ËøëÂ∞æÂ£∞ÔºåÊàëÂèàÊµèËßà‰∫Ü‰∏ÄÈÅçÊúÄÂàùÁöÑÊñáÊ°£ÔºåÂ•ΩÂÉèÂπΩÈªòÊïÖ‰∫ãÔºåÂè™ÊòØÁúº‰∏≠Â∏¶Ê≥™„ÄÇ</p>

<p>Êï¥‰ΩìÊó∂Èó¥ÁöÑÈîôËØØÂÆâÊéí„ÄÇ‰πãÂâçÊúâËØªÂà∞ËøáÔºåÂ¶ÇÊûúËÆ°ÂàíÂçäÂπ¥ÁöÑËΩØ‰ª∂ÂºÄÂèëÂë®ÊúüÔºåÈÇ£ÊØîËæÉÂêàÁêÜÁöÑÊó∂Èó¥ÂÆâÊéí‰∏∫‰∏â‰∏™ÊúàÁ°ÆÂÆöÈúÄÊ±ÇÔºå‰∏Ä‰∏™ÊúàÁ≥ªÁªüËÆæËÆ°Ôºå‰∏Ä‰∏™ÊúàÂºÄÂèëÁºñÁ†ÅÔºå‰∏Ä‰∏™ÊúàÊµãËØï‰∏äÁ∫ø„ÄÇËÄåÊàëÂú®ÈúÄÊ±ÇÂ∞ö‰∏çÂÆåÂñÑÊòéÁ°ÆÁöÑÊÉÖÂÜµ‰∏ãÔºåÊâãÁóíÂºÄÂßãÁºñÁ†Å„ÄÇÁªìÊûú‰∏çÊñ≠‰∫ÜËß£Ôºå‰∏çÊñ≠ÊîπËøõÔºå‰∏çÊñ≠ÊòéÁ°ÆÈúÄÊ±ÇÔºå‰∏çÊñ≠Êé®ÂÄíÈáçÂÜô„ÄÇÁ≤óÁï•È¢Ñ‰º∞ÔºåÊàëÂ§öËä±‰∫Ü‰∏ÄÂÄçÁöÑÊó∂Èó¥ÂíåÂøÉÊÄùÂú®‰∏çÂøÖË¶ÅÁöÑ‰ª£Á†Å‰∏ä„ÄÇÊØ´‰∏çË∞¶ËôöÁöÑËØ¥ÔºåÊàëÂÜô‰∫Ü‰∏ÄÊâãÂ±é‰ª£Á†Å„ÄÇ</p>

<p>Ê≤üÈÄöÁöÑÂõ∞Èöæ„ÄÇÊÄé‰πàË∑üÂÆ¢Êà∑ÊúâÊïàÊ≤üÈÄöÔºå‰ªé‰ªñ‰ª¨ÊîØÁ¶ªÁ†¥Á¢éÁöÑÊèèËø∞‰∏≠ÊâæÂà∞‰∫ßÂìÅÁöÑÈúÄÊ±ÇÁÇπÔºüÂ¶Ç‰ΩïÂª∫Á´ã‰∏ÄÂ•óÊúâÊïàÁöÑÂèçÈ¶àÊú∫Âà∂ÔºåËÆ©ÂÆ¢Êà∑ÂíåËá™Â∑±ÁöÑÊó∂Èó¥‰∫í‰∏çÊâìÊâ∞Âèà‰øùËØÅÊ≤üÈÄöÈ°∫ÁïÖÔºüÂ¶Ç‰ΩïÊúâÊïàÂú∞Ë°®ËææÊÉÖÁª™ÔºåËÄå‰∏çÊòØÂ∏¶ÁùÄÊÉÖÁª™Ë°®ËææÔºüÊàëÂú®‰∏ÄÊ≠•Ê≠•Êë∏Á¥¢Ôºå‰ΩÜÂßãÁªàÊâæ‰∏çÂà∞ best practice„ÄÇÂØπ‰∫éÊú¨Êù•ÂÜÖÂêëÁöÑÊàëÔºåÂ•ΩÂ§öÊó∂ÂÄôÊàëÈÄâÊã©Áî®Â§ö‰ªòÂá∫Êù•‰ª£ÊõøÂ∞ëÊ≤üÈÄöÔºåÂ§ö‰πàÈîôËØØÁöÑÂÅöÊ≥ïÔºåÊàëÂ∑≤Ê∑±Êúâ‰Ωì‰ºö„ÄÇ</p>

<p>ÊúâÂÄ∫ÂøÖËøòÔºå‰ΩÜÊòØÊàë‰ª¨ËØ•ÊÄé‰πàÂéªÂÆö‰πâÂÄ∫ÔºüÊúâ‰∫õÊó∂ÂÄôÔºåÂú®ËÆæËÆ°ÂíåÁºñÁ†ÅÁöÑËøáÁ®ãÔºåËÑë‰∏≠Èó™Ëøá‰∏ÄÁßçËæπÁïåÊÉÖÂÜµÔºåÂõ†‰∏∫‰∏çÂú®ÈúÄÊ±Ç‰πã‰∏≠ÔºåÂ∞±ÊääÂÆÉÊöÇ‰∏îÊîæ‰∏ã„ÄÇ‰ΩÜÊòØÈúÄÊ±ÇÁöÑ‰∏çÊñ≠ÂèòÂåñÔºåÊàñËÄÖËØ¥Êàë‰ª¨ÂØπÈúÄÊ±Ç‰∏çÊñ≠ÊúâÊñ∞ÁöÑËÆ§ËØÜÔºåËøôÁßçËæπÁïåÊÉÖÂÜµÂèà‰ºöËπ¶Âá∫Êù•‰∫üÂæÖËß£ÂÜ≥„ÄÇÈÇ£‰πàÈóÆÈ¢òÂõûÂà∞ÊúÄÂàùÔºåË¶Å‰∏çË¶ÅÂ∞ÜËøôÁßçÊÉÖÂÜµ‰∏ÄÂπ∂Ëß£ÂÜ≥ÔºüÊàëÊöÇÊó∂ËÆ§ÂèØÁöÑÁ≠îÊ°àÊòØÔºå‰∏çËß£ÂÜ≥ÔºåÊª°Ë∂≥ÂΩì‰∏ãÁöÑÈúÄÊ±ÇÂç≥ÂèØÔºå‰ΩÜË¶Å‰∏∫ÈúÄÊ±ÇÂèòÂä®ÂÅö„ÄéÈÄÇÂΩì„ÄèÁöÑÈ¢ÑÁïô„ÄÇÊàë‰ª¨ÈÉΩÁü•ÈÅìËøáÂ∫¶‰ºòÂåñÊòØ‰∏áÊÅ∂‰πãÊ∫êÔºå‰ΩÜÊòØËøáÂ∫¶‰∏éÈÄÇÂΩì‰πü‰ªÖ‰ªÖ‰∏ÄÂøµ‰πãÂ∑Æ„ÄÇÂèØËÉΩÂè™ÊòØÁïô‰∏ã placeholderÔºå‰∏Ä‰∏™ NotImplementError Âç≥ÂèØËÆ©Êú™Êù•‰∏çÈÇ£‰πàÁãºÁãàÔºå‰ΩÜÊòØÈù¢ÂØπÁõ∏ÂØπÊ†πÂü∫ÁöÑËÆæËÆ°Â±ÇÈù¢ÁöÑÈóÆÈ¢òÔºåÂèàËØ•‰∏∫Êú™Êù•ÂÅöÂ§öÂ∞ë‰øùÁïôÂë¢Ôºü</p>

<p>ËøòÊúâ‰∫õÈóÆÈ¢òÔºåÊàë‰πü‰∏ÄÁõ¥Êä±ÊúâÊÄÄÁñë„ÄÇ</p>

<p>ÊòØÂê¶ÈúÄË¶ÅËÆ©ÂÆ¢Êà∑‰ªòÂá∫‰∏ÄÂÆöÁöÑËÆ§Áü•Êù•‰∫ÜËß£Á≥ªÁªüËÆæËÆ°ÔºüÂä™ÂäõÂÅöÂà∞ÂÇªÁìúÂåñÊìç‰ΩúÔºåDon‚Äôt let them thinkÔºåËøòÊòØÂØπÂü∫Á°ÄÁöÑËÆæËÆ°ÂÅöÁÆÄÂçïÁöÑËÆ≤Ëß£ÔºåËÆ©ÂÆ¢Êà∑Èù¢ÂØπÁâπÊÆäÊÉÖÂÜµËá™Ë°åÁÅµÊ¥ªËß£ÂÜ≥„ÄÇ</p>

<p>ÊúÄÁªàÂÆåÊàêÁöÑ‰∫ßÂìÅË¶ÅÂØπÂÆ¢Êà∑ÈúÄÊ±ÇÊîØÊåÅÂà∞‰ªÄ‰πàÁ®ãÂ∫¶ÔºüÂÆ¢Êà∑ÂæÄÂæÄÊÉ≥Ë¶ÅÁöÑÊòØ elixerÔºå‰∏Ä‰∏™‰∏áËÉΩÁöÑ‰∫ßÂìÅÔºåÊó¢Á¨¶Âêà‰ªñ‰ª¨ÂéüÊú¨ÁöÑÊÄùË∑ØÔºåÂèàËÉΩËß£ÂÜ≥ÊâÄÊúâÈóÆÈ¢ò„ÄÇËÄåÁé∞ÂÆûÂæÄÂæÄÊòØÔºåÊàë‰ª¨ÂÆö‰∏ãÊù°Êù°Ê°ÜÊ°ÜÊù•‰øùËØÅÊµÅÁ®ã„ÄÅÊï∞ÊçÆÁöÑÂáÜÁ°ÆÔºå‰ΩÜÊÄª‰ºöÂá∫Áé∞ÁâπÊÆäÊÉÖÂÜµ„ÄÇÂΩìÊúÄÁªà‰∫§‰ªò‰∫ßÂìÅÊó∂ÔºåÂà∞Â∫ïËØ•ÂØπÁâπÊÆäÊÉÖÂÜµÂÅöÂ§öÂ§ßÁ®ãÂ∫¶ÁöÑÊîØÊåÅÔºüÂπ∂‰∏îÔºåÊàëË∂äÂèëËÆ§ËØÜÂà∞‰∏Ä‰∏™ÊÆãÈÖ∑ÁöÑ‰∫ãÂÆûÔºå‰ªéÊó∂Èó¥ÁöÑËßíÂ∫¶ÁúãÔºåÂè™ÈúÄËä±Ë¥π 20% ÁöÑÊó∂Èó¥Â∞±ËÉΩÂÆåÊàê 80% ÁöÑÊ†áÂáÜÂäüËÉΩÔºåËÄå 80% ÁöÑÊó∂Èó¥ÈÉΩË¢´Áî®ÂéªÂ∫îÂØπÈÇ£‰∫õÁ¢æÂéã‰∏ÄÂàáÁöÑÁâπÊÆäÂ§ÑÁêÜ„ÄÇ</p>

<p>ÂõûÈ¶ñÊï¥‰∏™Â∑•‰ΩúËøáÁ®ãÔºåÈù¢ÂØπ‰∏çÊñ≠ÁöÑÂª∂ÊúüÔºåÊé®ËøüÂéüÊúâÁöÑÂÖ∂‰ªñËÆ°ÂàíÔºåËÆ©ÊàëÈù¢ÂØπÂæàÂ§ßÁöÑÂéãÂäõ„ÄÇÊØèÈöî‰∏ÄÊÆµÊó∂Èó¥ÈÉΩ‰ºö‰∏çÁî±Ëá™‰∏ªÁöÑÁÑ¶ËôëÔºåÈô∑ÂÖ•Ê∑±Ê∑±ÁöÑÊÅêÊÖå„ÄÇÂ•Ω‰∏çÂÆπÊòìÂæóÂà∞‰∏ÄÊÆµÂÅáÊúüÔºåÁªìÊûúÂè™ÊòØ‰ªé‰∏Ä‰∏™ÂùëË∑≥Âà∞Âè¶‰∏Ä‰∏™Âùë„ÄÇËØ¥Â•ΩÁöÑ Gap Year Ëá™Â∑±Âá∫ÂéªËµ∞‰∏ÄÂúàÔºåÁªìÊûúË¢´ÂúàÂú®‰∫ÜËá™Â∑±ÂÆ∂Èáå„ÄÇÊúãÂèãÈÉΩ‰ª•‰∏∫ÊàëÈÄçÈÅ•Ëá™Âú®ÔºåÊîæ‰∫ÜÂ§ßÂÅáÔºåÂè™ÊúâÊàëËá™Â∑±Ê∑±Áü•ËøôÂÖ∂‰∏≠ÁöÑËã¶Ê∂©„ÄÇÊó∂Èó¥Á¥ßËø´‰∏çÂÅúÊ≠áÔºåËøôÊòØÊàëÊúÄÂ§ßÁöÑÈöæËøá„ÄÇÂ¶Ç‰ΩïÂÖãÂà∂‰∏çËÆ©Ëá™Â∑±ËÆ°ÁÆóÊó∂Èó¥ÊàêÊú¨ÔºåÂ¶Ç‰ΩïËíôÈ™óËá™Â∑±‰ª•ÊúüÊúõÂú®‰ΩéÊî∂ÊïàÁöÑÂ∑•‰Ωú‰∏≠‰πüËÉΩÂæóÂà∞‰∫õËÆ∏ÁªèÈ™åÔºåÂ¶Ç‰ΩïËÆ©Ëá™Â∑±‰øùÊåÅÁßØÊûÅÊÄÅÂ∫¶ÔºåÁ∫µ‰ΩøÂøÉÈáåÂÜçÊÄ•Ë°åÂä®‰πü‰∏çËÉΩÁùÄÊÄ•ÔºåÂè™ËÉΩÁÇπÊª¥ÂéªÂÅöÔºåËøáÂ•ΩÊØèÂ§©ÁÑ∂ÂêéÈªòÈªòÁ≠âÂæÖ„ÄÇËøô‰∏ÄÁ¢óÁ¢óÂÇªÈÄºÈ∏°Ê±§ÔºåÁÜ¨ÂïäÁÜ¨ÔºåÊàëÂπ≤ÁöÑÁóõÂø´„ÄÇ</p>

<p>Êú¨Êù•ÂÅáÊúüÂºÄÂßãÔºåÂØπËá™Â∑±ÊúÄÂ§ßÁöÑÊúüÊúõÊòØËÉΩÂ§üÂà©Áî®Â•ΩÊó∂Èó¥Â§öÁúã‰∫õÊäÄÊúØ‰π¶Á±çÔºå‰∏∫Ëá™Â∑±ÁßØÁ¥Ø‰∏Ä‰∫õÈáèÂèò„ÄÇËÆ©Â∑•‰ΩúÂ∏¶Âä®Ëá™Â∑±ÁöÑÁä∂ÊÄÅÔºåÁïô‰∏ãÁ©∫‰ΩôÊó∂Èó¥Â§öÁúã‰π¶Â≠¶‰π†„ÄÇ‰ΩÜÊòØÔºåË∂ÖÂá∫È¢ÑÊúüÁöÑÂ∑•‰ΩúÊó∂Èó¥ÔºåÂú®ÂçÅ‰∫åÊúàÂΩªÂ∫ïÁàÜÂèëÔºåÂøôÁªø„ÄÅÁÑ¶ËôëÔºåËÆ©ÊàëÂΩªÂ∫ïÊ∑πÊ≤°Âú®Â∑•‰Ωú‰∏≠„ÄÇÊ≤°ËÉΩÂú®ÊäÄÊúØ‰∏äÊúâÊâÄÁ™ÅÁ†¥ËÆ©ÊàëÊáäÊÇî‰∏çÂ∑≤„ÄÇÊï¥‰∏™ÂçäÂπ¥ÁöÑÊó∂Èó¥ÔºåÁ≤óÁï•‰º∞ËÆ°Âè™Êúâ 1/5 ÁöÑÊó∂Èó¥Ëä±Âú®‰∫ÜÊäÄÊúØÂ≠¶‰π†‰∏ä„ÄÇËÆ§ÁúüÁúã‰∫Ü„ÄäOperating Systems Three Easy Pieces„ÄãÔºå„ÄäHTTP - The Definitive Guide„ÄãÔºå‰ª•ÂèäÂá†‰∏™ Udacity ‰∏äÁöÑ Web ËØæÁ®ã„ÄÇÊ†áËÆ∞‰∫Ü‰∏ÄÂ†ÜÊÉ≥ÁúãÁöÑ‰π¶Á±çËØæÁ®ãÔºå‰ΩÜ‰πüÂè™ËÉΩÊé•ÂèóËøôÊúÄÁªàÂ∑ÆÂº∫‰∫∫ÊÑèÁöÑÂÆåÊàêÂ∫¶„ÄÇ</p>

<p><strong>ÊÄªÁªì‰∏éÂèçÊÄù</strong></p>

<p>Â¶ÇÊûúÈùûË¶ÅÊÄªÁªìËøô‰∏™ËøáÁ®ãËá™Â∑±ÂæóÂà∞‰ªÄ‰πàÂÆùË¥µÁªèÈ™åÔºåÈÇ£Èô§‰∫Ü‰∏äÈù¢ÁöÑÊÄùËÄÉÔºåÂú®Êó∂Èó¥ÁöÑÂÇ¨‰øÉ‰∏ãÔºåÊàëÈúÄË¶Å‰∏çÊñ≠ÂèçÊÄùÂ∑•‰ΩúËøáÁ®ãÔºåÊÉ≥ÊñπËÆæÊ≥ïÊèêÈ´òÂ∑•‰ΩúÊïàÁéá„ÄÇÂçÅ‰∫åÊúàÂàùÁöÑÊó∂ÂÄôÔºåÁúãÂà∞Áü•‰πéËøôÁØá<a href="http://www.zhihu.com/question/37167038">‰Ω†ÁöÑÊØèÊó•ÁßÅ‰∫∫ÊàêÈïøÊöóÂô®ÊòØ‰ªÄ‰πàÔºü</a>ÔºåËøûÂêåËá™Â∑±ÁöÑ‰∏™‰∫∫ÂÆûË∑µÔºåÂà∂ÂÆö‰∫Ü‰∏Ä‰ªΩ‰∏™‰∫∫ËÆ°Âàí„ÄÇ</p>

<blockquote>
  <p>ÊØèÊó•ËÆ°ÂàíÔºàGTDÔºâ</p>
</blockquote>

<ul>
  <li>ÊØèÂ§©ÂºÄÂßãÊó∂ÔºåÊåáÂÆö‰ªªÂä°ÂàóË°®ÔºõÁªìÊùüÊó∂ÔºåÂÆ°ÈòÖÂ∑≤ÂÆåÊàê‰∫ãÈ°πÔºåÂª∂ÊúüÊú™ÂÆåÊàêÂ∑•‰Ωú</li>
  <li>ÂÆåÊàêÂ∫¶ÁöÑÊ†áÂáÜÔºå‰∏çÂú®‰∫éÊ∏ÖÁ©∫‰ªªÂä°ÂàóË°®ÔºåËÄåÂú®‰∫éÊòØÂê¶ËææÂà∞Â∑•‰ΩúÊó∂Èïø</li>
</ul>

<p>‰ªéÂâçÊàëÁªèÂ∏∏Èù¢ÂØπËøôÊ†∑ÁöÑÊÉÖÂÜµÔºåÁù°ÂâçÊï¥ÁêÜ‰ªªÂä°ÂàóË°®ÔºåÁúãÁùÄ‰∏Ä‰∏§Êù°Âà∫ÁúºÁöÑÊú™ÂÆåÊàêËÆ°ÂàíÔºå‰º¥ÁùÄÊó†Â•à‰∏éÂ§±ÊúõÁù°Âéª„ÄÇÊàëÁ°Æ‰ø°ÔºåËøôÊòØËÆ©Êàë‰∏çÂø´‰πêÁöÑÈáçË¶ÅÂõ†Á¥†„ÄÇ‰ΩÜÊòØÊàëÊÖ¢ÊÖ¢ËÆ§ËØÜÂà∞ÔºåÂ¶ÇÊûúÂä™ÂäõËøòÊòØÂÆå‰∏çÊàêËÆ°ÂàíÔºåÂ§öÊï∞ÊÉÖÂÜµÂè™ÊòØÂØπËÆ°ÂàíÁöÑÈîôËØØÈ¢Ñ‰º∞„ÄÇÂ∑≤ÁÑ∂Â∞ΩÂäõÂéªÂÅö‰∫ÜÔºåÂ∞±‰∏çÂøÖÂüãÊÄ®Ëá™Â∑±„ÄÇËµ∑ÂàùÊàë‰πüÊÄÄÁñëÔºåËøôÊòØ‰∏çÊòØÂú®Èôç‰ΩéÊ†áÂáÜ‰ºÅÂõæÂéüË∞ÖËá™Â∑±„ÄÇÊàëÁöÑÁªìËÆ∫ÊòØÔºå‰∏ç„ÄÇËøôÊòØÂØπËá™Â∑±ËÉΩÂäõÁöÑÊ≠£Á°ÆËÆ§ËØÜÔºå‰øùÊåÅÂ•ΩÁöÑÂøÉÊÄÅÂéªÂÆåÊàêÊõ¥Â§öÁöÑ‰∫ãÊÉÖ„ÄÇÊâÄ‰ª•ÔºåÊàëÁé∞Âú®Â∞Ü‰ªªÂä°ÁöÑÂÆåÊàêÂ∫¶Ê†áÂáÜÂÆö‰πâ‰∏∫ÔºåÊòØÂê¶ËææÂà∞È¢ÑÂÆöÁöÑÂ∑•‰ΩúÊó∂Èïø„ÄÇÂ¶ÇÊûú‰øùÊåÅÈ´òÊïàÁöÑÂÆåÊàê‰∫ÜÂ∑•‰ΩúÊó∂Èó¥Ôºå‰ΩÜÊúÄÁªàËøòÊòØÂâ©‰∏ã‰∏Ä‰∏§Êù°Âà∫ÁúºÁöÑÊú™ÂÆåÊàêËÆ°ÂàíÔºåÊàë‰ºöË¥£Êó†ÊóÅË¥∑ÊääÂÆÉ‰ª¨Êé®ËøüÂà∞ÊòéÂ§©ÔºåÁÑ∂ÂêéÁªôËá™Â∑±‰∏Ä‰∏™ËÇØÂÆöÁöÑÈºìÂä±„ÄÇ</p>

<blockquote>
  <p>‰π†ÊÉØÂÖªÊàê</p>
</blockquote>

<p>‰π†ÊÉØÂàóË°®Ë¶ÅËûçÂÖ•Âà∞ÊØèÂ§©ÁöÑÊó∂Èó¥ÂÆâÊéí‰∏≠ÔºåÊó•ÁßØÊúàÁ¥Ø</p>

<ul>
  <li>ÂùöÊåÅÂÜôÊó•ËÆ∞ÂÅöÊÄªÁªì</li>
  <li>‰∏ÄÂë® 4-5 Ê¨°ÂÅ•Ë∫´</li>
  <li>ÊØèÂ§© 1 ÁÇπÂâçÁù°Ëßâ</li>
  <li>ÂùöÊåÅËØª‰π¶ 1h</li>
</ul>

<blockquote>
  <p>Êó∂Èó¥ÂÆâÊéíÔºàÂ∑•‰ΩúÊó•Ôºâ</p>
</blockquote>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/weekday_calender.png" alt="weekday_calendar" /></p>

<p>Ê±áÊÄª</p>

<ul>
  <li>Áù°Áú† 8.5 hÔºåÈ¢ÑÁïô 1 h ÁºìÂÜ≤ÔºàÁøªÊâãÊú∫ÔºåÁù°‰∏çÁùÄÁ≠âÔºâ</li>
  <li>ÊØèÂ§©‰∏âÈ§êÂõ∫ÂÆöÊó∂Èó¥ 1 h</li>
  <li>‰∏âÊÆµÂ∑•‰ΩúÊó∂Èó¥ÔºåÊØèÊÆµ 2.5 h„ÄÇÊ≥®ÊÑèË¶Å‰øùËØÅÂ∑•‰Ωú‰∏ìÊ≥®Â∫¶Ôºå‰ΩøÁî®Áï™ËåÑÂ∑•‰ΩúÊ≥ï„ÄÇ</li>
  <li>ÂÅ•Ë∫´Êó∂Èó¥ 2 h</li>
  <li>Ëá™Áî±Êó∂Èó¥ 3h</li>
</ul>

<p>Êó∂Èó¥ÁöÑË∞ÉÈÖç‰∏äÔºå<em>Â∞ΩÈáè</em>ÊåâÁÖßÊó∂Èó¥Ë°®„ÄÇÂ¶ÇÊúâÁâπÊÆäÊÉÖÂÜµÔºàÊèêÂâç‰ΩøÁî®Ëá™Áî±Êó∂Èó¥Á≠âÔºâÔºåÂèØËá™Ë°åË∞ÉÈÖçÔºå‰øùËØÅÊó∂Èó¥ÂÆåÊàêÂ∫¶Âç≥ÂèØ„ÄÇ</p>

<blockquote>
  <p>Êó∂Èó¥ÂÆâÊéíÔºàÂë®Êú´Ôºâ</p>
</blockquote>

<p>‰∏ç‰∏•Ê†ºÊåâÁÖßÂ∑•‰ΩúÊó•ÁöÑÊó∂Èó¥ÂÆâÊéíÔºå‰ΩÜÈúÄË¶Å‰øùËØÅ</p>

<ul>
  <li>Â∞±Êüê‰∏™ topic ÊÄªÁªì‰∏ÄÁØá evernoteÔºåÁßØÁ¥Ø‰∏ÄÂÆöÁ®ãÂ∫¶ÂÆåÊàê blog</li>
  <li>Ê∏ÖÁ©∫ÈÇÆ‰ª∂ÂàóË°®</li>
</ul>

<blockquote>
  <p>Â∑•ÂÖ∑</p>
</blockquote>

<p>ÂñÑÁî®Â∑•ÂÖ∑ËæÖÂä©Ëá™Â∑±ËøΩË∏™ËÆ∞ÂΩïÂ∑•‰ΩúÁä∂ÂÜµÔºö</p>

<ol>
  <li>OmnifocusÔºåGTD ‰ªªÂä°ÂàóË°®„ÄÇËøô‰∏™ App ÁÅµÊ¥ªÂà∞Âü∫Êú¨ÂèØ‰ª•Êª°Ë∂≥‰ªª‰ΩïËá™ÂÆö‰πâÈúÄÊ±Ç„ÄÇÊàëËá™Â∑±ÁöÑÂ∑•‰ΩúÊµÅÁ®ãÊòØÔºå‰øùÊåÅ‰∏§‰∏™Á™óÂè£ Inbox Âíå Project„ÄÇInbox ‰Ωú‰∏∫ quick entry Á≠âÂæÖÂΩíÁªìÊï¥ÁêÜÂà∞Êüê‰∏™ Project„ÄÇÊï¥‰Ωì‰∏äÈÄöËøá Due Date Êù•ÂÅöÊó∂Èó¥ÊääÊéß„ÄÇ</li>
  <li>FocusÔºåÊó∂Èó¥ËÆ∞ÂΩïÔºåËÆ©Ëá™Â∑±ÂÅö‰∏ÄÂêçÂø´‰πêÁöÑÊ†ëÂÜú„ÄÇËøô‰∏™ App Âõ†‰∏∫Êó∂Èó¥ÂèØÂèòÔºå‰∏çÁî®ÊïôÊù°ÁöÑÈÅµÂæ™Áï™ËåÑÂ∑•‰ΩúÊ≥ïÔºåËøúÁ¶ªÊâãÊú∫ÊòØÊãíÁªù‰∏ÄÂàáËØ±ÊÉëÁöÑÂºÄÂßã„ÄÇÂè¶Â§ñÔºåËÆ∞ÂΩïÂ∑•‰ΩúÊó∂Èó¥ÂØπÊàëÁöÑÊÑè‰πâÁõ∏ÂØπÊõ¥Â§ß„ÄÇËµ∑ÂàùÊàë‰ª•‰∏∫‰∏ÄÊï¥Â§©ÈöèÊó∂ÈÉΩÂú®Â∑•‰ΩúÔºå‰ΩÜÊòØÁ≤æÁ°ÆËÆ°ÁÆóÊâçÂèëÁé∞ÔºåÂáÄÊó∂Èó¥Âè™ÊúâÂõõÂà∞‰∫î‰∏™Â∞èÊó∂„ÄÇ‰∏çÊñ≠ÂèçÊÄùÂ∑•‰ΩúËøáÁ®ã„ÄÅÂêàÁêÜÂÆâÊéíÊó∂Èó¥ÔºåÊÖ¢ÊÖ¢ÔºåÂ∑ÖÂ≥∞Êó∂ÂÄôÂèØ‰ª•ÊääËá™Â∑±Êé®Âà∞ÊØèÂ§©‰πùÂà∞ÂçÅ‰∏™Â∞èÊó∂„ÄÇÊ∏ÖÊ•öÁü•ÈÅìÊó∂Èó¥ÈÉΩÂéª‰∫ÜÂì™ÔºåÊâçËÉΩÊÉ≥ÂäûÊ≥ïÂÅöÂá∫ÊèêÈ´ò„ÄÇ</li>
</ol>

<h3 id="section-1">ÊóÖË°å</h3>

<p>Â∏¶Áà∏Â¶àÂéªÊ≥∞ÂõΩÁé©‰∫Ü‰∏ÄÂúàÊòØËøôÂÅáÊúüÊúÄÈ™ÑÂÇ≤ÁöÑ‰∫ãÊÉÖ„ÄÇËæûËÅåÂâçÂ∞±ÊÉ≥ÂÆâÊéíËøôÊ†∑‰∏ÄÊ¨°ÊóÖË°åÔºå‰πùÊúà‰ªΩÁªà‰∫éÊàêË°å„ÄÇÊàëË¶ÅËá™ÁßÅÁöÑÊâøËÆ§ÔºåÊï¥‰∏™ËøáÁ®ãËá™Â∑±‰∏çÊòØÊúÄÂø´‰πêÁöÑÔºåÂâçÊúüÁöÑÂáÜÂ§áÔºåÂá∫ÂéªÊØèÂ§©ÁöÑÂÆâÊéíÔºåÂ•ΩÂ§öÊó∂ÂÄô‰∏çÊÉ≥Èù¢ÂØπÈ∫ªÁÉ¶Â∞±Âè™ËÉΩÂ§öËä±Èí±Ôºå‰ΩÜÊòØËøô‰∏™ËøáÁ®ã‰πüÂçïÂçï‰∏çÊòØ‰∏∫Ëá™Â∑±ÁöÑ„ÄÇÊàë‰∏ç‰ºöËÆ∞ÂæóÂì™ÈáåÁöÑÊôØËâ≤ÁâπÂà´ÊºÇ‰∫ÆÔºåÂè™ÊòØËÄÅÂ¶àÊó∂‰∏çÊó∂Ê¥ãÊ∫¢Âπ∏Á¶èË°®ÊÉÖÔºåËÄÅÁà∏ÂõûÊù•ÂêéÂºÄÂßãÊØèÂ§©Â≠¶‰π†Ëã±ËØ≠ÔºåËÆ©ÊàëÁõºÊúõÁùÄ‰∏ã‰∏ÄÊ¨°ÁöÑÂºÄÂßã„ÄÇ</p>

<p>ÂçäÂπ¥ÁöÑÊó∂Èó¥ÔºåÂéª‰∫Ü‰∏ÄÊ¨°‰∏äÊµ∑ÔºåÂíåÂ§ßÂ≠¶Â•≥ÂèãÈáçÂΩí‰∫éÂ•ΩÔºõÂéª‰∫Ü‰∏ÄÊ¨°Âåó‰∫¨ÔºåÂú®Âç†‰∏úÂíåÂ∞èÈ∏°ÂÆ∂ÁÜüÊÇâÁöÑÊéíÈ™®ÂíåÈ∏°ÁøÖÔºà‰ø®ÁÑ∂Êàê‰∫ÜÂú∞Èô™Ê†áÈÖçÔºâÔºõÂéª‰∫Ü‰∏ÄÊ¨°Ê≤àÈò≥‰∏§Ê¨°ÈïøÊò•ÔºåË∑üÊØèÂπ¥Âè™ËÉΩËøáÂπ¥ËßÅÈù¢ÁöÑÂ•ΩÂèãÔºåÂú®Êüê‰∏™Âπ≥Â∏∏ÁöÑÂë®Êú´Áõ∏ËÅöÔºåËøôÊÑüËßâÂ§™Â•Ω„ÄÇ</p>

<p>Êú¨Êù•ËØ¥Â•ΩÁöÑÈùíÂ≤õ„ÄÅÂé¶Èó®„ÄÅÈáçÂ∫ÜÂõ†‰∏∫Â∑•‰ΩúÊú™ËÉΩÊàêË°åÔºåÂ∏åÊúõÂπ¥ÂêéËøòÊúâÊú∫‰ºö„ÄÇ</p>

<h3 id="section-2">ÁîüÊ¥ª</h3>

<p>Ëøô‰∏§Âπ¥ÊúÄÂ∏∏ÊÄùËÄÉÁöÑ‰∏Ä‰∏™ÈóÆÈ¢òÂ∞±ÊòØÂ¶Ç‰ΩïÂÅöÂà∞ÂùöÊåÅ„ÄÇÊüêÁßçÁ®ãÂ∫¶ÔºåÊàëÊääÂùöÊåÅÂΩì‰ΩúÈÄöÂæÄÊàêÂäüÁöÑ‰∏áËÉΩÈí•Âåô„ÄÇ‰ªª‰Ωï‰∫ãÊÉÖÔºåÂîØÊúâÂùöÊåÅÊòØÊúÄÈöæ‰∏ÄÂÖ≥Ôºå‰πüÂîØÊúâÂùöÊåÅÊâçÊòØÊúÄË∏èÂÆûÂäûÊ≥ï„ÄÇËá™‰ªéÁúãÂÆå„Ää‰π†ÊÉØÁöÑÂäõÈáè„ÄãÔºåÊàëÊÑøÊÑèÁõ∏‰ø°‰π†ÊÉØÂÖªÊàêÊòØÂùöÊåÅÊúÄÊúâÊïàÁöÑÊâãÊÆµÔºåÊàë‰πüÊÑøÊÑèÊää‰π†ÊÉØÂΩìÂÅö‰∏ÄÁßçÊäïËµÑÔºåÂú®Êó∂Èó¥Êíí‰∏ãÁßçÂ≠êÔºåÈùôÂÄôÂÆÉÁîüÊ†πÂèëËäΩ„ÄÇ</p>

<p>ÂÅáÊúüÂºÄÂßãÔºåÁªôËá™Â∑±ÂÆö‰∏ã‰∏Ä‰∫õÂÖ≥‰∫é‰π†ÊÉØÁöÑÁõÆÊ†á„ÄÇÂõûËøáÂ§¥Êù•ÔºåËøô‰∫õËææÊàêÁöÑ‰π†ÊÉØ‰πüÊàê‰∫ÜÊàëËøôÂçäÂπ¥ÊúÄÂ§ßÁöÑÊî∂Ëé∑„ÄÇ</p>

<ul>
  <li>Áù°ÂâçÊó•ËÆ∞„ÄÇÂõ†‰∏∫ÊâãÈáåÊè°ÊúâÂ§ßÊääÊó∂Èó¥ÔºåÂæàÊÄïÂú®ÊùæÊáà‰∏é‰∏çËá™Áü•‰∏≠ËÆ©Êó∂Èó¥ÊÇÑÁÑ∂ÊµÅÈÄù„ÄÇËôΩÁÑ∂Â•ΩÂ§öÊó•Â≠êÂè™ÊòØËÆ∞‰∫Ü‰∫õÊ∞¥Ë¥¶Ôºå‰ΩÜÈáçË¶ÅÁöÑÊòØËÉΩËÆ©Ëá™Â∑±ÂÅú‰∏ãÊù•ÂõûÊÉ≥Ëøô‰∏ÄÂ§©ÂèëÁîü‰∫Ü‰ªÄ‰πàÔºåÊé•‰∏ãÂéªË¶ÅÂÅö‰ªÄ‰πà„ÄÇËøôÊòØÊàëÂùöÊåÅÊúÄÂ•ΩÁöÑ‰π†ÊÉØÔºå‰∏ÄÂ§©Ê≤°ÊúâËêΩ‰∏ãÔºåÊâÄ‰ª•ÊàëÊ∏ÖÊ•öÁü•ÈÅì‰ªäÂ§©ÊòØÂõûÂÆ∂Á¨¨199Â§©„ÄÇ</li>
  <li>ÂÅ•Ë∫´ÔºåÊÄªÂÖ±ÂÆåÊàê‰∫Ü91Â§©„ÄÇËøô‰∏™ËøáÁ®ãÁõ∏ÂØπËâ∞ËæõÔºåÊÄª‰ºöË¢´ÂêÑÁßç‰∫ãÊÉÖÊâìÊñ≠Ôºå‰æãÂ¶ÇÂøÉÊÉÖ„ÄÅÂ§©Ê∞î„ÄÅÂçàÈ•≠ÂêÉÊíëÁ≠âÁ≠â„ÄÇËØ¥Âà∞Â∫ïÔºåËøòÊòØÊÉ∞ÊÄß„ÄÇ‰ªéÂºÄÂßãÁúã‰π¶Â≠¶‰π†ÔºåÊ†πÊçÆËá™Ë∫´ÊåáÂÆöËÆ°ÂàíÔºåÂà∞‰∏çÊñ≠‰∫≤Ë∫´ËØïÈ™åÊÄªÁªìÂèçÊÄùÔºåËøôÊòØ‰∏Ä‰∏™‰∏çÊñ≠ÊîπËøõÁöÑÂéÜÁ®ãÔºåËá™Â∑±‰πüÊÄªÁªìÂá∫‰∏Ä‰∫õÁªèÈ™åÔºöÊâÄÊúâÂèØËÄÉËôëÂõ†Á¥†‰∏≠ÈÉΩÂü∫‰∫éÊúÄÈáçË¶Å‰∏ÄÁÇπÔºåÂæóÂéª„ÄÇÊàòËÉúËá™Â∑±ÊØîÊäÄÂ∑ßÈáçË¶Å„ÄÇ‰∫ÜËß£Âπ∂ÊâøËÆ§Ëá™Â∑±ÁöÑÊÉ∞ÊÄßÔºåÊâçËÉΩÊåáÂÆöÊõ¥Áé∞ÂÆûÁöÑËÆ°Âàí„ÄÇÊï¥‰∏™ËøáÁ®ãÊúÄÈöæÁöÑÊòØÂºÄÂßãÔºåÂíåÈöî‰∏ÄÊÆµÊó∂Èó¥ÂêéÈáçÊñ∞Êç°Ëµ∑„ÄÇËøûÁª≠ÁöÑÂéªÂíå‰∏çÂéªÈÉΩÂæàÂÆπÊòìÂ∏¶Âá∫ÊÉØÊÄß„ÄÇÊúÄÂ•ΩÁöÑÂÅ•Ë∫´Êàø‰∏çÊòØÂô®Ê¢∞Â•ΩÊöñÂíåÂèØ‰ª•Ê¥óÊæ°ÔºåËÄåÊòØ‰∫∫Â∞ë„ÄÇÁì∂È¢àÂæàÂø´‰ºöÊù•ÔºåÁü≠ÊúüÂÜÖÂä™ÂäõÂü∫Êú¨Áúã‰∏çÂà∞ÊïàÊûú„ÄÇÊâøËÆ§ÊÖ¢ÂäüÂ§´ÔºåËÆ©Êó∂Èó¥Ê£ÄÈ™å„ÄÇÈ•ÆÈ£üÂèØ‰ª•ÊéßÂà∂Ôºå‰ΩÜÊãíÁªùÈò∂ÊÆµÊÄßÈ•ÆÈ£üÊîπÂèòÔºåË¶ÅÊâæÂà∞ÈïøÊúüÂèØ‰æùËµñÁöÑÈ•ÆÈ£üÊñπÂºè„ÄÇËÇåËÇâÊúâ‰∏™ËßâÈÜíÁöÑËøáÁ®ãÔºåÈúÄË¶Å‰∏ÄÂÆöÁßØÁ¥ØÊâçËÉΩÊâæÂà∞Ê≠£Á°ÆÁöÑÂèëÂäõ„ÄÇÊúÄÁæéÂ•ΩÁöÑ‰∏ÄÂ§©ÊÄªÂú®‰∏çÁªèÊÑèÈó¥Âá∫Áé∞ÔºåÊù†ÈìÉÂ§öÂä†‰∏§ÁâáÈáçÈáèÔºåÁÜ¨Âá∫ÂèòÂåñ‰æø‰∏çÂÜçÁóõËã¶„ÄÇÊàëÂàöÂàöËµ∞Âà∞Ëøô‰∏ÄÊ≠•ÔºåÂÅ•Ë∫´Êàø‰ªäÂ§©ÂºÄÂßãÂÖ≥Èó®‰∫ÜÔºå‰∏Ä‰∏™Á§ºÊãúÂêéÊâçÂºÄÔºåÈ∫ªÁóπ„ÄÇ</li>
  <li>Êó©Áù°Êó©Ëµ∑„ÄÇ‰ªéÂ§ßÂ≠¶ÂºÄÂßãÂà∞‰∏äÁè≠‰∏âÂπ¥Ôºå‰ΩúÊÅØÂü∫Êú¨‰øùÊåÅÂú®ÂáåÊô®‰∏§ÁÇπÂà∞Êó©‰∏äÂçÅÁÇπ„ÄÇÂõûÂÆ∂ÂêéÂ∞ÜÁõÆÊ†áÂÆöÂú®‰∏ÄÁÇπÂâçÁù°ÔºåÂêéÊù•ÈÄêÊ≠•Ë∞ÉÊï¥‰∏∫ÂçÅ‰∫åÁÇπÂçäÔºåÂóØÔºå‰ºüÂ§ßÁöÑ‰∏ÄÂ∞èÊ≠•„ÄÇÊÖ¢ÊÖ¢ÂèëÁé∞ÔºåÂõ†‰∏∫ÊôöÁù°ÂèØ‰ª•ÊôöËµ∑ÔºåÊüêÁßçÁ®ãÂ∫¶‰æøÂ§±ÂéªÊó©Áù°ÁöÑÂä®Âäõ„ÄÇÊâÄ‰ª•ÔºåÊúÄËøë‰∏Ä‰∏™Â§öÊúàÂ∑≤Â∞ÜËµ∑Â∫äÊó∂Èó¥ÈîÅÊ≠ªÂú®ÂÖ´ÁÇπ„ÄÇË¶ÅËÆ©Ëá™Â∑±ÊâøÊãÖÊôöÁù°ÁöÑÂêéÊûúÔºåÊÉ≥Âà∞Á¨¨‰∫åÂ§©Ëµ∑Êù•ÂêéÁ•ûÊÉÖÁñ≤ÊÉ´„ÄÅÁù°ÁúºÊÉ∫Âø™ÔºåÈÇ£ÂçÅ‰∏ÄÁÇπÂçäÂ∞±ÂøÖÈ°ªÁªìÊùüÂ∑•‰ΩúÔºåÂçÅ‰∫åÁÇπÁúã‰∫Ü‰∏ÄÂçäÁöÑÁæéÂâß‰πüÂøÖÈ°ªÂÖ≥ÊéâÔºåÂçÅ‰∫åÁÇπÂçäÂè™ËÉΩÂÅúÊ≠¢Âà∑ÊâãÊú∫„ÄÇÂú®Áù°Ââç‰∫´ÂèóÁñ≤ÊÉ´„ÄÅÁäíÂä≥Ëá™Â∑±ÊòØ‰∏ÄÂ§©ÁöÑÁæéÂ•ΩÊó∂ÂÖâÔºåÊÆãÂøçÂú∞ÁªìÊùüËøô‰∏ÄÂàáÊâçÊòØÊúÄÈöæÁöÑ„ÄÇÈÄêÊ≠•ÔºåÊàëÂ∑≤ÁªèÊääÊØèÂ§©ÁöÑÈ´òÊïàÊó∂Èó¥Êå™Âà∞‰∫Ü‰∏äÂçàÔºåÂà∂ÂÆö‰∏ÄÂ§©ËÆ°ÂàíÔºåÊÄùËÄÉÁõ∏ÂØπÂõ∞ÈöæÁöÑÈóÆÈ¢òÔºåÂâ©‰∏ãÁöÑÂè™ÊòØÂéªÂÅöÂ∞±Â•Ω„ÄÇ</li>
</ul>

<p>Âú®Ëøô‰∏™ËøáÁ®ã‰ΩøÁî®‰∫Ü‰∏Ä‰∫õ App ‰Ωú‰∏∫ËæÖÂä©ÔºåÂú®Ê≠§Êé®ËçêÔºö</p>

<ol>
  <li>Day One - Êó•ËÆ∞ÔºåÁ®çÂæÆÊúâÁÇπË¥µ„ÄÇÂºÄÂßãÊó∂ÂÄôÂú®Âì™ÂÜôÊ†πÊú¨‰∏çÈáçË¶ÅÔºåÂè™ÊúâÂΩìÁ°ÆÂÆöËá™Â∑±‰ºö‰∏ÄÁõ¥Ëøô‰πàËÆ∞‰∏ãÂéªÂêéÔºåËøô‰∏™ App ÊâçÊòØÂÄºÂæóÁöÑ„ÄÇ</li>
  <li>Productive - Á≠æÂà∞Ôºå‰π†ÊÉØÂÖªÊàêÔºåÁªüËÆ°ÂÆåÊàêÂ∫¶</li>
  <li>Sleep Better - ËøΩË∏™Áù°Áú†Ë¥®Èáè</li>
</ol>

<h3 id="section-3">Â∞æÂ£∞</h3>

<p>Êàë‰∏çÁ°ÆÂÆöËøôÂçäÂπ¥ÁöÑ‰ºëÂÅáÊó∂Èó¥ÊòØÂê¶ÂÄºÂæóÔºåË∂≥Â§üÊúâÊÑè‰πâ„ÄÇÂèØËÉΩÈîôËøá‰∫Ü‰∏Ä‰∫õÂ•ΩÁöÑÂ∑•‰ΩúÊú∫‰ºöÔºåÊàë‰πüÊáäÊÇîËá™Â∑±Ê≤°ËÉΩÁúãË∂≥Â§üÁöÑ‰π¶Á±çËÆ©Ëá™Â∑±ÁöÑÊäÄÊúØÊúâÊâÄÈïøËøõÔºå‰∏Ä‰∫õÈ¢ÑÂÆöËÆ°Âàí‰πüÂú®ÂèòÂåñ‰∏≠Ê≤°ËÉΩÂÆûÁé∞„ÄÇ‰ΩÜ‰∏çÁÆ°ÊÄéÊ†∑ÔºåÊàëÁ°Æ‰ø°Ëá™Â∑±ÊòØÂú®Âä™ÂäõËÆ©Ëøô‰∏™ËøáÁ®ãÂèòÂæóÂÄºÂæóÔºåÊúâÊÑè‰πâ„ÄÇÂØπ‰∫éËøáÂæÄÁöÑÂèëÁîüÔºåÊàëÊ≤°ÂäûÊ≥ïÊîπÂèòÔºåÂè™ËÉΩÊä±ÁùÄÁßØÊûÅÁöÑÂøÉÊÄÅÔºåÁî®ÂøÉÊÄªÁªìÔºåÁÑ∂ÂêéÈù¢ÂØπÔºåÊÉ≥ÊñπËÆæÊ≥ïÊää‰πãÂêéÂÅöÂ•Ω„ÄÇËøáÂπ¥ÁöÑÊó∂Èó¥ÊòØ‰∏ÄÊÆµÁªàÁªìÔºåGithub ÁöÑ Streak ‰πüÂú®‰ªäÂ§©Êñ≠ÊéâÔºåÊàëË¶Å‰πê‰∫éÊé•ÂèóËøôÊÆµÁ©∫ÁôΩÁöÑ‰ºëÊÅØ„ÄÇ‰πãÂêéÊÄéÊ†∑ÊàëËøòÂú®ÊÄùËÄÉÔºå‰ΩÜ‰∏çÊñ≠Âä™ÂäõÔºå‰∏çÊñ≠ÊîπËøõÔºåËÆ©Ëá™Â∑±ÂèòÂ•ΩÊâçÊòØÊúÄÁªàÁöÑÂ∏åÊúõ„ÄÇ</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Review] Concurrency - Operating Systems Three Easy Pieces]]></title>
    <link href="http://blog.ifyouseewendy.com/blog/2015/12/26/review-concurrency-operating-systems-three-easy-pieces/"/>
    <updated>2015-12-26T11:33:57+08:00</updated>
    <id>http://blog.ifyouseewendy.com/blog/2015/12/26/review-concurrency-operating-systems-three-easy-pieces</id>
    <content type="html"><![CDATA[<table class="custom">
  <tbody>
    <tr>
      <td><strong>Book</strong></td>
      <td>Operating Systems: Three Easy Pieces</td>
    </tr>
    <tr>
      <td><strong>Author</strong></td>
      <td><a href="http://www.cs.wisc.edu/~remzi">Remzi H. Arpaci-Dusseau</a> and <a href="http://www.cs.wisc.edu/~dusseau">Andrea C. Arpaci-Dusseau</a></td>
    </tr>
    <tr>
      <td><strong>Link</strong></td>
      <td><a href="http://pages.cs.wisc.edu/~remzi/OSTEP/">pages.cs.wisc.edu/~remzi/OSTEP</a></td>
    </tr>
  </tbody>
</table>

<ul id="markdown-toc">
  <li><a href="#concurrency">Concurrency</a>    <ul>
      <li><a href="#chapter-26---introduction">Chapter 26 - Introduction</a></li>
      <li><a href="#chapter-27---interlude-thread-api">Chapter 27 - Interlude: Thread API</a></li>
      <li><a href="#chapter-28---locks">Chapter 28 - Locks</a></li>
      <li><a href="#chapter-29---lock-based-concurrent-data-structures">Chapter 29 - Lock-based Concurrent Data Structures</a></li>
      <li><a href="#chapter-30---condition-variables">Chapter 30 - Condition Variables</a></li>
      <li><a href="#chapter-31---semaphores">Chapter 31 - Semaphores</a></li>
      <li><a href="#chapter-32---common-concurrency-problems">Chapter 32 - Common Concurrency Problems</a></li>
      <li><a href="#chapter-33---event-based-concurrency-advanced">Chapter 33 - Event-based Concurrency (Advanced)</a></li>
    </ul>
  </li>
</ul>

<h1 id="concurrency">Concurrency</h1>

<h2 id="chapter-26---introduction">Chapter 26 - Introduction</h2>

<p><strong>Background</strong></p>

<p>With time sharing, we can take a single physical CPU and turn it into multiple virtual CPUs, thus enabling the illusion of multiple programs running at the same time, through time sharing.</p>

<p>With paging (base and bounds, segmentation), we can create the illusion of a large, private virtual memory for each process; this abstraction of the address space enables each program to behave as if it has its own memory when indeed the OS is secretly multiplexing address spaces across physical memory (and sometimes, disk).</p>

<p>But the abstraction of running program we use along is the process, and it‚Äôs a classic view of a single point of execution within a program. Now we introduce a new abstraction, thread. And  a <strong>multi-threaded</strong> program has more than one point of execution.</p>

<p>Perhaps another way to think of this is that each thread is very much like a separate process, except for one difference: they share the same address space and thus ca access the same data.</p>

<p><strong>Thread vs. Process</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-thread_vs_process.png" alt="os-thread_vs_process.png" /></p>

<p>Address space</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-thread_address_space.png" alt="os-thread_address_space.png" /></p>

<p><strong>Advantage</strong></p>

<p>Efficiency, as they share the same address space.</p>

<ul>
  <li>Save storage</li>
  <li>Easy context switching (no need to change page)</li>
</ul>

<p><strong>Issues</strong></p>

<ul>
  <li><strong>Sharing data</strong>, that of accessing shared variables and the need to support atomicity for critical sections.</li>
  <li><strong>Waiting for another</strong>, sleeping and waking interaction, where one thread must wait for another to complete some action before it continues.</li>
</ul>

<p><strong>Shared Data</strong></p>

<p>The heart of the problem is <strong>uncontrolled scheduling</strong>.</p>

<p>It is a wonderful and hard problem, and should make your mind hurt (a bit). If it doesn‚Äôt, then you don‚Äôt understand! Keep working until your head hurts; you then know you‚Äôre headed in the right directinn.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-thread_sharing_data.png" alt="os-thread_sharing_data.png" /></p>

<p><strong>Key Concurrency Terms</strong> (from Edsger Dijkstra)</p>

<p>A <strong>critical section</strong> is a piece of code that accesses a shared resource, usually a variable or data structure.</p>

<p>A <strong>race condition</strong> arises if multiple threads of execution enter the critical section at roughly the same time; both attempt to update the shared data structure, leading to a surprising (and perhaps un- desirable) outcome. The results depend on the timing execution of the code.</p>

<p>An <strong>indeterminate</strong> program consists of one or more races onditions; the output of the program varies from run to run, depending on which threads ran when. The outcome is thus not deterministic, something we usually expect from computer systems.</p>

<p>To avoid these problems, threads should use some kind of <strong>mutual exclusion primitives</strong>; doing so guarantees that only a single thread ever enters a critical section, thus avoiding racoes, and resulting in deterministic program outputs.</p>

<p><strong>Atomic</strong></p>

<p>Atomic operations are one of the most powerful underlying techniques in building computer systems.</p>

<p>The idea behind making a series of actions <strong>atomic</strong> is simply expressed with the phrase ‚Äúall or nothing‚Äù; it should either appear as if all of the actions you wish to group together occurred, or that none of them occurred, with no in-between state visible. Sometimes, the grouping of many actions into a single atomic action is called a <strong>transaction</strong>.</p>

<p>In our theme of exploring concurrency, we‚Äôll be using synchronization primitives to turn short sequences of instructions into atomic blocks of execution.</p>

<p><strong>The Wish For Atomicity</strong></p>

<p>Hardware guarantees the instructions is atomic, and provide a general set we call <strong>synchronisation primitives</strong> to ensure atomicity.</p>

<p>Hardware guarantees that the instructions execute atomically. It could not be interrupted mid-instruction, because that is precisely the guarantee we receive from the hardware: when an interrupt occurs, either the instruction has not run at all, or it has run to completion; there is no in-between state.</p>

<p>But, would we really want the hardware to support an ‚Äúatomic update of B-tree‚Äù instruction?</p>

<p>No. Thus, what we will instead do is ask the hardware for a few useful instructions upon which we can build a general set of what we call <strong>synchronization primitives</strong>. By using these hardware synchronization primitives, in combination with some help from the operating system, we will be able to build multi-threaded code that accesses critical sections in a synchronized and controlled manner, and thus reliably produces the correct result despite the challenging nature of concurrent execution.</p>

<p><strong>Why in OS Class?</strong></p>

<p>‚ÄúHistory‚Äù is the one-word answer; the OS was the first concurrent program, and many techniques were created for use within the OS. Later, with multi-threaded processes, application programmers also had to consider such things.</p>

<p>OS designers, from the very beginning of the introduction of the interrupt, had to worry about how the OS updates internal structures. Not surprisingly, page tables, process lists, file system structures, and virtually every kernel data structure has to be carefully accessed, with the proper synchronization primitives, to work correctly.</p>

<h2 id="chapter-27---interlude-thread-api">Chapter 27 - Interlude: Thread API</h2>

<p><strong>Guidelines</strong></p>

<p>There are a number of small but important things to remember when you use the POSIX thread library.</p>

<ul>
  <li><strong>Keep it simple</strong>. Above all else, any code to lock or signal between threads should be as simple as possible. Tricky thread interactions lead to bugs.</li>
  <li>Minimize thread interactions. Try to keep the number of ways in which threads interact to a minimum.</li>
  <li><strong>Each thread has its own stack</strong>. If you have a locally-allocated variable inside of some function a thread is exe- cuting, it is essentially private to that thread; no other thread can (easily) access it. To share data between threads, the values must be in the heap or otherwise some locale that is globally accessible.</li>
  <li><strong>Be careful with how you pass arguments to, and return values from, threads.</strong> In particular, any time you are passing a reference to a variable allocated on the stack, you are probably doing something wrong.</li>
  <li><strong>Check your return codes.</strong> Of course, in any C and UNIX program- ming you do, you should be checking each and every return code, and it‚Äôs true here as well.</li>
  <li><strong>Always use condition variables to signal between threads.</strong> While it is often tempting to use a simple flag, don‚Äôt do it.</li>
  <li><strong>Initialize locks and condition variables.</strong> Failure to do so will lead to code that sometimes works and sometimes fails in very strange ways.</li>
  <li><strong>Use the manual pages.</strong> On Linux, in particular, the pthread man pages (man -k pthread) are highly informative and discuss much of the nuances pre- sented here, often in even more detail.</li>
</ul>

<p><strong>Thread Creation</strong></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="c"><span class="line"><span class="cp">#include &lt;pthread.h&gt;</span>
</span><span class="line"><span class="kt">int</span> <span class="nf">pthread_create</span><span class="p">(</span><span class="n">pthread_t</span> <span class="o">*</span> <span class="kr">thread</span><span class="p">,</span>
</span><span class="line">                     <span class="k">const</span> <span class="n">pthread_attr_t</span> <span class="o">*</span>  <span class="n">attr</span><span class="p">,</span>
</span><span class="line">                     <span class="kt">void</span> <span class="o">*</span> <span class="p">(</span><span class="o">*</span><span class="n">start_routine</span><span class="p">)(</span><span class="kt">void</span><span class="o">*</span><span class="p">),</span>
</span><span class="line">                     <span class="kt">void</span> <span class="o">*</span>  <span class="n">arg</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li><code>thread</code>, is a pointer to a structure of type pthread t; we‚Äôll use this structure to interact with this thread</li>
  <li><code>attr</code>, is used to specify any attributes this thread might have. Some examples include setting the stack size or perhaps in- formation about the scheduling priority of the thread.</li>
  <li>The third argument is the most complex, but is really just asking: which function should this thread start running in? In C, we call this a function pointer, and this one tells us the following is expected: a function name (<code>start routine</code>), which is passed a single argument of type void * (as indicated in the parentheses after start routine), and which returns a value of type void * (i.e., a void pointer).</li>
  <li><code>arg</code>, is exactly the argument to be passed to the function where the thread begins execution.</li>
</ul>

<p><strong><em>Why do we need these void pointers?</em></strong></p>

<p>Having a void pointer as an argument to the function start routine allows us to pass in any type of argument; having it as a return value allows the thread to return any type of result.</p>

<p><strong>Thread Completion</strong></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="c"><span class="line"><span class="kt">int</span> <span class="nf">pthread_join</span><span class="p">(</span><span class="n">pthread_t</span> <span class="kr">thread</span><span class="p">,</span> <span class="kt">void</span> <span class="o">**</span><span class="n">value_ptr</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li><code>thread</code> is used to specify which thread to wait for</li>
  <li><code>value_ptr</code> is a pointer to the return value you expect to get back. Because the routine can return anything, it is defined to return a pointer to void; because the pthread join() routine changes the value of the passed in argument, you need to pass in a pointer to that value, not just the value itself.</li>
</ul>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-thread_waiting_demo.png" alt="os-thread_waiting_demo.png" /></p>

<p>Note that one has to be extremely careful with how values are returned from a thread. In particular, never return a pointer which refers to something allocated on the thread‚Äôs call stack.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-thread_waiting_demo_wrong.png" alt="os-thread_waiting_demo_wrong.png" /></p>

<p>However, when it returns, the value is automatically deallocated (that‚Äôs why the stack is so easy to use, after all!), and thus, passing back a pointer to a now deallocated variable will lead to all sorts of bad results.</p>

<p>Not all code that is multi-threaded uses the join routine. For example, a multi-threaded web server might create a number of worker threads, and then use the main thread to accept requests and pass them to the workers, indefinitely. Such long-lived programs thus may not need to join.</p>

<p><strong>Locks</strong></p>

<p>Providing mutual exclusion to a critical section via locks.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="c"><span class="line"><span class="kt">int</span> <span class="nf">pthread_mutex_lock</span><span class="p">(</span><span class="n">pthread_mutex_t</span> <span class="o">*</span><span class="n">mutex</span><span class="p">);</span>
</span><span class="line"><span class="kt">int</span> <span class="nf">pthread_mutex_unlock</span><span class="p">(</span><span class="n">pthread_mutex_t</span> <span class="o">*</span><span class="n">mutex</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>When you have a region of code you realize is a critical section, and thus needs to be pro- tected by locks in order to operate as desired.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
</pre></td><td class="code"><pre><code class="c"><span class="line"><span class="n">pthread_mutex_t</span> <span class="n">lock</span><span class="p">;</span>
</span><span class="line">
</span><span class="line"><span class="n">Pthread_mutex_init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">lock</span><span class="p">);</span>
</span><span class="line">
</span><span class="line"><span class="n">Pthread_mutex_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">lock</span><span class="p">);</span>
</span><span class="line"><span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span> <span class="c1">// or whatever your critical section is</span>
</span><span class="line"><span class="n">Pthread_mutex_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">olock</span><span class="p">);</span>
</span><span class="line">
</span><span class="line"><span class="c1">// Always check for failure</span>
</span><span class="line"><span class="kt">void</span> <span class="nf">Pthread_mutex_init</span><span class="p">(</span><span class="n">pthread_mutex_t</span> <span class="o">*</span><span class="n">mutex</span><span class="p">)</span> <span class="p">{</span>
</span><span class="line">    <span class="kt">int</span> <span class="n">rc</span> <span class="o">=</span> <span class="n">pthread_mutex_init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">lock</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">);</span> <span class="c1">// dynamic initialisation, or PTHREAD_MUTEX_INITIALIZER</span>
</span><span class="line">    <span class="n">assert</span><span class="p">(</span><span class="n">rc</span> <span class="o">==</span> <span class="mi">0</span><span class="p">);</span> <span class="c1">// always check success!</span>
</span><span class="line"><span class="p">}</span>
</span><span class="line"><span class="kt">void</span> <span class="nf">Pthread_mutex_lock</span><span class="p">(</span><span class="n">pthread_mutex_t</span> <span class="o">*</span><span class="n">mutex</span><span class="p">)</span> <span class="p">{</span>
</span><span class="line">    <span class="kt">int</span> <span class="n">rc</span> <span class="o">=</span> <span class="n">pthread_mutex_lock</span><span class="p">(</span><span class="n">mutex</span><span class="p">);</span>
</span><span class="line">    <span class="n">assert</span><span class="p">(</span><span class="n">rc</span> <span class="o">==</span> <span class="mi">0</span><span class="p">);</span>
</span><span class="line"><span class="p">}</span>
</span><span class="line"><span class="kt">void</span> <span class="nf">Pthread_mutex_unlock</span><span class="p">(</span><span class="n">pthread_mutex_t</span> <span class="o">*</span><span class="n">mutex</span><span class="p">)</span> <span class="p">{</span>
</span><span class="line">    <span class="kt">int</span> <span class="n">rc</span> <span class="o">=</span> <span class="n">pthread_mutex_unlock</span><span class="p">(</span><span class="n">mutex</span><span class="p">);</span>
</span><span class="line">    <span class="n">assert</span><span class="p">(</span><span class="n">rc</span> <span class="o">==</span> <span class="mi">0</span><span class="p">);</span>
</span><span class="line"><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><strong>Condition Variables</strong></p>

<p>Condition variables are useful when some kind of signaling must take place between threads, if one thread is waiting for another to do something before it can continue.</p>

<p>To use a condition variable, one has to in addition have a lock that is associated with this condition. When calling either of the above routines, this lock should be held.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="c"><span class="line"><span class="kt">int</span> <span class="nf">pthread_cond_wait</span><span class="p">(</span><span class="n">pthread_cond_t</span> <span class="o">*</span><span class="n">cond</span><span class="p">,</span> <span class="n">pthread_mutex_t</span> <span class="o">*</span><span class="n">mutex</span><span class="p">);</span>
</span><span class="line"><span class="kt">int</span> <span class="nf">pthread_cond_signal</span><span class="p">(</span><span class="n">pthread_cond_t</span> <span class="o">*</span><span class="n">cond</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>pthread_cond_wait(), puts the calling thread to sleep, ad thus waits for some other thread to signal it, usually when something in the program has changed that the now-sleeping thread might care about.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="c"><span class="line"><span class="n">pthread_mutex_t</span> <span class="n">lock</span> <span class="o">=</span> <span class="n">PTHREAD_MUTEX_INITIALIZER</span><span class="p">;</span>
</span><span class="line"><span class="n">pthread_cond_t</span>  <span class="n">cond</span> <span class="o">=</span> <span class="n">PTHREAD_COND_INITIALIZER</span><span class="p">;</span>
</span><span class="line"><span class="n">Pthread_mutex_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">lock</span><span class="p">);</span>
</span><span class="line"><span class="k">while</span> <span class="p">(</span><span class="n">ready</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
</span><span class="line">    <span class="n">Pthread_cond_wait</span><span class="p">(</span><span class="o">&amp;</span><span class="n">cond</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">lock</span><span class="p">);</span>
</span><span class="line"><span class="n">Pthread_mutex_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">lock</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>After initialization of the relevant lock and condition, a thread checks to see if the variable ready has yet been set to something other than zero. If not, the thread simply calls the wait routine in order to sleep until some other thread wakes it.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="c"><span class="line"><span class="n">Pthread_mutex_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">lock</span><span class="p">);</span>
</span><span class="line"><span class="n">ready</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
</span><span class="line"><span class="n">Pthread_cond_signal</span><span class="p">(</span><span class="o">&amp;</span><span class="n">cond</span><span class="p">);</span>
</span><span class="line"><span class="n">Pthread_mutex_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">lock</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Notice 1</p>

<p>When signaling (as well as when modifying the global variable ready), we always make sure to have the lock held. This ensures that we don‚Äôt accidentally introduce a race condition into our code.</p>

<p>Notice 2</p>

<p>Notice that the wait call takes a lock as its second parameter, whereas the signal call only takes a condition. The reason for this difference is that the wait call, in addition to putting the calling thread to sleep, releases the lock when putting said caller to sleep.</p>

<p>Imagine if it did not: how could the other thread acquire the lock and signal it to wake up? However, before returning after being woken, the pthread_cond_wait() re-acquires the lock, thus ensuring that any time the waiting thread is running between the lock acquire at the beginning of the wait sequence, and the lock release at the end, it holds the lock.</p>

<p>Notice 3</p>

<p>The waiting thread re-checks the condition in a while loop, instead of a simple if statement. Although it rechecks the condition (perhaps adding a little overhead), there are some pthread implementations that could spuriously wake up a waiting thread; in such a case, without rechecking, the waiting thread will continue thinking that the condition has changed even though it has not.</p>

<p>Notice 4</p>

<p>Don‚Äôt ever use these ad hoc synchronisations.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="c"><span class="line"><span class="c1">// waitingnwhile (ready == 0)</span>
</span><span class="line">    <span class="p">;</span> <span class="c1">// spin</span>
</span><span class="line">
</span><span class="line"><span class="c1">// signaling</span>
</span><span class="line"><span class="n">ready</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>First, it performs poorly in many cases (spinning for a long time just wastes CPU cycles). Second, it is error prone.</p>

<p><strong>Others</strong></p>

<p>On the link line, you must also explicitly link with the pthreads library, by adding the -pthread flag.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">prompt&gt; gcc -o main main.c -Wall -pthread
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="chapter-28---locks">Chapter 28 - Locks</h2>

<p><strong>The Basic Idea</strong></p>

<p>Programmers annotate source code with locks, putting them around critical sections, and thus ensure that any such critical section executes as if it were a single atomic instruction.</p>

<p>This lock variable (or just ‚Äúlock‚Äù for short) holds the state of the lock at any instant in time. It is either available (or unlocked or free) and thus no thread holds the lock, or acquired (or locked or held), and thus exactly one thread holds the lock and presumably is in a critical section.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-lock_demo.png" alt="os-lock_demo.png" /></p>

<p>In general, we view thre
ads as entities created by the programmer but scheduled by the OS, in any fashion that the OS chooses. Locks yield some of that control back to the programmer; by putting a lock around a section of code, the programmer can guarantee that no more than a single thread can ever be active within that code.</p>

<p>The name that the <strong>POSIX</strong> library uses for a lock is a <strong>mutex</strong>, as it is used to provide <strong>mutual exclusion</strong> between threads.</p>

<p><strong>Building A Lock</strong></p>

<p>Some hardware support (in the form of a more powerful instruction) plus some operating system support (e.g., in the form of park() and unpark() primitives on Solaris, or futex on Linux).</p>

<p><strong>Evaluating Locks</strong></p>

<ul>
  <li>The first is whether the lock does its basic task, which is to provide <strong>mutual exclusion</strong>. Basically, does the lock work, preventing multiple threads from entering a critical section?</li>
  <li>The second is <strong>fairness</strong>. Does each thread contending for the lock get a fair shot at acquiring it once it is free?</li>
  <li>The final criterion is <strong>performance</strong>, specifically the time overheads added by using the lock.</li>
</ul>

<p><strong>Controlling Interrupts</strong></p>

<p>Turning off interrupts is only used in limited contexts as a mutual-exclusion primitive. For example, in some cases an operating system itself will use interrupt masking to guarantee atomicity when accessing its own data structures, or at least to prevent certain messy interrupt handling situations from arising. This usage makes sense, as the trust issue disappears inside the OS, which always trusts itself to perform privileged operations anyhow.</p>

<p><strong>Plain Solution</strong></p>

<p>Without hardware support, just use a flag.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-lock_plain_solution.png" alt="os-lock_plain_solution.png" /></p>

<p>The core issue is that the testing and setting part can be interrupted by context switch, and both thread enters the critical section.</p>

<p>You should get used to this thinking about concurrent programming. Maybe pretend yourself as a <strong>malicious scheduler</strong> to understand the concurrent execution.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-lock_no_mutal_exclusion.png" alt="os-lock_no_mutal_exclusion.png" /></p>

<p><strong>Test And Set (Atomic Exchange)</strong></p>

<p>Let hardware provides a transaction-like instrument to ensure the sequence of operations is performed <strong>atomically</strong>.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-lock_test_and_set.png" alt="os-lock_test_and_set.png" /></p>

<p>The key, of course, is that this sequence of operations is performed atomically. The reason it is called ‚Äútest and set‚Äù is that it enables you to ‚Äútest‚Äù the old value (which is what is returned) while simultaneously ‚Äúsetting‚Äù the memory location to a new value; as it turns out, this slightly more powerful instruction is enough to build a simple spin lock</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-lock_spin_lock_by_test_and_set.png" alt="os-lock_spin_lock_by_test_and_set.png" /></p>

<p>By making both the test (of the old lock value) and set (of the new value) a single atomic operation, we ensure that only one thread acquires the lock.</p>

<p><strong>Compare-And-Swap</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-lock_compare_and_swap.png" alt="os-lock_compare_and_swap.png" />
<img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-lock_spin_lock_by_compare_and_swap.png" alt="os-lock_spin_lock_by_compare_and_swap.png" /></p>

<p>compare-and-swap is a more powerful instruction than test-and-set. We will make some use of this power in the future when we briefly delve into <strong>wait-free synchronisation</strong>.</p>

<p><strong>Load-Linked and Store-Conditional</strong></p>

<p>Some platforms provide a pair of instructions that work in concert to help build critical sections. On the MIPS architecture, for example, the load-linked and store-conditional instructions can be used in tandem to build locks and other concurrent structures.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-lock_load_linked_store_conditional.png" alt="os-lock_load_linked_store_conditional.png" />
<img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-lock_spin_lock_by_load_linked_store_conditional.png" alt="os-lock_spin_lock_by_load_linked_store_conditional.png" /></p>

<p><strong>Fetch-And-Add</strong></p>

<p>Fetch-and-add atomically increments a value while returning the old value at a particular address.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-lock_fetch_and_add.png" alt="os-lock_fetch_and_add.png" /></p>

<p>Fetch-and-add could build a <em>ticket lock</em>, this solution uses a ticket and turn variable in combination to build a lock. The basic operation is pretty simple: when a thread wishes to acquire a lock, it first does an atomic fetch-and-add on the ticket value; that value is now considered this thread‚Äôs ‚Äúturn‚Äù (myturn). The globally shared lock-&gt;turn is then used to determine which thread‚Äôs turn it is; when (myturn == turn) for a given thread, it is that thread‚Äôs turn to enter the critical section. It has the advantage of the fairness, ensures progress for all threads. Once a thread is assigned its ticket value, it will be scheduled at some point in the future</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-lock_ticket_lock_by_fetch_and_add.png" alt="os-lock_ticket_lock_by_fetch_and_add.png" /></p>

<p><strong>Spin Lock</strong></p>

<p>We use a while loop to endlessly check the value of a flag, this technique is known as <strong>spin-waiting</strong>. Spin-waiting wastes time waiting for another thread to release a lock. The waste is exceptionally high on a uniprocessor, where the thread that the waiter is waiting for cannot even run (at least, until a context switch occurs)!</p>

<p><strong>Spin lock</strong> is the simplest type of lock to build, and simply spins, using CPU cycles, until the lock becomes available. To work correctly on a single processor, it requires a <strong>preemptive scheduler</strong>. (Remember that SJF is non-preemptive, but STCF is preemptive, which means permitting one thread to be interrupted).</p>

<p>Evaluating</p>

<ul>
  <li>‚àö correctness, the spin lock only allows a single thread to enter the critical section at a time.</li>
  <li>X fairness, spin locks don‚Äôt provide any fairness guarantees. Indeed, a thread spinning may spin forever, under contention. Spin locks are not fair and may lead to starvation.</li>
  <li>X performance, bad in the single CPU case. The problem gets worse with N threads contending for a lock; N ‚àí 1 time slices may be wasted in a similar manner, simply spinning and waiting for a single thread to release the lock.</li>
</ul>

<p><strong>Avoid Spinning by Yield</strong></p>

<blockquote>
  <p>‚Äújust yield, baby!‚Äù</p>
</blockquote>

<p>Hardware support alone cannot solve the problem. We‚Äôll need OS support too! Assume an operating system primitive <strong>yield()</strong> which a thread can call when it wants to give up the CPU and let another thread run. A thread can be in one of three states (running, ready, or blocked); yield is simply a system call that moves the caller from the <strong>running</strong> state to the <strong>ready</strong> state, and thus promotes another thread to running. Thus, the yielding process essentially <strong>deschedules</strong> itself.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-lock_with_test_and_set_and_yield.png" alt="os-lock_with_test_and_set_and_yield.png" /></p>

<p>This approach eliminates the spinning time, but still costly when context switching. And we have not tackled the starvation problem at all. A thread may get caught in an endless yield loop while other threads repeatedly enter and exit the critical section.</p>

<p><strong>Avoid Spnning by Queues</strong></p>

<p>The scheduler determines which thread runs next; if the scheduler makes a bad choice, a thread runs that must either spin waiting for the lock (our first approach), or yield the CPU immediately (our second approach). Either way, there is potential for waste and no prevention of starvation.</p>

<p>Thus, we must explicitly exert some control over who gets to acquire the lock next after the current holder releases it.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-lock_with_test_and_set_and_yield_and_queue.png" alt="os-lock_with_test_and_set_and_yield_and_queue.png" /></p>

<p>This approach thus doesn‚Äôt avoid spin-waiting entirely; a thread might be interrupted while acquiring or releasing the lock, and thus cause other threads to spin-wait for this one to run again. However, the time spent spinning is quite limited (just a few instructions inside the lock and unlock code, instead of the user-defined critical section), and thus this approach may be reasonable.</p>

<p>With just the wrong timing, a thread will be about to park, assuming that it should sleep until the lock is no longer held. A switch at that time to another thread (say, a thread holding the lock) could lead to trouble, for example, if that thread then released the lock. The subsequent park by the first thread would then sleep forever (potentially). This problem is sometimes called the <strong>wakeup/waiting race</strong>.</p>

<p>Solaris solves this problem by adding a third system call: <strong>setpark()</strong>. By calling this routine, a thread can indicate it is about to park. If it then happens t be interrupted and another thread calls unpark before park is actually called, the subsequent park returns immediately instead of sleeping.</p>

<p>You might also notice the interesting fact that the flag does not get set back to 0 when another thread gets woken up. Why is this? Well, it is not an error, but rather a necessity! When a thread is woken up, it will be as if it is returning from park(); however, it does not hold the guard at that point in the code and thus cannot even try to set the flag to 1. Thus, we just pass the lock directly from the thread releasing the lock to the next thread acquiring it; flag is not set to 0 in-between.</p>

<p><strong>Linux Support</strong></p>

<p>Linux provides something called a <strong>futex</strong> which is similar to the Solaris interface but provides a bit more in-kernel functionality. Specifically, each futex has associated with it a specific physical memory location; associated with each such memory location is an in-kernel queue.</p>

<ul>
  <li><code>futex_wait(address, expected)</code> puts the calling thread to sleep, assouming the value at address is equal to expected. If it is not equal, the call returns immediately.</li>
  <li><code>futex_wake(address)</code> wakes one thread that is wait- ing on the queue.</li>
</ul>

<p>Linux approach has the flavor of an old approach that has been used on and off for years, , and is now referred to as a <strong>two-phase lock</strong>. A two-phase lock realizes that spinning can be useful, particularly if the lock is about to be released. So in the first phase, the lock spins for a while, hoping that it can acquire the lock. However, if the lock is not acquired during the first spin phase, a second phase is entered, where the caller is put to sleep, and only woken up when the lock becomes free later.</p>

<h2 id="chapter-29---lock-based-concurrent-data-structures">Chapter 29 - Lock-based Concurrent Data Structures</h2>

<p><strong>Background</strong></p>

<p>Adding locks to a data structure to make it usable by threads makes the structure <strong>thread safe</strong>. There is always a standard method to make a concurrent data structure: add a big lock. But sometimes we need to ensure the scalability.</p>

<p>To evaluate the concurrent data structures, theres are two factors to concern:</p>

<ul>
  <li>Correctness</li>
  <li>Performance. MORE CONCURRENCY ISN‚ÄôT NECESSARILY FASTER. If the scheme you design adds a lot of overhead (for example, by acquiring and releasing locks frequently, instead of once), the fact that it is more concurrent may not be important. Build both alternatives (simple but less concurrent, and complex but more concurrent) and measure how they do.</li>
</ul>

<p>Ideally, you‚Äôd like to see the threads complete just as quickly on multiple processors as the single thread does on one. Achieving this end is called <strong>perfect scaling</strong>.</p>

<p><strong>Guidelines</strong></p>

<ul>
  <li>Be careful with acquisition and release of locks around control flow changes</li>
  <li>Enabling more concurrency does not necessarily increase performance</li>
  <li>Performance problems should only be remedied once they exist, avoiding premature optimization, is central to any performance-minded developer</li>
  <li>There is no value in making something faster if doing so will not improve the overall performance of the application.</li>
</ul>

<p><strong>Concurrent Counters</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-lock_performance_concurrent_counters.png" alt="os-lock_performance_concurrent_counters.png" /></p>

<p>Traditional Counter</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-lock_traditional_counter.png" alt="os-lock_traditional_counter.png" /></p>

<p>In this manner, it is similar to a data structure built with <strong>monitors</strong>, where locks are acquired and released automatically as you call and return from object methods.</p>

<p>The performance of the synchronized counter scales poorly.</p>

<p>Sloppy Counter</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-lock_sloppy_counter.png" alt="os-lock_sloppy_counter.png" /></p>

<p>The sloppy counter works by representing a single logical counter via numerous local physical counters, one per CPU core, as well as a single global counter.
When a thread running on a given core wishes to increment the counter, it increments its local counter; access to this local counter is synchronized via the corresponding local lock.
How often this local-to-global transfer occurs is determined by a threshold, which we call S here (for sloppiness). The smaller S is, the more the counter behaves like the non-scalable counter above; the bigger S is, the more scalable the counter, but the further off the global value might be from the actual count.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-lock_sloppy_counter_scaling.png" alt="os-lock_sloppy_counter_scaling.png" /></p>

<p><strong>Concurrent Linked Lists</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-lock_concurrent_link_list.png" alt="os-lock_concurrent_link_list.png" /></p>

<p>One small tricky issue arises if malloc() happens to fail (a rare case); in this case, the code must also release the lock before failing the insert. This kind of exceptional control flow has been shown to be quite error prone; a recent study of Linux kernel patches found that a huge fraction of bugs (nearly 40%) are found on such rarely-taken code paths.</p>

<p>BE WARY OF LOCKS AND CONTROL FLOW</p>

<p>Many functions will begin by acquiring a lock, allocating some memory, or doing other similar stateful operations, when errors arise, the code has to undo all of the state before returning, which is error-prone. Thus, it is best to structure code to minimize this pattern.</p>

<p>Specifically, we can rearrange the code a bit so that the lock and release only surround the actual critical section in the insert code, and that a common exit path is used in the lookup code.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-lock_concurrent_link_list_optimized.png" alt="os-lock_concurrent_link_list_optimized.png" /></p>

<p>Once again we are in a situation where it does not scale particularly well. One technique that researchers have explored to enable more concurrency within a list is something called <strong>hand-over-hand locking</strong> (a.k.a. <strong>lock coupling</strong>).</p>

<p>Instead of having a single lock for the entire list, you instead add a lock per node of the list. When traversing the list, the code first grabs the next node‚Äôs lock and then releases the current node‚Äôs lock.</p>

<p>It enables a high degree of concurrency in list operations. However, in practice, it is hard to make such a structure faster than the simple single lock approach, as the overheads of acquiring and releasing locks for each node of a list traversal is prohibitive. Perhaps some kind of hybrid (where you grab a new lock every so many nodes) would be worth investigating.</p>

<p><strong>Concurrent Queues</strong></p>

<p>Look at a slightly more concurrent queue designed by Michael and Scott.</p>

<p>There are two locks, one for the head of the queue, and one for the tail. The goal of these two locks is to enable concurrency of enqueue and dequeue operations. One trick used by the Michael and Scott is to add a dummy node (allocated in the queue initialization code); this dummy enables the separation of head and tail operations.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-lock_concurrent_queue.png" alt="os-lock_concurrent_queue.png" /></p>

<p><strong>Concurrent Hash Table</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-lock_concurrent_hash_table.png" alt="os-lock_concurrent_hash_table.png" /></p>

<p>This concurrent hash table is straightforward, is built using the concurrent lists we developed earlier, and works incredibly well. The reason for its good performance is that instead of having a single lock for the entire structure, it uses a lock per hash bucket.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-lock_scaling_hash_table.png" alt="os-lock_scaling_hash_table.png" /></p>

<p>AVOID PREMATURE OPTIMIZATION (KNUTH‚ÄôS LAW)</p>

<blockquote>
  <p>‚ÄúPremature optimization is the root of all evil.‚Äù</p>
</blockquote>

<p>Many operating systems utilized a single lock when first transitioning to multiprocessors, including Sun OS and Linux. In the latter, this lock even had a name, the <strong>big kernel lock (BKL)</strong>. When multi-CPU systems became the norm, only allowing a single active thread in the kernel at a time became a performance bottleneck. Thus, it was finally time to add the optimization of improved concurrency to these systems. Within Linux, the more straightforward approach was taken: replace one lock with many. Within Sun, a more radical decision was made: build a brand new operating system, known as Solaris, that incorporates concurrency more fundamentally from day one.</p>

<h2 id="chapter-30---condition-variables">Chapter 30 - Condition Variables</h2>

<p><strong>Background</strong></p>

<p>There are many cases where a thread wishes to check whether a condition is true before continuing its execution. For example, a parent thread might wish to check whether a child thread has completed before continuing (this is often called a <code>join()</code>).</p>

<p>In multi-threaded programs, it is often useful for a thread to wait for some conditio to become true before proceeding. The simple approach, of just spinning until the condition becomes true, is grossly inefficient and wastes CPU cycles, and in some cases, can be incorrect.</p>

<p><strong>Definition and Routines</strong></p>

<p>To wait for a condition to become true, a thread can make use of what is known as a condition variable. A <strong>condition variable</strong> is an explicit queue that threads can put themselves on when some state of execution (i.e., some condition) is not as desired (by <strong>waiting</strong> on the condition); some other thread, when it changes said state, can then wake one (or more) of those waiting threads and thus allow them to continue (by <strong>signaling</strong> on the condition).</p>

<p>By allowing threads to sleep when some program state is not as desired, CVs enable us to neatly solve a number of important synchronization problems, including the famous (and still important) producer/consumer problem, as well as covering conditions.</p>

<p>A condition variable has two operations associated with it: <strong>wait()</strong> and <strong>signal()</strong>.</p>

<ul>
  <li>The <strong>wait()</strong> call is executed when a thread wishes to put itself to sleep</li>
  <li>The <strong>signal()</strong> call is executed when a thread has changed something in the program and thus wants to wake a sleeping thread waiting on this condition.</li>
</ul>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-cv_waiting_demo.png" alt="os-cv_waiting_demo.png" /></p>

<p><strong><em>Is the state variable <code>done</code> necessary?</em></strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-cv_waiting_demo_2.png" alt="os-cv_waiting_demo_2.png" /></p>

<p>Yes. Imagine the case where the child runs immediately and calls thr exit() immediately; in this case, the child will signal, but there is no thread asleep on the condition. When the parent runs, it will simply call wait and be stuck; no thread will ever wake it. From this example, you should appreciate the importance of the state variable done; it records the value the threads are interested in knowing. The sleeping, waking, and locking all are built around it.</p>

<p><strong><em>Is there a need to hold the lock while singaling?</em></strong></p>

<p>Although it is strictly not necessary in all cases, it is likely simplest and best to hold the lock while signaling when using condition variables. The generalization of this tip is correct: hold the lock when calling signal or wait, and you will always be in good shape.</p>

<p><strong>Producer/Consumer (Bounded Buffer)</strong></p>

<p>The producer/consumer problem, or sometimes as the bounded buffer problem, which was first posed by Dijkstra. Indeed, it was this very producer/consumer problem that led Dijkstra and his co-workers to invent the generalized <strong>semaphore</strong> (which can be used as either a lock or a condition variable).</p>

<p>A bounded buffer is also used when you pipe the output of one program into another, e.g.,</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">// grep process is the producer
</span><span class="line">// wc process is the consumer
</span><span class="line">// between them is an in-kernel bounded buffer
</span><span class="line">grep foo file.txt | wc -l
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Basic operations: <code>put()</code> and <code>get()</code></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-cv_put_and_get_v1.png" alt="os-cv_put_and_get_v1.png" /></p>

<p><strong>Plain Solution</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-cv_producer_and_consumer_v1.png" alt="os-cv_producer_and_consumer_v1.png" /></p>

<p><strong>Single CV and If</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-cv_producer_and_consumer_single_cv_and_if.png" alt="os-cv_producer_and_consumer_single_cv_and_if.png" /></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-cv_producer_and_consumer_single_cv_and_if_trace.png" alt="os-cv_producer_and_consumer_single_cv_and_if_trace.png" /></p>

<p><strong>Single CV and While</strong></p>

<p>Signaling a thread only wakes them up; it is thus a hint that the state of the world has changed (in this case, that a value has been placed in the buffer), but there is no guarantee that when the woken thread runs, the state will still be as desired. This interpretation of what a signal means is often referred to as <strong>Mesa semantics</strong>, after the first research that built a condition variable in such a manner. Virtually every system ever built employs Mesa semantincs.</p>

<p>Thanks to Mesa semantics, a simple rule to remember with condition variables is to <strong>always use while loops</strong>.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-cv_producer_and_consumer_single_cv_and_while.png" alt="os-cv_producer_and_consumer_single_cv_and_while.png" /></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-cv_producer_and_consumer_single_cv_and_while_trace.png" alt="os-cv_producer_and_consumer_single_cv_and_while_trace.png" /></p>

<p><strong>Two CVs and While</strong></p>

<p>Signaling is clearly needed, but must be more directed. <strong>A consumer should not wake other consumers, only producers</strong>, and vice-versa.</p>

<p>Use two condition variables, instead of one, in order to properly signal which type of thread should wake up when the state of the system changes. Producer threads wait on the condition empty, and signals fill. Conversely, consumer threads wait on fill and signal empty.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-cv_producer_and_consumer_single_two_cv_and_while.png" alt="os-cv_producer_and_consumer_single_two_cv_and_while.png" /></p>

<p><strong>Final Solution</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-cv_producer_and_consumer_final_solution.png" alt="os-cv_producer_and_consumer_final_solution.png" /></p>

<p><strong>Covering Conditions</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-cv_producer_and_consumer_covering_conditions.png" alt="os-cv_producer_and_consumer_covering_conditions.png" /></p>

<p>Assume there are zero bytes free; thread Ta calls <code>allocate(100)</code>, followed by thread Tb which asks for less memory by calling <code>allocate(10)</code>. Both Ta and Tb thus wait on the condition and go to sleep; there aren‚Äôt enough free bytes to satisfy either of these requests. At that point, assume a third thread, Tc, calls <code>free(50)</code>. Unfortunately, when it calls signal to wake a waiting thread, it might not wake the correct waiting thread, Tb, which is waiting for only 10 bytes to be freed; Ta should remain waiting, as not enough memory is yet free. Thus, the code in the figure does not work, as the thread waking other threads does not know which thread (or threads) to wake up.</p>

<p>The solution suggested by Lampson and Redell is straightforward: replace the <code>pthread_cond_signal()</code> call in the code above with a call to <code>pthread_cond_broadcast()</code>, which wakes up all waiting threads. Those threads will simply wake up, re-check the condition, and then go immediately back to sleep.</p>

<p>Lampson and Redell call such a condition a <strong>covering condition</strong>, as it covers all the cases where a thread needs to wake up (conservatively); the cost, is that too many threads might be woken.</p>

<p>In general, if you find that your program only works when you change your signals to broadcasts (but you don‚Äôt think it should need to), you probably have a bug; fix it! But in cases like the memory allocator above, broadcast may be the most straightforward solution available.</p>

<h2 id="chapter-31---semaphores">Chapter 31 - Semaphores</h2>

<p><strong>Background</strong></p>

<p>As we know now, one needs both locks and condition variables to solve a broad range of relevant and interesting concurrency problems. One of the first people to realize this years ago was Edsger Dijkstra. Dijkstra and colleagues invented the semaphore as a single primitive for all things related to synchronization; as you will see, one can use semaphores as both locks and condition variables.</p>

<p><strong>Definition</strong></p>

<p>A semaphore is an object with an integer value that we can manipulate with two routines; in the POSIX standard, these routines are sem <code>wait()</code> and sem <code>post()</code>. The initial value of the semaphore determines its behaviour.</p>

<p>Semaphores are a powerful and flexible primitive for writing concurrent programs. Some programmers use them exclusively, shunning locks and condition variables, due to their simplicity and utility.</p>

<p>In my view, semaphore is an primitive, which can be made by locks and condition variables, also can‚Äôt be used as locks and condition variables.</p>

<p>Initialization</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-semaphore_init.png" alt="os-semaphore_init.png" /></p>

<p>Usage
<img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-semaphore_definition.png" alt="os-semaphore_definition.png" /></p>

<ul>
  <li><code>sem_wait()</code> will either return right away (because the value of the semaphore was one or higher when we called <code>sem_wait()</code>), or it will cause the caller to suspend execution waiting for a subsequent post.</li>
  <li><code>sem_post()</code> does not wait for some particular condition to hold like <code>sem_wait()</code> does. Rather, it simply increments the value of the semaphore and then, if there is a thread waiting to be woken, wakes one of them up.</li>
  <li>The value of the semaphore, when negative, is equal to the number of waiting threads</li>
</ul>

<p><strong>Semaphores As Locks</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-semaphore_as_locks.png" alt="os-semaphore_as_locks.png" /></p>

<p>Because locks only have two states (held and not held), this usage is sometimes known as a <strong>binary semaphore</strong>.</p>

<p><strong>Semaphores As Condition Variables</strong></p>

<p>Semaphores are also useful when a thread wants to halt its progress waiting for a
 condition to become true. In this pattern of usage, we often find a thread waiting for something to happen, and a different thread making that something happen and then signaling that it has happened, thus waking the waiting thread.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-semaphore_as_cv.png" alt="os-semaphore_as_cv.png" /></p>

<p><strong>Producer/Consumer (Bounded Buffer)</strong></p>

<p>Plain Solution</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-semaphore_producer_and_consumer_plain.png" alt="os-semaphore_producer_and_consumer_plain.png" /></p>

<p>The condition variable (semaphore based) controls the execution order, which can let multiple threads enter the critical section at the same time. It still needs a lock.</p>

<p>Adding Mutual Exclusion</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-semaphore_producer_and_consumer_add_mutex.png" alt="os-semaphore_producer_and_consumer_add_mutex.png" /></p>

<p>The consumer holds the mutex and is waiting for the someone to signal full. The producer could si!gnal full but is waiting for the mutex. Thus, the producer and consumer are each stuck waiting for each other: a classic deadlock.</p>

<p>To avoid the deadlock, we can simply move the mutex acquire and release to be just around the critical section. The result is a simple and working bounded buffer, a commonly-used pattern in multi-threaded programs.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-semaphore_producer_and_consumer_add_mutex_correctly.png" alt="os-semaphore_producer_and_consumer_add_mutex_correctly.png" /></p>

<p><strong>Reader-Writer Locks</strong></p>

<p>Another classic problem stems from the desire for a more flexible <strong>locking primitive</strong> that admits that different data structure accesses might require different kinds of locking.</p>

<p>Imagine a number of concurrent list operations, including inserts and simple lookups. While inserts change the state of the list (and thus a traditional critical section makes sense), lookups simply read the data structure; as long as we can guarantee that no insert is on-going, we can allow many lookups to proceed concurrently. The special type of lock we will now develop to support this type of operation is known as a <strong>reader-writer lock</strong>.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-semaphore_reader_writer_lock.png" alt="os-semaphore_reader_writer_lock.png" /></p>

<p>Once a reader has acquired a read lock, more readers will be allowed to acquire the read lock too; however, any thread that wishes to acquire the write lock will have to wait until all readers are finished; the last one to exit the critical section calls sem <code>post()</code> on ‚Äúwritelock‚Äù and thus enables a waiting writer to acquire the lock.</p>

<p>This approach works (as desired), but does have some negatives, especially when it comes to fairness. In particular, it would be relatively easy for readers to starve writers. It should be noted that reader-writer locks should be used with some caution. They often add more overhead (especially with more sophisticated implementations), and thus do not end up speeding up performance as compared to just using simple and fast locking primitives.</p>

<p>SIMPLE AND DUMB CAN BE BETTER (HILL‚ÄôS LAW)</p>

<p>You should never underestimate the notion that the simple and dumb approach can be the best one. Always try the simple and dumb approach first.</p>

<p><strong>The Dining Philosophers</strong></p>

<p>One of the most famous concurrency problems posed, and solved, by Dijkstra, is known as the dining philosopher‚Äôs problem.</p>

<p>There are five ‚Äúphilosophers‚Äù sitting around a table. Between each pair of philosophers is a single fork (and thus, five total). The philosophers each have times where they think, and don‚Äôt need any forks, and times where they eat. In order to eat, a philosopher needs two forks, both the one on their left and the one on their right. The contention for these forks, and the synchronization problems that ensue, are what makes this a problem we study in concurrent programming.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-semaphore_dinning_philosophers.png" alt="os-semaphore_dinning_philosophers.png" /></p>

<p>Broken Solution</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-semaphore_dinning_philosophers_deadlock_solution.png" alt="os-semaphore_dinning_philosophers_deadlock_solution.png" /></p>

<p>The problem is deadlock. If each philosopher happens to grab the fork on their left before any philosopher can grab the fork on their right, each will be stuck holding one fork and waiting for another, forever.</p>

<p>A Solution: Breaking The Dependency</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-semaphore_dinning_philosophers_solution.png" alt="os-semaphore_dinning_philosophers_solution.png" /></p>

<p><strong>Implement Semaphores</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-semaphore_implementation.png" alt="os-semaphore_implementation.png" /></p>

<h2 id="chapter-32---common-concurrency-problems">Chapter 32 - Common Concurrency Problems</h2>

<p><strong>Background</strong></p>

<p>Lu et al has made a study, which analyzes a number of popular concurrent applications in great detail to understand what types of bugs arise in practice.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-concurrency_bugs.png" alt="os-concurrency_bugs.png" /></p>

<p><strong>Non-Deadlock Bugs</strong></p>

<ul>
  <li>Atomicity violation bugs. The desired serializability among multiple memory accesses is violated (i.e. a code region is intended to be atomic, but the atomicity is not enforced during execution). Solve by locks.</li>
  <li>Order violation bugs. The desired order between two (groups of) memory accesses is flipped (i.e., A should always be executed before B, but the order is not enforced during execution). Solve by condition variables.</li>
</ul>

<p><strong>Deadlock Bugs</strong></p>

<p>Deadlock occurs, for example, when a thread (say Thread 1) is holding a lock (L1) and waiting for another one (L2); unfortunately, the thread (Thread 2) that holds lock L2 is waiting for L1 to be released.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-concurrency_deadlock_dependency.png" alt="os-concurrency_deadlock_dependency.png" /></p>

<p><strong>Caused by</strong></p>

<p>One reason is that in large code bases, complex dependencies arise between cmponents. The design of locking strategies in large systems must be carefully done to avoid deadlock in the case of <strong>circular dependencies</strong> that may occur naturally in the code.</p>

<p>Another reason is due to the nature of <strong>encapsulation</strong>. As software developers, we are taught to hide details of implementations and thus make software easier to build in a modular way.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-concurrency_deadlock_by_encapsulation.png" alt="os-concurrency_deadlock_by_encapsulation.png" /></p>

<p><strong>Conditions for Deadlock</strong></p>

<ul>
  <li><strong>Mutual exclusion</strong>: Threads claim exclusive control of resources that they require (e.g., a thread grabs a lock).</li>
  <li><strong>Hold-and-wait</strong>: Threads hold resources allocated to them (e.g.,locks that they have already acquired) while waiting for additional resources (e.g., locks that they wish to acquire).</li>
  <li><strong>No preemption (hold)</strong>: Resources (e.g., locks) cannot be forcibly removed from threads that are holding them.</li>
  <li><strong>Circular wait (wait)</strong>: There exists a coircular chain of threads such that each thread holds one more resources (e.g., locks) that are being requested by the next thread in the chain.</li>
</ul>

<p><strong>Prevention Based on Four Conditions</strong></p>

<p>Mutual Exclusion</p>

<p>To avoid the need for mutual exclusion at all. Herlihy had the idea that one could design various data structures to be <strong>wait-free</strong>. The idea here is simple: using powerful hardware instructions, you can build data structures in a manner that does not require explicit locking.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-concurrency_deadlock_wait_free.png" alt="os-concurrency_deadlock_wait_free.png" /></p>

<p>However, this will fail if some other thread successfully swapped in a new head in the meanwhile, causing this thread to retry again with the new head.</p>

<p>Hold-and-wait</p>

<p>The hold-and-wait requirement for deadlock can be avoided by acquiring all locks at once, atomically.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-concurrency_deadlock_hold_and_wait.png" alt="os-concurrency_deadlock_hold_and_wait.png" /></p>

<p>By first grabbing the lock prevention, this code guarantees that no untimely thread switch can occur in the midst of lock acquisition and thus deadlock can once again be avoided.</p>

<p>Note that the solution is problematic for a number of reasons. As before, encapsulation works against us: when calling a routine, this approach requires us to know exactly which locks must be held and to acquire them ahead of time. This technique also is likely to decrease concurrency as all locks must be acquired early on (at once) instead of when they are truly needed.</p>

<p>No Preemption</p>

<p>Because we generally view locks as held until unlock is called, multiple lock acquisition often gets us into trouble because when waiting for one lock we are holding another. Many thread libraries provide a more flexible set of interfaces to help avoid this situation. Specifically, a <code>trylock()</code> routine will grab the lock (if it is available) or return -1 indicating that the lock is held right now and that you should try again later if you want to grab that lock.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-concurrency_deadlock_no_preemption.png" alt="os-concurrency_deadlock_no_preemption.png" /></p>

<p>One new problem does arise, however: <strong>livelock</strong>. It is possible (though perhaps unlikely) that two threads could both be repeatedly attempting this sequence and repeatedly failing to acquire both locks. In this case, both systems are running through this code sequence over and over again (and thus it is not a deadlock), but progress is not being made, hence the name lovelock. One could add a random delay before looping back and trying the entire thing over again, thus decreasing the odds of repeated interference among competing threads.</p>

<p>Another issues arises due to encapsulation: if one of these locks is buried in some routine that is getting called, the jump back to the beginning becomes more complex to implement.</p>

<p>Circular Wait</p>

<p>The best solution in practice is to be careful, develop a lock acquisition order, and thus prevent deadlock from occurring in the first place.</p>

<ul>
  <li>The most straightforward way to do that is to provide a <strong>total ordering</strong> on lock acquisition. For example, if there are only two locks in the system (L1 and L2), you can prevent deadlock by always acquiring L1 before L2. Such strict ordering ensures that no cyclical wait arises; hence, no deadlock.</li>
  <li>A <strong>partial ordering</strong> can be a useful way to structure lock acquisition so as to avoid deadlock.</li>
</ul>

<p><strong>Avoidance via Scheduling</strong></p>

<p>Instead of deadlock prevention, in some scenarios deadlock avoidance is preferable. Avoidance requires some global knowledge of which locks various threads might grab during their execution, and subsequently schedules said threads in a way as to guarantee no deadlock can occur.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-concurrency_deadlock_avoid_via_scheduling.png" alt="os-concurrency_deadlock_avoid_via_scheduling.png" /></p>

<p>Unfortunately, they are only useful in very limited environments, for example, in an embedded system where one has full knowledge of the entire set of tasks that must be run and the locks that they need. Further, such approaches can limit concurrency. Thus, avoidance of deadlock via scheduling is not a widely-used general-purpose solution</p>

<p><strong>Detect and Recover</strong></p>

<p>One final general strategy is to allow deadlocks to occasionally occur, and then take some action once such a deadlock has been detected.</p>

<p>Many database systems employ deadlock detection and recovery techniques. A deadlock detector runs periodically, building a resource graph and checking it for cycles. In the event of a cycle (deadlock), the system needs to be restarted.</p>

<p>DON‚ÄôT ALWAYS DO IT PERFECTLY (TOM WEST‚ÄôS LAW)</p>

<p>Tom West says famously, ‚ÄúNot everything worth doing is worth doing well‚Äù, which is a terrific engineering maxim. If a bad thing happens rarely, certainly one should not spend a great deal of effort to prevent it, particularly if the cost of the bad thing occurring is small.</p>

<p><strong>Others</strong></p>

<p>Perhaps the best solution is to develop new concurrent programming models: in systems such as <strong>MapReduce</strong> (from Google), programmers can describe certain types of parallel computations without any locks whatsoever.</p>

<h2 id="chapter-33---event-based-concurrency-advanced">Chapter 33 - Event-based Concurrency (Advanced)</h2>

<p><strong>Background</strong></p>

<p>A different style of concurrent programming is often used in both GUI-based applications as well as some types of internet servers. This style, known as event-based concurrency, has become popular in some modern systems, including server-side frameworks such as node.js, but its roots are found in C/UNIX systems that we‚Äôll discuss below.</p>

<p>Event-based servers give control of scheduling to the application itself, but do so at some cost in complexity and difficulty of integration with other aspects of modern systems (e.g., paging). Because of these challenges, no single approach has emerged as best; thus, both threads and events are likely to persist as two different approaches to the same concurrency problem for many years to come.</p>

<p>The problem that event-based concurrency addresses is two-fold.</p>

<ul>
  <li>The first is that managing concurrency correctly in multi-threaded applications can be challenging.</li>
  <li>The second is that in a multi-threaded application, the developer has little or no control over what is scheduled at a given moment in time; rather, the programmer simply creates threads and then hopes that the underlying OS schedules them in a reasonable manner across available CPUs.</li>
</ul>

<p><strong>The Basic Idea: An Event Loop</strong></p>

<p>The approach is quite simple: you simply wait for something (i.e., an ‚Äúevent‚Äù) to occur; when it does, you check what type of  event it is and do the small amount of work it requires (which may include issuing I/O requests, or scheduling other events for future handling, etc.). That‚Äôs it!</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-event_loop.png" alt="os-event_loop.png" /></p>

<p>Importantly, when a handler processes an event, it is the only activity taking place in the system; thus, deciding which event to handle ext is equivalent to scheduling. This explicit control over scheduling is one of the fundamental advantages of the event- based approach.</p>

<p>But there is a big question: how exactly does an event-based server determine which events are taking place, in particular with regards to network and disk I/O? Specifically, how can an event server tell if a message has arrived for it?</p>

<p><strong>An Important API: select() (or poll())</strong></p>

<p>In most systems, a basic API is available, via either the <strong>select()</strong> or <strong>poll()</strong> system calls. Either way, these basic primitives give us a way to build a non-blocking event loop, which simply checks for incoming packets, reads from sockets with messages upon them, and replies as needed.</p>

<p>What these interfaces enable a program to do is simple: check whether there is any incoming I/O that should be attended to.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-event_select_api.png" alt="os-event_select_api.png" /></p>

<p>First, note that it lets you check whether descriptors can be reand from as well as written to; the former lets a server determine that a new packet has arrived and is in need of processing, whereas the latter lets the service know when it is OK to reply (i.e., the outbound queue is not full).</p>

<p>Second, note the timeout argument. One common usage here is to set the timeout to <code>NULL</code>, which causes <code>select()</code> to block indefinitely, until some descriptor is ready. However, more robust servers will usually specify some kind of timeout; one common technique is to set the timeout to zero, and thus use the call to <code>select()</code> to return immediately.</p>

<p>Now linux uses <strong>epoll</strong>, FreeBSD (Mac OS) uses <strong>kqueue</strong>, and Windows uses <strong>IOCP</strong>.</p>

<p>BLOCKING VS. NON-BLOCKING INTERFACES</p>

<ul>
  <li>Blocking (or synchronous) interfaces do all of their work before returning to the caller. The usual culprit in blocking calls is I/O of some kind.</li>
  <li>Non-blocking (or asynchronous) interfaces begin some work but return immediately, thus letting whatever work that needs to be done get done in the background. Non-blocking interfaces can be used in any style of programming (e.g., with threads), but are essential in the event-based approach, as a call that blocks will halt all progress.</li>
</ul>

<p>DON‚ÄôT BLOCK IN EVENT-BASED SERVERS</p>

<p>Event-based servers enable fine-grained control over scheduling of tasks. However, to maintain such control, no call that blocks the execution the caller can ever be made; failing to obey this design tip will result in a blocked event-based server.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-event_select_code_demo.png" alt="os-event_select_code_demo.png" /></p>

<p>Advantage</p>

<p>With a single CPU and an event-based application, the problems found in concurrent programs are no longer present. Specifically, because only one event is being handled at a time, there is no need to acquire or release locks; the event-based server cannot be interrupted by another thread because it is decidedly single threaded. Thus, concurrency bugs common in threaded programs do not manifest in the basic event-based approach.</p>

<p><strong>Issue: Blocking System Calls</strong></p>

<p>For example, imagine a request comes from a client into a server to read a file from disk and return its contents to the requesting client (much like a simple HTTP request). Both the open() and read() calls may issue I/O requests to the storage system (when the needed metadata or data is not in memory already), and thus may take a long time to service.</p>

<p>With a thread-based server, this is no issue: while the thread issuing the I/O request suspends (waiting for the I/O to complete), other threads can run, thus enabling the server to make progress. Indeed, this natural <strong>overlap</strong> of I/O and other computation is what makes thread-based programming quite natural and straight-forward.</p>

<p>With an event-based approach, however, there are no other threads to run: just the main event loop. And this implies that if an event handler issues a call that blocks, the entire server will do just that: block until the call completes.</p>

<p>We thus have a rule that must be obeyed in event-based systems: no blocking calls are allowed.</p>

<p>Solution: Asynchronous I/O</p>

<p>To overcome this limit, many modern operating systems have intro- duced new ways to issue I/O requests to the disk system, referred to generically as asynchronous I/O. These interfaces enable an application to issue an I/O request and return control immediately to the caller, before the I/O has completed; additional interfaces enable an application to determine whether various I/Os have completed.</p>

<p>The APIs revolve around a basic structure, the struct aiocb or <strong>AIO control block</strong> in common terminology.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-event_aio_control_block.png" alt="os-event_aio_control_block.png" /></p>

<ul>
  <li>An application can periodically poll the system via a call to aio error() to determine whether said I/O has yet completed.</li>
  <li>Some systems provide an approach based on the interrupt. This method uses UNIX signals to inform applications when an asynchronous I/O completes, thus removing the need to repeatedly ask the system.</li>
</ul>

<p>In systems without asynchronous I/O, the pure event-based approach cannot be implemented. However, clever researchers have derived methods that work fairly well in their place. For example, Pai et al describe a hybrid approach in which events are used to process network packets, and a thread pool is used to manage outstanding I/Os.</p>

<p>UNIX SIGNALS</p>

<p>A huge and fascinating infrastructure known as <strong>signals</strong> is present in all mod ern UNIX variants. At its simplest, signals provide a way to communicate with a process. Specifically, a signal can be delivered to an application; doing so stops the application from whatever it is doing to run a <strong>signal handler</strong>, i.e., some code in the application to handle that signal. When finished, the process just resumes its previous behaviour. A program can be configured to catch that signal. Or when a signal is sent to a process not config- ured to handle that signal, some default behavior is enacted; for SEGV, the process is killed.</p>

<p><strong>Issue: State Management</strong></p>

<p>When an event handler issues an asynchronous I/O, it must package up some program state for the next event handler to use when the I/O finally completes; this additional work is not needed in thread-based programs, as the state the program needs is on the stack of the thread. Adya et al. call this work <strong>manual stack management</strong>, and it is fundamental to event-based programming.</p>

<p>Solution: Continuation</p>

<p>Use an old programming language construct known as a <strong>continuation</strong>. Though it sounds complicated, the idea is rather simple: basically, record the needed information to finish processing this event in some data structure; when the event happens (i.e., when the disk I/O completes), look up the needed information and process the event.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-event_state_management.png" alt="os-event_state_management.png" /></p>

<p>Record the socket descriptor (sd) in some kind of data structure (e.g., a hash table), indexed by the file descriptor (fd). When the disk I/O completes, the event handler would use the file descriptor to look up the continuation, which will return the value of the socket descriptor to the caller.</p>

<p><strong>What Is Still Difficult With Events</strong></p>

<p>Multiple CPUS. When systems moved from a single CPU to multiple CPUs, some of the simplicity of the event-based approach disappeared. Specifically, in order to utilize more than one CPU, the event server has to run multiple event handlers in parallel; when doing so, the usual synchronization problems (e.g., critical sections) arise, and the usual solutions (e.g., locks) must be employed. Thus, on modern multicore systems, simple event handling without locks is no longer possible.</p>

<p>Implicit blocking. It does not integrate well with certain kinds of systems activity, such as paging. For example, if an event-handler page faults, it will block, and thus the server will not make progress until the page fault completes. Even though the server has been structured to avoid explicit blocking, this type of implicit blocking due to page faults is hard to avoid and thus can lead to large performance problems when prevalent.</p>

<p>API changes all the time. That event-based code can be hard to manage over time, as the exact semantics of various routines changes]. For example, if a routine changes from non-blocking to blocking, the event handler that calls that routine must also change to accommodate its new nature, by ripping itself into two pieces. Because blocking is so disastrous for event-based servers, a programmer must always be on the lookout for such changes in the semantics of the APIs each event uses.</p>

<p>Async network I/O. Though asynchronous disk I/O is now possible on most platforms, it has taken a long time to get there, and it never quite integrates with asynchronous network I/O in as simple and uniform a manner as you might think. For example, while one would simply like to use the select() interface to manage all outstanding I/Os, usually some combination of select() for networking and the AIO calls for disk I/O are required.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Review] Website Performance Optimization]]></title>
    <link href="http://blog.ifyouseewendy.com/blog/2015/12/19/web-performance-optimization/"/>
    <updated>2015-12-19T15:21:58+08:00</updated>
    <id>http://blog.ifyouseewendy.com/blog/2015/12/19/web-performance-optimization</id>
    <content type="html"><![CDATA[<p>After several years working, I‚Äôve learned many lessons like how to write HTML, how to minify and compress CSS and JavaScript files, where to put the CSS and JavaScript reference, how to do the cache control and etc.. But all the knowledge are scattered, and the real mechanism, like the HTML rendering, seems like a mysterious process to me. So I spent some time digging and learning, the things finally got clear.</p>

<p><strong><em>For short, what‚Äôs the basic idea of web performance optimization?</em></strong></p>

<ul>
  <li>Minimize the number of critical resources, like optimizing CSS (inline, or specify media query), and optimizing JavaScript (defer execution).</li>
  <li>Minimize the number of critical bytes, like optimizing content efficiency, minify, compress and HTTP cache control.</li>
  <li>Minimize the critical path length, like preload scanner.</li>
</ul>

<p><strong>Materials</strong></p>

<ul>
  <li><a href="https://www.udacity.com/course/website-performance-optimization--ud884">Udacity - Website Performance Optimization</a></li>
  <li><a href="https://developers.google.com/web/fundamentals/performance/critical-rendering-path/?hl=en">Google Developer - Critical Rendering Path</a></li>
</ul>

<p><strong>TOC</strong></p>

<ul id="markdown-toc">
  <li><a href="#optimizing-content-efficiency">Optimizing content efficiency</a>    <ul>
      <li><a href="#eliminating-unnecessary-downloads">Eliminating unnecessary downloads</a></li>
      <li><a href="#optimizing-encoding-and-transfer-size-of-text-based-assets">Optimizing encoding and transfer size of text-based assets</a></li>
      <li><a href="#image-optimization">Image optimization</a></li>
      <li><a href="#web-font-optimization">Web font optimization</a></li>
      <li><a href="#http-caching">HTTP caching</a></li>
    </ul>
  </li>
  <li><a href="#critical-rendering-path">Critical Rendering Path</a>    <ul>
      <li><a href="#critical-rendering-path-1">Critical Rendering Path</a></li>
      <li><a href="#analysing-critical-rendering-path-performance">Analysing Critical Rendering Path Performance</a></li>
      <li><a href="#optimizing-the-critical-rendering-path">Optimizing the critical rendering path</a></li>
    </ul>
  </li>
  <li><a href="#browser-rendering-optimization">Browser Rendering Optimization</a></li>
</ul>

<h2 id="optimizing-content-efficiency">Optimizing content efficiency</h2>

<ul>
  <li>Apply content-specific optimizations first: CSS, JS, and HTML minifiers.</li>
  <li>Apply GZIP to compress the minified output.</li>
</ul>

<h3 id="eliminating-unnecessary-downloads">Eliminating unnecessary downloads</h3>

<p>The fastest and best optimized resource is a resource not sent.</p>

<ul>
  <li>Inventory all own and third party assets on your pages</li>
  <li>Measure the performance of each asset: its value and its technical performance</li>
  <li>Determine if the resources are providing sufficient value</li>
</ul>

<p>For best results you should periodically inventory and revisit these questions for each and every asset on your pages.</p>

<h3 id="optimizing-encoding-and-transfer-size-of-text-based-assets">Optimizing encoding and transfer size of text-based assets</h3>

<p><strong>Data Compression</strong></p>

<p>Compression is the process of encoding information using fewer bits. Eliminating unnecessary data always yields the best results.</p>

<p><strong>Minification: preprocessing &amp; context-specific optimizations</strong></p>

<ul>
  <li>Remove comments</li>
  <li>Remove inefficient ways of defining CSS rules</li>
  <li>Strip out all the whitespaces (tabs and spaces).</li>
</ul>

<p>We can keep the original page as our ‚Äúdevelopment version‚Äù and then apply the steps above whenever we are ready to release the page on our website.</p>

<blockquote>
  <p>Case in point, the uncompressed development version of the JQuery library is now approaching ~300KB. The same library, but minified (removed comments, etc.) is about 3x smaller: ~100KB.</p>
</blockquote>

<p><strong>Text compression with GZIP</strong></p>

<p>GZIP is a generic compressor that can be applied to any stream of bytes. In practice, GZIP performs best on text-based content, often achieving compression rates of as high as 70-90% for larger files.</p>

<p>All modern browsers support and automatically negotiate GZIP compression for all HTTP requests.</p>

<p>A quick and simple way to see GZIP in action is to open Chrome DevTools and inspect the ‚ÄúSize / Content‚Äù column in the Network panel: ‚ÄúSize‚Äù indicates the transfer size of the asset, and ‚ÄúContent‚Äù the uncompressed size of the asset.</p>

<ul>
  <li><a href="http://www.whatsmyip.org/http-compression-test/">HTTP Compression Test</a></li>
  <li><a href="https://github.com/h5bp/server-configs-nginx">Nginx HTTP server boilerplate configs</a></li>
</ul>

<h3 id="image-optimization">Image optimization</h3>

<ul>
  <li>Prefer vector formats: vector images are resolution and scale independent, which makes them a perfect fit for the multi-device and high-resolution world.</li>
  <li>Minify and compress SVG assets: XML markup produced by most drawing applications often contains unnecessary metadata which can be removed; ensure that your servers are configured to apply GZIP compression for SVG assets.</li>
  <li>Pick best raster image format: determine your functional requirements and select the one that suits each particular asset.</li>
  <li>Experiment with optimal quality settings for raster formats: don‚Äôt be afraid to dial down the ‚Äúquality‚Äù settings, the results are often very good and byte savings are significant.</li>
  <li>Remove unnecessary image metadata: many raster images contain unnecessary metadata about the asset: geo information, camera information, and so on. Use appropriate tools to strip this data.</li>
  <li>Serve scaled images: resize images on the server and ensure that the ‚Äúdisplay‚Äù size is as close as possible to the ‚Äúnatural‚Äù size of the image. Pay close to attention to large images in particular, as they account for largest overhead when resized!</li>
  <li>Automate, automate, automate: invest into automated tools and infrastructure that will ensure that all of your image assets are always optimized.</li>
</ul>

<p><strong>Eliminating and replacing images</strong></p>

<ul>
  <li>Eliminate unnecessary image resources</li>
  <li>Leverage CSS3 effects where possible</li>
  <li>Use web fonts instead of encoding text in images</li>
</ul>

<p><strong>Vector vs. Raster images</strong></p>

<ul>
  <li>Vector images are ideal for images that consist of geometric shapes</li>
  <li>Vector images are zoom and resolution-independent</li>
  <li>Raster images should be used for complex scenes with lots of irregular shapes and details</li>
</ul>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/vector_vs_raster_image.png" alt="vector_vs_raster_image.png" /></p>

<ul>
  <li>Vector graphics use lines, points, and polygons to represent an image.</li>
  <li>Raster graphics represent an image by encoding the individual values of each pixel within a rectangular grid.</li>
</ul>

<p><strong>Implications of high-resolution screens</strong></p>

<ul>
  <li>High resolution screens have multiple device pixels per CSS pixel</li>
  <li>High resolution images require significantly higher number of pixels and bytes</li>
  <li>Image optimization techniques are the same regardless of resolution</li>
</ul>

<p>High resolution screens also require high-resolution images: prefer vector images whenever possible as they are resolution independent and always deliver sharp results, and if a raster image is required, deliver and optimize multiple variants of each imagewith the help of srcset and picture.</p>

<p><strong>Optimizing vector images</strong></p>

<ul>
  <li>SVG is an XML-based image format</li>
  <li>SVG files should be minified to reduce their size</li>
  <li>SVG files should be compressed with GZIP</li>
</ul>

<p>All modern browsers support Scalable Vector Graphics (SVG), which is an XML-based image format for two-dimensional graphics: we can embed the SVG markup directly on the page, or as an external resource.</p>

<p><strong>Optimizing raster images</strong></p>

<p>Image optimization boils down to two criteria: optimizing the number of bytes used to encode each image pixel, and optimizing the total number of pixels: the filesize of the image is simply the total number of pixels times the number of bytes used to encode each pixel.</p>

<ul>
  <li>A raster image is a grid of pixels</li>
  <li>Each pixel encodes color and transparency information</li>
  <li>Image compressors use a variety of techniques to reduce the number of required bits per pixel to reduce file size of the image</li>
</ul>

<p>A raster image is simply a 2-dimensional grid of individual ‚Äúpixels‚Äù - e.g. a 100x100 pixel image is a sequence of 10,000 pixels. In turn, each pixel stores the ‚ÄúRGBA‚Äù values: (R) red channel, (G) green channel, (B) blue channel, and (A) alpha (transparency) channel.</p>

<p>Internally, the browser allocates 256 values (shades) for each channel, which translates to 8 bits per channel (2 ^ 8 = 256), and 4 bytes per pixel (4 channels x 8 bits = 32 bits = 4 bytes).</p>

<p>So, a 100 x 100px image, is 39 KB size without losing any information.</p>

<blockquote>
  <p>100 x 100px image is composed of 10,000 pixels<br />
10,000 pixels x 4 bytes = 40,000 bytes<br />
40,000 bytes / 1024 = 39 KB  </p>
</blockquote>

<p><strong>Lossless vs lossy image compression</strong></p>

<ul>
  <li>Due to how our eyes work, images are great candidates for lossy compression</li>
  <li>Image optimization is a function of lossy and lossless compression</li>
  <li>Differences in image formats are due to the difference in how and which lossy and lossless algorithms are used to optimize the image</li>
  <li>There is no single best format or ‚Äúquality setting‚Äù for all images: each combination of particular compressor and image contents produce a unique output</li>
</ul>

<p>In fact, the difference between various image formats, such as GIF, PNG, JPEG, and others, is in the combination of the specific algorithms they use (or omit) when applying the lossy and lossless steps.</p>

<p><strong><em>What is the ‚Äúoptimal‚Äù configuration of lossy and lossless optimization?</em></strong></p>

<p>The answer depends on the image contents and your own criteria such as the tradeoff between filesize and artifacts introduced by lossy compression.</p>

<p><strong>Selecting the right image format</strong></p>

<ul>
  <li>Start by selecting the right universal format: GIF, PNG, JPEG</li>
  <li>Experiment and select the best settings for each format: quality, palette size, etc.</li>
  <li>Consider adding WebP and JPEG XR assets for modern clients</li>
</ul>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/select_the_right_image.png" alt="select_the_right_image.png" /></p>

<ul>
  <li><strong>GIF</strong> limits the color palette to at most 256 colors, which makes it a poor choice for most images.</li>
  <li><strong>PNG</strong> does not apply any lossy compression algorithms beyond the choice of the size of the color palette. As a result, it will produce the highest quality image, but at a cost of significantly higher filesize than other formats. Use judiciously.</li>
  <li>If the image asset contains imagery composed of geometric shapes, consider converting it to a vector (<strong>SVG</strong>) format!</li>
  <li>If the image asset contains text, stop and reconsider. Text in images is not selectable, searchable, or ‚Äúzoomable‚Äù. If you need to convey a custom look (for branding or other reasons), use a <strong>web font</strong> instead.</li>
  <li><strong>JPEG</strong> uses a combination of lossy and lossless optimization to reduce filesize of the image asset.</li>
  <li>Also consider adding an additional variant encoded in <strong>WebP</strong> and <strong>JPEG XR</strong>. WebP delivers a 30% filesize decrease over a comparable JPEG image.</li>
</ul>

<p><strong>Tools and parameter tuning</strong></p>

<ul>
  <li><a href="http://www.lcdf.org/gifsicle/">gifsicle</a>, create and optimize GIF images</li>
  <li><a href="http://jpegclub.org/jpegtran/">jpegqran</a>, optimize JPEG images</li>
  <li><a href="http://optipng.sourceforge.net/">optpng</a>, lossless PNG optimization</li>
  <li><a href="http://pngquant.org/">pngquant</a>, lossy PNG optimization</li>
</ul>

<p><strong>Delivering scaled image assets</strong></p>

<p>One of the simplest and most effective image optimization techniques is to ensure that we are not shipping any more pixels than needed to display the asset at its intended size in the browser. Most pages fail this test for many of their image assets: typically, they ship larger assets and rely on the browser to rescale them - which also consumes extra CPU resources - and display them at a lower resolution.</p>

<p>You should ensure that the number of unnecessary pixels is minimal, and that your large assets in particular are delivered as close as possible to their display size.</p>

<h3 id="web-font-optimization">Web font optimization</h3>

<p>Use of webfonts does not need to delay page rendering or have negative impact on other performance metrics. Well optimized use of fonts can deliver a much better overall user experience:</p>

<ul>
  <li>Audit and monitor your font use: do not use too many fonts on your pages, and for each font, minimize the number of used variants. This will assist in delivering a more consistent and a faster experience for your users.</li>
  <li>Subset your font resources: many fonts can be subset, or split into multiple unicode-ranges to deliver just the glyphs required by a particular page - this reduces the filesize and improves download speed of the resource. However, when defining the subsets be careful to optimize for font re-use - e.g. you don‚Äôt want to download a different but overlapping set of characters on each page. A good practice is to subset based on script - e.g. Latin, Cyrillic, and so on.</li>
  <li>Deliver optimized font formats to each browser: each font should be provided in WOFF2, WOFF, EOT, and TTF formats. Make sure to apply GZIP compression to EOT and TTF formats, as they are not compressed by default.</li>
  <li>Specify revalidation and optimal caching policies: fonts are static resources that are infrequently updated. Make sure that your servers provide a long-lived max-age timestamp, and a revalidation token, to allow for efficient font re-use between different pages.</li>
  <li>Use Font Loading API to optimize the Critical Rendering Path: default lazyloading behavior may result in delayed text rendering. Font Loading API allows us to override this behavior for particular fonts, and to specify custom rendering and timeout strategies for different content on the page. For older browsers that do not support the API, you can use the webfontloader JavaScript library or use the CSS inlining strategy.</li>
</ul>

<p><strong>Anatomy of a webfont</strong></p>

<p>A webfont is a collection of glyphs, and each glyph is a vector shape that describes a letter or symbol. As a result, the size of a particular font file is determined by two simple variables:</p>

<ul>
  <li>the complexity of the vector paths of each glyph</li>
  <li>the number of glyphs in a particular font</li>
</ul>

<p>Today there are four font container formats in use on the web: EOT, TTF, WOFF, and WOFF2.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/fonts.png" alt="fonts.png" /></p>

<p>Consider using <a href="http://en.wikipedia.org/wiki/Zopfli">Zopfli compression</a> for EOT, TTF, and WOFF formats. Zopfli is a zlib compatible compressor that delivers ~5% filesize reduction over gzip.</p>

<p><strong>Defining font family with @font-face</strong></p>

<p>format selection</p>

<p>A ‚Äúfull‚Äù webfont that includes all stylistic variants, which we may not need, plus all the glyphs, which may go unused, can easily result in a multi-megabyte download. To address this, the @font-face CSS rule is specifically designed to allow us to split the font family into a collection of resources: unicode subsets, distinct style variants, and so on.</p>

<p>The @font-face CSS at-rule allows us to define the location of a particular font resource, its style characteristics, and the Unicode codepoints for which it should be used. A combination of such @font-face declarations can be used to construct a ‚Äúfont family‚Äù, which the browser will use to evaluate which font resources need to be downloaded and applied to the current page.</p>

<p>Each @font-face declaration provides the name of the font family, which acts as a logical group of multiple declarations, font properties such as style, weight, and stretch, and the src descriptor that specifies a prioritized list of locations for the font resource.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/font_face_1.png" alt="font_face_1.png" /></p>

<p>The browser figures out which resources are required and will select the optimal format on our behalf.</p>

<p>Unicode-range subsetting</p>

<p>In addition to font properties such as style, weight, and stretch, the @font-face rule allows us to define a set of Unicode codepoints supported by each resource. This enables us to split a large Unicode font into smaller subsets (e.g. Latin, Cyrillic, Greek subsets) and only download the glyphs required to render the text on a particular page.</p>

<p>The use of unicode range subsets, and separate files for each stylistic variant of the font allows us to define a composite font family that is both faster and more efficient to download - the visitor will only download the variants and subsets it needs, and they are not forced to download subsets that they may never see or use on the page.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/font_face_2.png" alt="font_face_2.png" /></p>

<p>Unicode-range subsetting is particularly important for Asian languages, where the number of glyphs is much larger than in western languages and a typical ‚Äòfull‚Äô font is often measured in megabytes, instead of tens of kilobytes!</p>

<p>There is one small gotcha with unicode-range: <a href="http://caniuse.com/#feat=font-unicode-range">not all browser support it</a>. We have to fallback to providing a single font resource that contains all necessary subsets, and hide the rest from the browser. We can use the open-source <a href="https://github.com/behdad/fonttools/blob/master/Lib/fontTools/subset.py#L16">pyftsubset</a> tool to subset and optimize your fonts.</p>

<p>Font selection and synthesis</p>

<p>Each font family is composed of multiple stylistic variants (regular, bold, italic) and multiple weights for each style, each of which, in turn, may contain very different glyph shapes - e.g. different spacing, sizing, or a different shape altogether.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/font_size.png" alt="font_size.png" /></p>

<p>All other in-between variants (indicated in gray) are automatically mapped to the closest variant by the browser. Similar logic applies to italic variants. it‚Äôs a good idea to keep the number of variants small!</p>

<p>What happens if one of our CSS rules specifies a different font weight, or sets the font-style property to italic?</p>

<ul>
  <li>If an exact font match is not available the browser will substitute the closest match.</li>
  <li>If no stylistic match is found (e.g. we did not declare any italic variants in example above), then the browser will <strong>synthesize</strong> its own font variant.</li>
</ul>

<p>For best consistency and visual results you should not rely on font synthesis. Instead, minimize the number of used font variants and specify their locations, such that the browser can download them when they are used on the page.</p>

<p><strong>Optimizing loading and rendering</strong></p>

<p>Font requests are delayed until the render tree is constructed, which can result in delayed text rendering.</p>

<p>Lazy loading of fonts carries an important hidden implication that may delay text rendering: the browser must construct the render tree, which is dependent on the DOM and CSSOM trees, before it will know which font resources it will need to render the text. As a result, font requests are delayed well after other critical resources, and the browser may be blocked from rendering text until the resource is fetched.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/font_rendering.png" alt="font_rendering.png" /></p>

<p>Font requests are dispatched once render tree indicates which font variants are needed to render the specified text on the page</p>

<p>The ‚Äúrace‚Äù between the first paint of page content, which can be done shortly after the render tree is built, and the request for the font resource is what creates the ‚Äúblank text problem‚Äù where the browser may render page layout but omits any text.</p>

<ul>
  <li>Safari hold text rendering until the font download is complete.</li>
  <li>Chrome and Firefox hold font rendering for up to 3 seconds, after which they use a fallback font, and once the font download has finished they re-render the text once more with the downloaded font.</li>
  <li>IE immediately renders with the fallback font if the request font is not yet available, and re-renders it once the font download is complete.</li>
</ul>

<p>Optimizing font rendering with the Font Loading API</p>

<p>Font Loading API provides a scripting interface to define and manipulate CSS font faces, track their download progress, and override their default lazyload behavior.</p>

<p>If we‚Äôre certain that a particular font variant will be required, we can define it and tell the browser to initiate an immediate fetch of the font resource:</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/font_loading_api.png" alt="font_loading_api.png" /></p>

<ul>
  <li>We can hold all text rendering until the font is available.</li>
  <li>We can implement a custom timeout for each font.</li>
  <li>We can use the fallback font to unblock rendering and inject a new style that uses desired font once the font is available.</li>
</ul>

<p>Optimizing font rendering with inlining</p>

<p>To inline the font contents into a CSS stylesheet:</p>

<ul>
  <li>CSS stylesheets with matching media queries are automatically downloaded by the browser with high priority as they are required to construct the CSSOM.</li>
  <li>Inlining the font data into CSS stylesheet forces the browser to download the font with high priority and without waiting for the render tree - i.e. this acts as a manual override to the default lazyload behavior.</li>
</ul>

<p>Optimizing font reuse with HTTP Caching</p>

<p>Font resources are, typically, static resources that don‚Äôt see frequent updates. As a result, they are ideally suited for a long max-age expiry.</p>

<p>There is no need to store fonts in localStorage or via other mechanisms - each of those has their set of performance gotchas. The browser‚Äôs HTTP cache, in combination with Font Loading API or the webfontloader library, provides the best and most robust mechanism to deliver font resources to the browser.</p>

<h3 id="http-caching">HTTP caching</h3>

<p>The combination of ETag, Cache-Control, and unique URLs allows us to deliver the best of all worlds: long-lived expiry times, control over where the response can be cached, and on-demand updates.</p>

<ul>
  <li>Use consistent URLs: if you serve the same content on different URLs, then that content will be fetched and stored multiple times. Tip: note that URLs are case sensitive!</li>
  <li>Ensure the server provides a validation token (ETag): validation tokens eliminate the need to transfer the same bytes when a resource has not changed on the server.</li>
  <li>Identify which resources can be cached by intermediaries: those with responses that are identical for all users are great candidates to be cached by a CDN and other intermediaries.</li>
  <li>Determine the optimal cache lifetime for each resource: different resources may have different freshness requirements. Audit and determine the appropriate max-age for each one.</li>
  <li>Determine the best cache hierarchy for your site: the combination of resource URLs with content fingerprints, and short or no-cache lifetimes for HTML documents allows you to control how quickly updates are picked up by the client.</li>
  <li>Minimize churn: some resources are updated more frequently than others. If there is a particular part of resource (e.g. JavaScript function, or set of CSS styles) that are often updated, consider delivering that code as a separate file. Doing so allows the remainder of the content (e.g. library code that does not change very often), to be fetched from cache and minimizes the amount of downloaded content whenever an update is fetched.</li>
</ul>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/http_caching.png" alt="http_caching.png" /></p>

<p><strong>Validating cached responses with ETags</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/http_caching_with_ETags.png" alt="http_caching_with_ETags.png" /></p>

<ul>
  <li>Validation token is communicated by the server via the ETag HTTP header</li>
  <li>Validation token enables efficient resource update checks: no data transfer if the resource has not changed.</li>
</ul>

<p><strong>Cache-Control</strong></p>

<ul>
  <li>Each resource can define its caching policy via Cache-Control HTTP header</li>
  <li>Cache-Control directives control who can cache the response, under which conditions, and for how long</li>
</ul>

<p>Cache-Control header was defined as part of the HTTP/1.1 specification and supersedes previous headers (e.g. Expires) used to define response caching policies. All modern browsers support Cache-Control, hence that is all we will need.</p>

<p>‚Äúno-cache‚Äù indicates that the returned response cannot be used to satisfy a subsequent request to the same URL without first checking with the server if the response has changed. As a result, if a proper validation token (ETag) is present, no-cache will incur a roundtrip to validate the cached response, but can eliminate the download if the resource has not changed.</p>

<p>‚Äúno-store‚Äù is much simpler, as it simply disallows the browser and all intermediate caches to store any version of the returned response - e.g. one containing private personal or banking data.</p>

<p>If the response is marked as ‚Äúpublic‚Äù then it can be cached, even if it has HTTP authentication associated with it, and even when the response status code isn‚Äôt normally cacheable. Most of the time, ‚Äúpublic‚Äù isn‚Äôt necessary, because explicit caching information (like ‚Äúmax-age‚Äù) indicates that the response is cacheable anyway.</p>

<p>‚Äúprivate‚Äù responses can be cached by the browser but are typically intended for a single user and hence are not allowed to be cached by any intermediate cache - e.g. an HTML page with private user information can be cached by that user‚Äôs browser, but not by a CDN.</p>

<p>‚Äúmax-age‚Äù specifies the maximum time in seconds that the fetched response is allowed to be reused for from the time of the request.</p>

<p><strong>Defining optimal Cache-Control policy</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/http_cache_control_policy.png" alt="http_cache_control_policy.png" /></p>

<p><strong>Invalidating and updating cached responses</strong></p>

<p>What if we want to update or invalidate a cached response? For example, let‚Äôs say we‚Äôve told our visitors to cache a CSS stylesheet for up to 24 hours (max-age=86400), but our designer has just committed an update that we would like to make available to all users. How do we notify all the visitors with what is now a ‚Äústale‚Äù cached copy of our CSS to update their caches? It‚Äôs a trick question - we can‚Äôt, at least not without changing the URL of the resource.</p>

<p>Simple, we can change the URL of the resource and force the user to download the new response whenever its content changes. Typically, this is done by embedding a fingerprint of the file, or a version number, in its filename - e.g. style.x234dff.css.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/http_update_cache_by_fingerprints.png" alt="http_update_cache_by_fingerprints.png" /></p>

<p>The ability to define per-resource caching policies allows us to define ‚Äúcache hierarchies‚Äù that allow us to control not only how long each is cached for, but also how quickly new versions are seen by visitor.</p>

<p>The HTML is marked with ‚Äúno-cache‚Äù, which means that the browser will always revalidate the document on each request and fetch the latest version if the contents change. Also, within the HTML markup we embed fingerprints in the URLs for CSS and JavaScript assets: if the contents of those files change, then the HTML of the page will change as well and new copy of the HTML response will be downloaded.</p>

<h2 id="critical-rendering-path">Critical Rendering Path</h2>

<h3 id="critical-rendering-path-1">Critical Rendering Path</h3>

<p>Optimizing for performance is all about understanding what happens in these intermediate steps between receiving the HTML, CSS, and JavaScript bytes and the required processing to turn them into rendered pixels - that‚Äôs the critical rendering path.</p>

<p>By optimizing the critical rendering path we can significantly improve the time to first render of our pages. Further, understanding the critical rendering path will also serve as a foundation for building well performing interactive applications. It turns out, the process for processing interactive updates is the same, just done in a continuous loop and ideally at 60 frames per second!</p>

<ul>
  <li>Process HTML markup and build the <strong>DOM tree</strong>.</li>
  <li>Process CSS markup and build the <strong>CSSOM tree</strong>.</li>
  <li>Combine the DOM and CSSOM into a <strong>render tree</strong>.</li>
  <li>Run <strong>layout</strong> on the render tree to compute geometry of each node.</li>
  <li><strong>Paint</strong> the individual nodes to the screen.</li>
</ul>

<p>Optimizing the critical rendering path is the process of minimizing the total amount of time spent in steps 1 through 5 in the above sequence. Doing so enables us to render content to the screen as soon as possible and also to reduces the amount of time between screen updates after the initial render.</p>

<p><strong>DOM</strong></p>

<p>The Document Object Model (DOM) is an application programming interface (API) for valid HTML and well-formed XML documents. It defines the logical structure of documents and the way a document is accessed and manipulated.</p>

<p>from <a href="http://www.w3.org/TR/DOM-Level-2-Core/introduction.html">http://www.w3.org/TR/DOM-Level-2-Core/introduction.html</a></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/dom_construction.png" alt="dom_construction.png" /></p>

<p>Every time the browser has to process HTML markup it has to step through all of the steps above: convert bytes to characters, identify tokens, convert tokens to nodes, and build the DOM tree.</p>

<p><strong>CSSOM</strong></p>

<p>The DOM tree captures the properties and relationships of the document markup, but it does not tell us anything about how the element should look when rendered. That‚Äôs the responsibility of the CSSOM.</p>

<p>The CSS bytes are converted into characters, then to tokens and nodes, and finally are linked into a tree structure known as the ‚ÄúCSS Object Model‚Äù, or CSSOM for short:</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/cssom_construction.png" alt="cssom_construction.png" /></p>

<p><strong><em>Is this the complete CSSOM?</em></strong></p>

<p>No. Note that the above tree is not the complete CSSOM tree and only shows the styles we decided to
override in our stylesheet. Every browser provides a default set of styles also known as ‚Äúuser agent styles‚Äù ‚Äì that‚Äôs what we see when we don‚Äôt provide any of our own ‚Äì and our styles simply override these defaults.</p>

<p><strong><em>Why does the CSSOM have a tree structure?</em></strong></p>

<p>When computing the final set of styles for any object on the page, the browser starts with the most general rule applicable to that node (e.g. if it is a child of body element, then all body styles apply) and then recursively refines the computed styles by applying more specific rules - i.e. the rules ‚Äúcascade down‚Äù.</p>

<p><strong><em>Curious to know how long the CSS processing took?</em></strong></p>

<p>Record a timeline in DevTools and look for ‚ÄúRecalculate Style‚Äù event: unlike DOM parsing, the timeline doesn‚Äôt show a separate ‚ÄúParse CSS‚Äù entry, and instead captures parsing and CSSOM tree construction, plus the recursive calculation of computed styles under this one event.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/css_render_timeline.png" alt="css_render_timeline.png" /></p>

<p><strong><em>Why we say that CSS is render blocking?</em></strong></p>

<p>Review the rendering process, DOM and CSSOM construct the render tree, then calculate layout, and paint. So CSS is a rendering blocking resource which blocks on rendering process.</p>

<p><strong><em>Why do browsers match CSS selectors from right to left?</em></strong></p>

<p>It sounds like that it is done this way to avoid having to look at all the children of parent (which could be many) rather than all the parents of a child which must be one. Even if the DOM is deep it would only look at one node per level rather than multiple in the RTL matching. </p>

<p>from <a href="http://stackoverflow.com/questions/5797014/why-do-browsers-match-css-selectors-from-right-to-left">Why do browsers match CSS selectors from right to left?</a></p>

<p><strong>Render Blocking CSS</strong></p>

<ul>
  <li>Get it down to the client as soon and as quickly as possible to optimize the time to first render</li>
  <li>Use media types and queries to unblock rendering</li>
</ul>

<p>By default CSS is treated as a render blocking resource, which means that the browser will hold rendering of any processed content until the CSSOM is constructed. Note that ‚Äúrender blocking‚Äù only refers to whether the browser will have to hold the initial rendering of the page on that resource. In either case, the CSS asset is still downloaded by the browser, albeit with a lower priority for non-blocking resources (like images).</p>

<p><strong><em>How to make it non-blocking?</em></strong></p>

<p>By using media queries, our presentation can be tailored to specific use cases such as display vs. print, and also to dynamic conditions such as changes in screen orientation, resize events, and more. When declaring your stylesheet assets, pay close attention to the media type and queries, as they will have big performance impact on the critical rendering path!</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="html"><span class="line"><span class="nt">&lt;link</span> <span class="na">href=</span><span class="s">&quot;style.css&quot;</span>    <span class="na">rel=</span><span class="s">&quot;stylesheet&quot;</span><span class="nt">&gt;</span>
</span><span class="line"><span class="nt">&lt;link</span> <span class="na">href=</span><span class="s">&quot;style.css&quot;</span>    <span class="na">rel=</span><span class="s">&quot;stylesheet&quot;</span> <span class="na">media=</span><span class="s">&quot;all&quot;</span><span class="nt">&gt;</span>
</span><span class="line"><span class="nt">&lt;link</span> <span class="na">href=</span><span class="s">&quot;portrait.css&quot;</span> <span class="na">rel=</span><span class="s">&quot;stylesheet&quot;</span> <span class="na">media=</span><span class="s">&quot;orientation:portrait&quot;</span><span class="nt">&gt;</span>
</span><span class="line"><span class="nt">&lt;link</span> <span class="na">href=</span><span class="s">&quot;print.css&quot;</span>    <span class="na">rel=</span><span class="s">&quot;stylesheet&quot;</span> <span class="na">media=</span><span class="s">&quot;print&quot;</span><span class="nt">&gt;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The third declaration has a dynamic media query which will be evaluated when the page is being loaded. Depending on the orientation of the device when the page is being loaded, portrait.css may or may not be render blocking.</p>

<p>The last declaration is only applied when the page is being printed, hence it is not render blocking when the page is first loaded in the browser.</p>

<p><strong>Render Tree</strong></p>

<p>The CSSOM and DOM trees are combined into a render tree, which is then used to</p>

<ul>
  <li>compute the layout of each visible element</li>
  <li>serves as an input to the paint process which renders the pixels to screen</li>
</ul>

<p>Render tree contains only the nodes required to render the page.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/render_tree_construction.png" alt="render_tree_construction.png" /></p>

<p><strong>Layout Stage</strong></p>

<p>The layout stage calculates the exact position and size within the viewport of the device.</p>

<p>The output of the layout process is a ‚Äúbox model‚Äù which precisely captures the exact position and size of each element within the viewport: all of the relative measures are converted to absolute pixels positions on the screen, and so on.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/layout_timeline.png" alt="layout_timeline.png" /></p>

<p><strong>Painting Stage</strong></p>

<p>Now that we know which nodes are visible, their computed styles, and geometry, we can finally pass this information to our final stage which will convert each node in the render tree to actual pixels on the screen - this step is often referred to as ‚Äúpainting‚Äù or ‚Äúrasterizing.‚Äù</p>

<p><strong><em>Can painting happen in the meantime dom is parsing?</em></strong></p>

<p>This is a gradual process: browsers won‚Äôt wait until all HTML is parsed. Parts of the content will be parsed and displayed, while the process continues with the rest of the contents that keeps coming from the network.</p>

<p>from <a href="http://stackoverflow.com/questions/34269416/when-does-parsing-html-dom-tree-happen">pesla‚Äôs answer</a> in SO</p>

<p><strong>Image</strong></p>

<p>Not all resources are critical to deliver the fast first paint. Images do not block the initial render of the page - although, of course, we should try to make sure that we get the images painted as soon as possible also.</p>

<p>Image don‚Äôt block on domContentLoaded, but blocks ‚Äúload‚Äù event.</p>

<p><strong>Javascript</strong></p>

<ul>
  <li>The location of the script in the document is significant.</li>
  <li>JavaScript can query and modify DOM and CSSOM.</li>
  <li>JavaScript execution blocks on CSSOM.</li>
  <li>JavaScript blocks DOM construction unless explicitly declared as async or defer</li>
</ul>

<p>The location of the script in the document is significant. The script is executed at the exact point where it is inserted in the document. When the HTML parser encounters a script tag, it pauses its process of constructing the DOM and yields control over to the JavaScript engine; once the JavaScript engine has finished running, the browser then picks up from where it left off and resumes the DOM construction.</p>

<p><strong><em>Why we say that JavaScript is parser blocking?</em></strong></p>

<p>It means JavaScript will block the DOM tree parsing process. And also, as it has dependency on CSSOM, so the total process is, DOM parsing blocks on JavaScript execution, and JavaScript execution blocks on CSSOM construction. That‚Äôs why we put the CSS link ref in head, and put the JavaScript link just before the close body tag.</p>

<p><strong><em>What if the browser hasn‚Äôt finished downloading and building the CSSOM when we want to run our script?</em></strong></p>

<p>The browser will delay script execution until it has finished downloading and constructing the CSSOM, and while we‚Äôre waiting, the DOM construction is also blocked!</p>

<p><strong><em>What‚Äôs the difference between inline script and external script?</em></strong></p>

<p>Javascript is the same as the CSS and images, being a resource of the HTML, which all need a process of downloading and executing.</p>

<p>The inline script has no extra downloading time, compared to external script, but has the same execution time.</p>

<p><strong><em>Where is the best place to put JavaScript?</em></strong></p>

<p>Library may place in the head, and application logic js is better placed right before closing body tag.</p>

<p>You don‚Äôt improve the total parsing time by including <code>&lt;script&gt;</code> at the end of the document. It does enhance the user experience, as the process of parsing and painting isn‚Äôt interrupted by <code>&lt;script&gt;</code> that need to be executed.</p>

<p><strong>Navigation Timing API</strong> (Measuring the Critical Rendering Path)</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/navigation_timing_api.png" alt="navigation_timing_api.png" /></p>

<ul>
  <li><em>domLoading</em>: this is the starting timestamp of the entire process, the browser is about to start parsing the first received bytes of the HTML document.</li>
  <li><em>domInteractive</em>: marks when DOM is ready.</li>
  <li><em>domContentLoaded</em>: marks the point when both the DOM is ready and there are no stylesheets that are blocking JavaScript execution - meaning we can now (potentially) construct the render tree. Typically marks when both the DOM and CSSOM are ready. The sooner the domContentLoaded event fires, the sooner other application logic can begin executing. jQuery‚Äôs $(document).ready() is hooked on domContentLoaded.</li>
  <li><em>loadEvent</em>: as a final step in every page load the browser fires an onload event which can trigger additional application logic.</li>
</ul>

<h3 id="analysing-critical-rendering-path-performance">Analysing Critical Rendering Path Performance</h3>

<ul>
  <li><strong>Critical Resource</strong>: resource that may block initial rendering of the page.</li>
  <li><strong>Critical Path Length</strong>: number of roundtrips, or the total time required to fetch all of the critical resources.</li>
  <li><strong>Critical Bytes</strong>: total amount of bytes required to get to first render of the page, which is the sum of the transfer filesizes of all critical resources. Our first example with a single HTML page contained a single critical resource (the HTML document), the critical path length was also equal to 1 network roundtrip (assuming file is small), and the total critical bytes was just the transfer size of the HTML document itself.</li>
</ul>

<p><strong>Without Javascript and CSS</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/without_js_and_css_timeline.png" alt="without_js_and_css_timeline.png" /></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/without_js_and_css_crp_diagram.png" alt="without_js_and_css_crp_diagram.png" /></p>

<ul>
  <li>1 critical resource</li>
  <li>1 roundtrip</li>
  <li>5 KB of critical bytes</li>
</ul>

<p><strong>With Only CSS</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/with_only_css_crp_diagram.png" alt="with_only_css_crp_diagram.png" /></p>

<ul>
  <li>2 critical resources</li>
  <li>2 or more roundtrips for the minimum critical path length</li>
  <li>9 KB of critical bytes</li>
</ul>

<p><strong>With JavaScript and CSS</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/with_js_and_css_timeline.png" alt="with_js_and_css_timeline.png" /></p>

<p>As Javascript blocks the DOM construction, also depends on the CSSOM, so the domContentLoaded event is blocked until the CSS file is downloaded and parsed.</p>

<p>I‚Äôm confusing on the image for a long long time! Finally, when I‚Äôm making this note, I get things through. Watch closely to the blue and red line. Blue line fires when the CSSOM has been created. And then Javascript executes, image downloads over, there fires the red line.</p>

<p>Remember, what does domContentLoaded mean? Marks the point when both the DOM is ready and there are no stylesheets that are blocking JavaScript execution - meaning we can now (potentially) construct the render tree. Typically marks when both the DOM and CSSOM are ready.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/with_js_and_css_crp_diagram.png" alt="with_js_and_css_crp_diagram.png" /></p>

<ul>
  <li>3 critical resources</li>
  <li>2 or more roundtrips for the minimum critical path length</li>
  <li>11 KB of critical bytes</li>
</ul>

<p><strong>With JavaScript (inline) and CSS</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/with_js_inline_and_css_timeline.png" alt="with_js_inline_and_css_timeline.png" /></p>

<p>Same time as the external Javascript, only without downloading process.</p>

<p><strong>With Javascript (inline) and CSS (inline)</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/with_js_inline_and_css_inline_timeline.png" alt="with_js_inline_and_css_inline_timeline.png" /></p>

<p><strong>With JavaScript (async) and CSS</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/with_js_async_and_css_timeline.png" alt="with_js_async_and_css_timeline.png" /></p>

<p>Much better! The domContentLoaded event fires shortly after the HTML is parsed: the browser knows not to block on JavaScript and since there are no other parser blocking scripts the CSSOM construction can also proceed in parallel.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/with_js_async_and_css_crp_diagram.png" alt="with_js_async_and_css_crp_diagram.png" /></p>

<ul>
  <li>2 critical resources (HTML and CSS)</li>
  <li>2 or more roundtrips for the minimum critical path length</li>
  <li>9 KB of critical bytes</li>
</ul>

<p><strong>With Javascript (async) and CSS (non-blocking)</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/with_js_async_and_css_non_block_crp_diagram.png.png" alt="with_js_async_and_css_non_block_crp_diagram.png.png" /></p>

<ul>
  <li>1 critical resource</li>
  <li>1 or more roundtrips for the minimum critical path length</li>
  <li>5 KB of critical bytes</li>
</ul>

<p>Demo and CRP diagram</p>

<p>Code from <a href="https://github.com/igrigorik/udacity-webperf/blob/master/assets/ex2-diagram.html">https://github.com/igrigorik/udacity-webperf/blob/master/assets/ex2-diagram.html</a></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
</pre></td><td class="code"><pre><code class="html"><span class="line"><span class="nt">&lt;html&gt;</span>
</span><span class="line">  <span class="nt">&lt;head&gt;</span>
</span><span class="line">    <span class="nt">&lt;meta</span> <span class="na">name=</span><span class="s">&quot;viewport&quot;</span> <span class="na">content=</span><span class="s">&quot;width=device-width&quot;</span><span class="nt">&gt;</span>
</span><span class="line">    <span class="nt">&lt;link</span> <span class="na">href=</span><span class="s">&quot;style.css&quot;</span> <span class="na">rel=</span><span class="s">&quot;stylesheet&quot;</span><span class="nt">&gt;</span>
</span><span class="line">    <span class="nt">&lt;link</span> <span class="na">href=</span><span class="s">&quot;print.css&quot;</span> <span class="na">rel=</span><span class="s">&quot;stylesheet&quot;</span> <span class="na">media=</span><span class="s">&quot;print&quot;</span><span class="nt">&gt;</span>
</span><span class="line">  <span class="nt">&lt;/head&gt;</span>
</span><span class="line">  <span class="nt">&lt;body&gt;</span>
</span><span class="line">    <span class="nt">&lt;p&gt;</span>
</span><span class="line">      Hello <span class="nt">&lt;span&gt;</span>web performance<span class="nt">&lt;/span&gt;</span> students!
</span><span class="line">    <span class="nt">&lt;/p&gt;</span>
</span><span class="line">    <span class="nt">&lt;div&gt;&lt;img</span> <span class="na">src=</span><span class="s">&quot;awesome-photo.jpg&quot;</span><span class="nt">&gt;&lt;/div&gt;</span>
</span><span class="line">    <span class="nt">&lt;script </span><span class="na">src=</span><span class="s">&quot;app.js&quot;</span><span class="nt">&gt;&lt;/script&gt;</span>
</span><span class="line">    <span class="nt">&lt;script </span><span class="na">src=</span><span class="s">&quot;analytics.js&quot;</span> <span class="na">async</span><span class="nt">&gt;&lt;/script&gt;</span>
</span><span class="line">  <span class="nt">&lt;/body&gt;</span>
</span><span class="line"><span class="nt">&lt;/html&gt;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>CRP diagram by <a href="https://discussions.udacity.com/t/quiz-crp-diagrams/16162/11?u=ifyouseewendy">connie_273453529</a></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/demo_crp_diagram_by_connie.png" alt="demo_crp_diagram_by_connie.png" /></p>

<ul>
  <li>3 critical resources</li>
  <li>total (HTML file + style.css + app.js) critical bytes</li>
  <li>2 roundtrip for the minimum critical path length</li>
</ul>

<h3 id="optimizing-the-critical-rendering-path">Optimizing the critical rendering path</h3>

<p><strong>Basic idea</strong></p>

<ul>
  <li>Minimize the number of critical resources.</li>
  <li>Minimize the number of critical bytes.</li>
  <li>Minimize the critical path length.</li>
</ul>

<p>To reduce the number of bytes we can reduce the number of resources (eliminate them or make them non-critical), and also ensure that we minimize the transfer size by compressing and optimizing each resource.</p>

<p>The fewer of these resources there are on the page, the less work the browser has to do to get content on the screen, and the less contention there is for CPU and other resources.</p>

<p>The critical path length is a function of the dependency graph between all the critical resources required by the page and their bytesize: some resource downloads can only be initiated once a previous resource has been processed, and the larger the resource the more roundtrips it will take us to download it.</p>

<p>The general sequence of steps to optimize the critical rendering path is:</p>

<ul>
  <li>Analyze and characterize your critical path: number of resources, bytes, length.</li>
  <li>Minimize number of critical resources: eliminate them, defer their download, mark them as async, etc.</li>
  <li>Optimize the order in which the remaining critical resources are loaded: you want to download all critical assets as early as possible to shorten the critical path length.</li>
  <li>Optimize the number of critical bytes to reduce the download time (number of roundtrips).</li>
</ul>

<p>The cardinal rule of web performance is, measure first, then optimize.</p>

<p><strong>Optimize JavaScript Use</strong></p>

<ul>
  <li>Prefer async JavaScript resources</li>
  <li>Defer parsing JavaScript</li>
  <li>Avoid synchronous server calls</li>
  <li>Avoid long running JavaScript</li>
</ul>

<p>Any initialization logic and functionality that is non-essential for the first render should be deferred until later. If a long initialization sequence needs to be run, consider splitting it into several stages to allow the browser to process other events in between.</p>

<p>async vs. defer</p>

<p>from <a href="http://www.growingwiththeweb.com/2014/02/async-vs-defer-attributes.html">async vs defer attributes</a></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/web-performance-optimization/async_vs_defer.png" alt="async_vs_defer.png" /></p>

<p><strong>Optimize CSS Use</strong></p>

<ul>
  <li>Put CSS in the document head</li>
  <li>Avoid CSS imports. CSS import (@import) directive enables one stylesheet to import rules from another stylesheet file. However, these directives should be avoided because they introduce additional roundtrips into the critical path: the imported CSS resources are discovered only after the CSS stylesheet with the @import rule itself has been received and parsed.</li>
  <li>Inline render-blocking CSS</li>
</ul>

<p><strong>The Preload Scanner</strong></p>

<p>from <a href="http://andydavies.me/blog/2013/10/22/how-the-browser-pre-loader-makes-pages-load-faster/">How the Browser Pre-loader Makes Pages Load Faster</a></p>

<p>Internet Explorer, WebKit and Mozilla all implemented pre-loaders in 2008 as a way of overcoming the low network utilisation while waiting for scripts to download and execute.</p>

<p>When the browser is blocked on a script, a second lightweight parser scans the rest of the markup looking for other resources e.g. stylesheets, scripts, images etc., that also need to be retrieved.</p>

<p>The pre-loader then starts retrieving these resources in the background with the aim that by the time the main HTML parser reaches them they may have already been downloaded and so reduce blocking later in the page.</p>

<p><strong>Others</strong></p>

<ul>
  <li><a href="http://www.stevesouders.com/blog/2009/05/18/flushing-the-document-early/">Flushing the Document Early</a></li>
  <li><a href="http://blog.cowchimp.com/chunk-scatter-http-chunked-response-analysis-tool/">Chunk Scatter, a fantastic tool for visualizing chunked HTTP responses</a></li>
  <li><a href="https://developer.chrome.com/devtools/docs/timeline">Performance profiling with the Timeline</a></li>
  <li><a href="http://www.webpagetest.org/forums/showthread.php?tid=10990">Record a Chrome dev tools timeline by webpagetest</a></li>
</ul>

<p><strong><em>Why should I profile the site on my phone?</em></strong></p>

<p>Chances are, you are developing your site on a fast laptop or a desktop machine. Mobile phones on the other hand are much more resource constrained: slower CPUs, less RAM and GPU memory, higher connection latencies, and so on. As a result, you should always try to profile and debug your site on mobile hardware to get a better and closer picture of how your users will experience your site on their handset.</p>

<h2 id="browser-rendering-optimization">Browser Rendering Optimization</h2>

<blockquote>
  <p>TODO <a href="https://www.udacity.com/course/browser-rendering-optimization--ud860">https://www.udacity.com/course/browser-rendering-optimization‚Äìud860</a></p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Some Hash Tricks in Ruby]]></title>
    <link href="http://blog.ifyouseewendy.com/blog/2015/11/30/some-hash-tricks-in-ruby/"/>
    <updated>2015-11-30T16:17:38+08:00</updated>
    <id>http://blog.ifyouseewendy.com/blog/2015/11/30/some-hash-tricks-in-ruby</id>
    <content type="html"><![CDATA[<blockquote>
  <p>from <a href="http://blog.honeybadger.io/advanced-ruby-hash-techniques/">http://blog.honeybadger.io/advanced-ruby-hash-techniques/</a></p>
</blockquote>

<h3 id="strict-fetching">Strict fetching</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="n">h</span> <span class="o">=</span> <span class="no">Hash</span><span class="o">.</span><span class="n">new</span> <span class="p">{</span> <span class="o">|</span><span class="nb">hash</span><span class="p">,</span> <span class="n">key</span><span class="o">|</span> <span class="k">raise</span> <span class="no">ArgumentError</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="s2">&quot;No hash key: </span><span class="si">#{</span> <span class="n">key</span> <span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="p">}</span>
</span><span class="line"><span class="n">h</span><span class="o">[</span><span class="ss">:a</span><span class="o">]=</span><span class="mi">1</span>
</span><span class="line"><span class="n">h</span><span class="o">[</span><span class="ss">:a</span><span class="o">]</span> <span class="c1"># 1</span>
</span><span class="line"><span class="n">h</span><span class="o">[</span><span class="ss">:x</span><span class="o">]</span> <span class="c1"># raises ArgumentError: No hash key: x</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="modifying-defaults-after-initialization">Modifying defaults after initialization</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="n">h</span><span class="o">=</span><span class="p">{}</span>
</span><span class="line"><span class="n">h</span><span class="o">[</span><span class="ss">:a</span><span class="o">]</span> <span class="c1"># nil</span>
</span><span class="line"><span class="n">h</span><span class="o">.</span><span class="n">default</span> <span class="o">=</span> <span class="s2">&quot;new default&quot;</span>
</span><span class="line"><span class="n">h</span><span class="o">[</span><span class="ss">:a</span><span class="o">]</span> <span class="c1"># &quot;new default&quot;</span>
</span><span class="line">
</span><span class="line"><span class="n">h</span><span class="o">.</span><span class="n">default_proc</span> <span class="o">=</span> <span class="no">Proc</span><span class="o">.</span><span class="n">new</span> <span class="p">{</span> <span class="no">Time</span><span class="o">.</span><span class="n">now</span><span class="o">.</span><span class="n">to_i</span> <span class="p">}</span>
</span><span class="line"><span class="n">h</span><span class="o">[</span><span class="ss">:a</span><span class="o">]</span> <span class="c1"># 1435684014</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="factorial-using-hash">Factorial using Hash</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="n">factorial</span> <span class="o">=</span> <span class="no">Hash</span><span class="o">.</span><span class="n">new</span><span class="p">{</span><span class="o">|</span><span class="n">h</span><span class="p">,</span><span class="n">k</span><span class="o">|</span> <span class="n">k</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="o">?</span> <span class="n">h</span><span class="o">[</span><span class="n">k</span><span class="o">]</span> <span class="o">=</span> <span class="n">h</span><span class="o">[</span><span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="o">]*</span><span class="n">k</span> <span class="p">:</span> <span class="n">h</span><span class="o">[</span><span class="n">k</span><span class="o">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="p">}</span>
</span><span class="line"><span class="no">Factorail</span><span class="o">[</span><span class="mi">4</span><span class="o">]</span> <span class="c1"># =&gt; 24</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="a-game-of-lazily-infinite-nested-hashes">A game of lazily infinite nested hashes</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="n">generator</span> <span class="o">=</span> <span class="no">Proc</span><span class="o">.</span><span class="n">new</span> <span class="k">do</span> <span class="o">|</span><span class="nb">hash</span><span class="p">,</span> <span class="n">key</span><span class="o">|</span>
</span><span class="line">  <span class="nb">hash</span><span class="o">[</span><span class="n">key</span><span class="o">]</span> <span class="o">=</span> <span class="no">Hash</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="o">&amp;</span><span class="n">generator</span><span class="p">)</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span> <span class="o">[</span><span class="s1">&#39;n&#39;</span><span class="p">,</span> <span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="s1">&#39;e&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="o">][</span><span class="nb">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="o">]</span> <span class="o">=&gt;</span> <span class="s1">&#39;You found me&#39;</span> <span class="p">)</span>
</span><span class="line"><span class="k">end</span>
</span><span class="line"><span class="n">dungeon</span> <span class="o">=</span> <span class="no">Hash</span><span class="o">.</span><span class="n">new</span> <span class="o">&amp;</span><span class="n">generator</span>
</span><span class="line"><span class="n">dungeon</span><span class="o">[</span><span class="s1">&#39;n&#39;</span><span class="o">]</span>            <span class="c1"># =&gt; { &quot;s&quot; =&gt; &quot;You found me&quot; }</span>
</span><span class="line"><span class="n">dungeon</span><span class="o">[</span><span class="s1">&#39;n&#39;</span><span class="o">][</span><span class="s1">&#39;w&#39;</span><span class="o">]</span>       <span class="c1"># =&gt; { &quot;e&quot; =&gt; &quot;You found me&quot; }</span>
</span><span class="line"><span class="n">dungeon</span><span class="o">[</span><span class="s1">&#39;n&#39;</span><span class="o">][</span><span class="s1">&#39;w&#39;</span><span class="o">][</span><span class="s1">&#39;e&#39;</span><span class="o">]</span>  <span class="c1"># =&gt; &quot;You found me&quot;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<blockquote>
  <p>from <a href="https://endofline.wordpress.com/2010/12/24/hash-tricks/">https://endofline.wordpress.com/2010/12/24/hash-tricks</a></p>
</blockquote>

<h3 id="hash-returns-hashes-to-build-a-tree-structure">Hash returns hashes, to build a tree structure</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="n">tree_block</span> <span class="o">=</span> <span class="o">-&gt;</span><span class="p">(</span><span class="nb">hash</span><span class="p">,</span><span class="n">k</span><span class="p">){</span> <span class="nb">hash</span><span class="o">[</span><span class="n">k</span><span class="o">]</span> <span class="o">=</span> <span class="no">Hash</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="o">&amp;</span><span class="n">tree_block</span><span class="p">)</span> <span class="p">}</span>
</span><span class="line"><span class="n">opts</span> <span class="o">=</span> <span class="no">Hash</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="o">&amp;</span><span class="n">tree_block</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">opts</span><span class="o">[</span><span class="s1">&#39;dev&#39;</span><span class="o">][</span><span class="s1">&#39;db&#39;</span><span class="o">][</span><span class="s1">&#39;host&#39;</span><span class="o">]</span> <span class="o">=</span> <span class="s2">&quot;localhost:2828&quot;</span>
</span><span class="line"><span class="n">opts</span><span class="o">[</span><span class="s1">&#39;dev&#39;</span><span class="o">][</span><span class="s1">&#39;db&#39;</span><span class="o">][</span><span class="s1">&#39;user&#39;</span><span class="o">]</span> <span class="o">=</span> <span class="s2">&quot;me&quot;</span>
</span><span class="line"><span class="n">opts</span><span class="o">[</span><span class="s1">&#39;dev&#39;</span><span class="o">][</span><span class="s1">&#39;db&#39;</span><span class="o">][</span><span class="s1">&#39;password&#39;</span><span class="o">]</span> <span class="o">=</span> <span class="s2">&quot;secret&quot;</span>
</span><span class="line"><span class="n">opts</span><span class="o">[</span><span class="s1">&#39;test&#39;</span><span class="o">][</span><span class="s1">&#39;db&#39;</span><span class="o">][</span><span class="s1">&#39;host&#39;</span><span class="o">]</span> <span class="o">=</span> <span class="s2">&quot;localhost:2828&quot;</span>
</span><span class="line"><span class="n">opts</span><span class="o">[</span><span class="s1">&#39;test&#39;</span><span class="o">][</span><span class="s1">&#39;db&#39;</span><span class="o">][</span><span class="s1">&#39;user&#39;</span><span class="o">]</span> <span class="o">=</span> <span class="s2">&quot;test_user&quot;</span>
</span><span class="line"><span class="n">opts</span><span class="o">[</span><span class="s1">&#39;test&#39;</span><span class="o">][</span><span class="s1">&#39;db&#39;</span><span class="o">][</span><span class="s1">&#39;password&#39;</span><span class="o">]</span> <span class="o">=</span> <span class="s2">&quot;test_secret&quot;</span>
</span><span class="line"><span class="n">opts</span>
</span><span class="line"><span class="c1"># =&gt; {</span>
</span><span class="line">  <span class="s2">&quot;dev&quot;</span>  <span class="o">=&gt;</span> <span class="p">{</span>
</span><span class="line">    <span class="s2">&quot;db&quot;</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span><span class="line">      <span class="s2">&quot;host&quot;</span>     <span class="o">=&gt;</span> <span class="s2">&quot;localhost:2828&quot;</span><span class="p">,</span>
</span><span class="line">      <span class="s2">&quot;user&quot;</span>     <span class="o">=&gt;</span> <span class="s2">&quot;me&quot;</span><span class="p">,</span>
</span><span class="line">      <span class="s2">&quot;password&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;secret&quot;</span>
</span><span class="line">    <span class="p">}</span>
</span><span class="line">  <span class="p">},</span>
</span><span class="line">  <span class="s2">&quot;test&quot;</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span><span class="line">    <span class="s2">&quot;db&quot;</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span><span class="line">      <span class="s2">&quot;host&quot;</span>     <span class="o">=&gt;</span> <span class="s2">&quot;localhost:2828&quot;</span><span class="p">,</span>
</span><span class="line">      <span class="s2">&quot;user&quot;</span>     <span class="o">=&gt;</span> <span class="s2">&quot;test_user&quot;</span><span class="p">,</span>
</span><span class="line">      <span class="s2">&quot;password&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;test_secret&quot;</span>
</span><span class="line">    <span class="p">}</span>
</span><span class="line">  <span class="p">}</span>
</span><span class="line"><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="use-hash-as-a-method">Use hash as a method</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="nb">require</span> <span class="s1">&#39;net/http&#39;</span>
</span><span class="line"><span class="n">http</span> <span class="o">=</span> <span class="no">Hash</span><span class="o">.</span><span class="n">new</span> <span class="k">do</span> <span class="o">|</span><span class="n">h</span><span class="p">,</span><span class="n">k</span><span class="o">|</span>
</span><span class="line">  <span class="n">h</span><span class="o">[</span><span class="n">k</span><span class="o">]</span> <span class="o">=</span> <span class="ss">Net</span><span class="p">:</span><span class="ss">:HTTP</span><span class="o">.</span><span class="n">get_response</span><span class="p">(</span><span class="no">URI</span><span class="p">(</span><span class="n">k</span><span class="p">))</span><span class="o">.</span><span class="n">body</span>
</span><span class="line">  <span class="n">h</span><span class="o">.</span><span class="n">delete</span> <span class="n">h</span><span class="o">.</span><span class="n">keys</span><span class="o">.</span><span class="n">first</span> <span class="k">if</span> <span class="n">h</span><span class="o">.</span><span class="n">length</span> <span class="o">&gt;</span> <span class="mi">3</span> <span class="c1"># a caching layer</span>
</span><span class="line">  <span class="n">h</span>
</span><span class="line"><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<blockquote>
  <p>from Amadan posted on <a href="https://www.reddit.com/r/ruby/comments/29hr4x/whats_youre_favorite_ruby_trick_or_quirk_thata">https://www.reddit.com/r/ruby/comments/29hr4x/whats_youre_favorite_ruby_trick_or_quirk_thata</a></p>
</blockquote>

<h3 id="autovivifying-hashes-are-cool">Autovivifying hashes are cool</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="n">autohash</span> <span class="o">=</span> <span class="no">Hash</span><span class="o">.</span><span class="n">new</span> <span class="p">{</span> <span class="o">|</span><span class="n">h</span><span class="p">,</span> <span class="n">k</span><span class="o">|</span> <span class="n">h</span><span class="o">[</span><span class="n">k</span><span class="o">]</span> <span class="o">=</span> <span class="no">Hash</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="o">&amp;</span><span class="n">h</span><span class="o">.</span><span class="n">default_proc</span><span class="p">)</span> <span class="p">}</span>
</span><span class="line"><span class="n">autohash</span><span class="o">[</span><span class="mi">1</span><span class="o">][</span><span class="mi">2</span><span class="o">][</span><span class="mi">3</span><span class="o">][</span><span class="mi">4</span><span class="o">][</span><span class="mi">5</span><span class="o">][</span><span class="mi">6</span><span class="o">][</span><span class="mi">7</span><span class="o">]</span> <span class="o">=</span> <span class="mi">8</span>
</span><span class="line"><span class="n">autohash</span> <span class="c1"># =&gt; {1=&gt;{2=&gt;{3=&gt;{4=&gt;{5=&gt;{6=&gt;{7=&gt;8}}}}}}}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<blockquote>
  <p>from The Buckblog <a href="http://weblog.jamisbuck.org/2015/11/14/little-things-refactoring-with-hashes.html">http://weblog.jamisbuck.org/2015/11/14/little-things-refactoring-with-hashes.html</a></p>
</blockquote>

<h3 id="refactor-case-statement">Refactor case statement</h3>

<p>before</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="n">klass</span> <span class="o">=</span> <span class="k">case</span> <span class="n">params</span><span class="o">[</span><span class="ss">:student_level</span><span class="o">]</span>
</span><span class="line">  <span class="k">when</span> <span class="ss">:freshman</span><span class="p">,</span> <span class="ss">:sophomore</span> <span class="k">then</span>
</span><span class="line">    <span class="ss">Student</span><span class="p">:</span><span class="ss">:Underclassman</span>
</span><span class="line">  <span class="k">when</span> <span class="ss">:junior</span><span class="p">,</span> <span class="ss">:senior</span> <span class="k">then</span>
</span><span class="line">    <span class="ss">Student</span><span class="p">:</span><span class="ss">:Upperclassman</span>
</span><span class="line">  <span class="k">when</span> <span class="ss">:graduate</span>
</span><span class="line">    <span class="ss">Student</span><span class="p">:</span><span class="ss">:Graduate</span>
</span><span class="line">  <span class="k">else</span>
</span><span class="line">    <span class="ss">Student</span><span class="p">:</span><span class="ss">:Unregistered</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line"><span class="n">student</span> <span class="o">=</span> <span class="n">klass</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="nb">name</span><span class="p">,</span> <span class="n">birthdate</span><span class="p">,</span> <span class="n">address</span><span class="p">,</span> <span class="n">phone</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>after</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="no">STUDENT_LEVELS</span> <span class="o">=</span> <span class="no">Hash</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="ss">Student</span><span class="p">:</span><span class="ss">:Unregistered</span><span class="p">)</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span>
</span><span class="line">  <span class="ss">freshman</span><span class="p">:</span> <span class="ss">Student</span><span class="p">:</span><span class="ss">:Underclassman</span><span class="p">,</span>
</span><span class="line">  <span class="ss">sophomore</span><span class="p">:</span> <span class="ss">Student</span><span class="p">:</span><span class="ss">:Underclassman</span><span class="p">,</span>
</span><span class="line">  <span class="ss">junior</span><span class="p">:</span>    <span class="ss">Student</span><span class="p">:</span><span class="ss">:Upperclassman</span><span class="p">,</span>
</span><span class="line">  <span class="ss">senior</span><span class="p">:</span>    <span class="ss">Student</span><span class="p">:</span><span class="ss">:Upperclassman</span><span class="p">,</span>
</span><span class="line">  <span class="ss">graduate</span><span class="p">:</span>  <span class="ss">Student</span><span class="p">:</span><span class="ss">:Graduate</span>
</span><span class="line"><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">klass</span> <span class="o">=</span> <span class="no">STUDENT_LEVELS</span><span class="o">[</span><span class="n">params</span><span class="o">[</span><span class="ss">:student_level</span><span class="o">]]</span>
</span><span class="line"><span class="n">student</span> <span class="o">=</span> <span class="n">klass</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="nb">name</span><span class="p">,</span> <span class="n">birthdate</span><span class="p">,</span> <span class="n">address</span><span class="p">,</span> <span class="n">phone</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Review] Virtualization - Operating Systems Three Easy Pieces]]></title>
    <link href="http://blog.ifyouseewendy.com/blog/2015/11/22/review-virtualization-operating-systems-three-easy-pieces/"/>
    <updated>2015-11-22T13:44:38+08:00</updated>
    <id>http://blog.ifyouseewendy.com/blog/2015/11/22/review-virtualization-operating-systems-three-easy-pieces</id>
    <content type="html"><![CDATA[<table class="custom">
  <tbody>
    <tr>
      <td><strong>Book</strong></td>
      <td>Operating Systems: Three Easy Pieces</td>
    </tr>
    <tr>
      <td><strong>Author</strong></td>
      <td><a href="http://www.cs.wisc.edu/~remzi">Remzi H. Arpaci-Dusseau</a> and <a href="http://www.cs.wisc.edu/~dusseau">Andrea C. Arpaci-Dusseau</a></td>
    </tr>
    <tr>
      <td><strong>Link</strong></td>
      <td><a href="http://pages.cs.wisc.edu/~remzi/OSTEP/">pages.cs.wisc.edu/~remzi/OSTEP</a></td>
    </tr>
  </tbody>
</table>

<ul id="markdown-toc">
  <li><a href="#introduction">Introduction</a></li>
  <li><a href="#cpu-virtualisation">CPU Virtualisation</a>    <ul>
      <li><a href="#process">Process</a>        <ul>
          <li><a href="#chapter-4---the-abstraction-the-process">Chapter 4 - The Abstraction: The Process</a></li>
          <li><a href="#chapter-5---interlude-process-api">Chapter 5 - Interlude: Process API</a></li>
        </ul>
      </li>
      <li><a href="#mechanism">Mechanism</a>        <ul>
          <li><a href="#chapter-6---mechanism-limited-direct-execution">Chapter 6 - Mechanism: Limited Direct Execution</a></li>
        </ul>
      </li>
      <li><a href="#scheduling">Scheduling</a>        <ul>
          <li><a href="#chapter-7---scheduling-introduction">Chapter 7 - Scheduling: Introduction</a></li>
          <li><a href="#chapter-8---scheduling-the-multi-level-feedback-queue">Chapter 8 - Scheduling: The Multi-Level Feedback Queue</a></li>
          <li><a href="#chapter-9---scheduling-proportional-share">Chapter 9 - Scheduling: Proportional Share</a></li>
          <li><a href="#chapter-10---multiprocessor-scheduling">Chapter 10 - Multiprocessor Scheduling</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#memory-virtualisation">Memory Virtualisation</a>    <ul>
      <li><a href="#address-space">Address Space</a>        <ul>
          <li><a href="#chapter-13---the-abstraction-address-spaces">Chapter 13 - The Abstraction: Address Spaces</a></li>
          <li><a href="#chapter-14---interlude-memory-api">Chapter 14 - Interlude: Memory API</a></li>
        </ul>
      </li>
      <li><a href="#dynamic-allocation-and-segmentation">Dynamic Allocation and Segmentation</a>        <ul>
          <li><a href="#chapter-15---mechanism-address-translation">Chapter 15 - Mechanism: Address Translation</a></li>
          <li><a href="#chapter-16-segmentation">Chapter 16 Segmentation</a></li>
          <li><a href="#chapter-17---free-space-management">Chapter 17 - Free-Space Management</a></li>
        </ul>
      </li>
      <li><a href="#paging">Paging</a>        <ul>
          <li><a href="#chapter-18---paging-introduction">Chapter 18 - Paging: Introduction</a></li>
          <li><a href="#chapter-19---paging-faster-translations-tlbs">Chapter 19 - Paging: Faster Translations (TLBs)</a></li>
          <li><a href="#note-on-cache-management">Note on Cache Management</a></li>
          <li><a href="#chapter-20---paging-smaller-tables">Chapter 20 - Paging: Smaller Tables</a></li>
        </ul>
      </li>
      <li><a href="#beyond-physical-memory">Beyond Physical Memory</a>        <ul>
          <li><a href="#chapter-21---beyond-physical-memory-mechanisms">Chapter 21 - Beyond Physical Memory: Mechanisms</a></li>
          <li><a href="#chapter-22---beyond-physical-memory-policies">Chapter 22 - Beyond Physical Memory: Policies</a></li>
          <li><a href="#chapter-23---the-vaxvms-virtual-memory-system">Chapter 23 - The VAX/VMS Virtual Memory System</a></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h1 id="introduction">Introduction</h1>

<p><strong>The Crux of the whole book</strong></p>

<p>How does the operating system virtualize resources?
What mechanisms and policies are implemented by the OS to attain virtualization?
How does the OS do so efficiently?</p>

<p><strong>The Von Neumann model of computing</strong></p>

<p>Many millions (and these days, even billions) of times every second, the processor <strong>fetches</strong> an instruction from memory, <strong>decodes</strong> it (i.e., figures out which instruction this is), and <strong>executes</strong> it.</p>

<p><strong>The OS is sometimes known as a resource manager</strong></p>

<p>The primary way the OS does this is through a general technique that we call virtualization. That is, the OS takes a physical resource (such as the processor, or memory, or a disk) and transforms it into a more general, powerful, and easy-to-use virtual form of itself. Thus, we sometimes refer to the operating system as a <strong>virtual machine</strong>.</p>

<p><strong>Virtualizing the CPU</strong></p>

<p>Turning a single CPU (or small set of them) into a seemingly infinite number of CPUs and thus allowing many programs to seemingly run at once is what we call virtualizing the CPU.</p>

<p><strong>Virtualizing the Memory</strong></p>

<p>Memory is just an array of bytes; to <strong>read</strong> memory, one must specify an <strong>address</strong> to be able to access the data stored there; to <strong>write</strong> (or update) memory, one must also specify the data to be written to the given address.</p>

<p>The OS is virtualizing memory. Each process accesses its own private <strong>virtual address space</strong> (sometimes just called its address space)</p>

<p><strong>Concurrency</strong></p>

<p>Three instructions: one to <strong>load</strong> the value of the counter from memory into a register, one to <strong>increment</strong> it, and one to <strong>store</strong> it back into memory. Because these three instructions do not execute atomically (all at once), strange things can happen.</p>

<p><strong>Persistence</strong></p>

<p>The software in the operating system that usually manages the disk is called the <strong>file system</strong>; it is thus responsible for storing any files the user creates in a reliable and efficient manner on the disks of the system.</p>

<p>For performance reasos, most file systems first <strong>delay</strong> such writes for a while, hoping to batch them into larger groups. To handle the problems of system crashes during writes, most file systems incorporate some kind of intricate write protocol, such as <strong>journaling</strong> or <strong>copy-on-write</strong>, carefully ordering writes to disk to ensure that if a failure occurs during the write sequence, the system can recover to reasonable state afterwards.</p>

<p><strong>Design Goals</strong></p>

<p>What an OS actually does: it takes physical <strong>resources</strong>, such as a CPU, memory, or disk, and <strong>virtualizes</strong> them. It handles tough and tricky issues related to <strong>concurrency</strong>. And it stores files <strong>persistently</strong>, thus making them safe over the long-term.</p>

<ol>
  <li>To build up some <strong>abstractions</strong> in order to make the system convenient and easy to use.</li>
  <li>To provide high <strong>performance</strong>, another way to say this is our goal is to minimize the overheads of the OS.</li>
  <li>To provide <strong>protection</strong> between applications, as well as between the OS and applications. Protection is at nthe heart of one of the main principles underlying an operating system, which is that of <strong>isolation</strong>; isolating processes from one another is the key to protection and thus underlies much of what an OS must do.</li>
</ol>

<p><strong>Some History</strong></p>

<ol>
  <li>Early Operating Systems: Just Libraries.  This mode of computing was known as <strong>batch</strong> processing.</li>
  <li>Beyond Libraries: Protection. The idea of a system call was invented. The key difference between a <strong>system call</strong> and a <strong>procedure call</strong> is that a system call transfers control (i.e., jumps) into the OS while simultaneously raising the hardware privilege level. User applications run in what is referred to as user mode which means the hardware restricts what applications can do; When a system call is initiated (usually through a special hardware instruction called a trap), the hardware transfers control to a pre-specified trap handler (that the OS set up previously) and simultaneously raises the privilege level to kernel mode.</li>
  <li>The Era of Multiprogramming by minicomputer. In particular, multiprogramming became commonplace due to the desire to make better use of machine resources. One of the major practical advances of the time was the introduction of the <strong>UNIX</strong> operating system, primarily thanks to <strong>Ken Thompson</strong> (and <strong>Dennis Ritchie</strong>) at Bell Labs (yes, the phone company). <strong>Bill Joy</strong>, made a wonderful distribution (the Berkeley Systems Distribution, or <strong>BSD</strong>) which had some advanced virtual memory, file system, and networking subsystems. Joy later co-founded Sun Microsystems.</li>
  <li>The Modern Era by PC with DOS, Mac OS.</li>
</ol>

<h1 id="cpu-virtualisation">CPU Virtualisation</h1>

<h2 id="process">Process</h2>

<h3 id="chapter-4---the-abstraction-the-process">Chapter 4 - The Abstraction: The Process</h3>

<p><strong>Process</strong></p>

<p>The definition of a process, informally, is quite simple: it is a running program.</p>

<p><strong>How to provide the illusion of many CPUs?</strong></p>

<p>This basic technique, known as <strong>time sharing</strong> of the CPU, allows users to run as many concurrent processes as they would like; the potential cost is performance, as each will run more slowly if the CPU(s) must be shared.</p>

<p><strong>Mechanisms</strong></p>

<p>Mechanisms are low-level methods or protocols that implement a needed piece of functionality.</p>

<p><strong>Policies</strong></p>

<p>On top of these mechanisms resides some of the intelligence in the OS, in the form of policies.</p>

<p><strong>Tip: Separate policy and mechanism</strong></p>

<p>In many operating systems, a common design paradigm is to separate high-level policies from their low-level mechanisms. You can think of the mechanism as providing the answer to a <strong>how</strong> question about a system; for example, how does an operating system perform a context switch? The policy provides the answer
 to a <strong>which</strong> question; for example, which process should the operating system run right now?</p>

<p><strong>Machine State</strong></p>

<p>To understand what constitutes a process, we thus have to understand its <strong>machine state</strong>: what a program can read or update when it is running. At any given time, what parts of the machine are important to the execution of this program?</p>

<ol>
  <li>Memory. The memory that the process can address (called its <strong>address space</strong>) is part of the process.</li>
  <li>Registry. There are some particularly special registers that form part of this machine state. For example, the <strong>program counter</strong> (PC) (sometimes called the instruction pointer or IP). similarly a stack pointer and associated <strong>frame pointer</strong> are used to manage the stack for function parameters, local variables, and return addresses.</li>
  <li>I/O information. Programs often access persistent storage devices too. Such I/O information might include a list of the files the process currently has open.</li>
</ol>

<p><strong>Process API</strong></p>

<ol>
  <li>Create</li>
  <li>Destroy</li>
  <li>Wait</li>
  <li>Miscellaneous Control (suspend, resume)</li>
  <li>Status</li>
</ol>

<p><strong>How does the OS get a program up and running?</strong></p>

<ol>
  <li>To <strong>load</strong> its code and any static data (e.g., initialized variables) into memory, into the <strong>address space</strong> of the process. In early (or simple) operating systems, the loading process is done <strong>eagerly</strong>; modern OSes perform the process <strong>lazily</strong>, i.e., by loading pieces of code or data only as they are needed during program execution. To truly understand how lazy loading of pieces of code and data works, you‚Äôll have to understand more about the machinery of <strong>paging</strong> and <strong>swapping</strong>.</li>
  <li>Once the code and static data are loaded into memory, there are a few other things the OS needs to do before running the process. Some memory must be allocated for the program‚Äôs <strong>run-time stack</strong> (or just stack). As you should likely already know, C programs use the stack for local variables, function parameters, and return addresses; the OS allocates this memory and gives it to the process.</li>
  <li>The OS may also allocate some memory for the program‚Äôs <strong>heap</strong>. In C programs, the heap is used for explicitly requested dynamically-allocated data; programs request such space by calling malloc() and free it explicitly by calling free(). The heap is needed for data structures such as linked lists, hash tables, trees, and other interesting data structures.</li>
  <li>The OS will also do some other initialization tasks, particularly as related to input/output (I/O). For example, in UNIX systems, each process by default has three open <strong>file descriptors</strong>.</li>
  <li>To start the program running at the entry point, namely main(), the OS transfers control of the CPU to the newly-created process, and thus the program begins its execution.</li>
</ol>

<p><strong>Process States</strong></p>

<ol>
  <li>Running</li>
  <li>Ready</li>
  <li>Blocked</li>
</ol>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-process_state_transitions.png" alt="os-process_state_transitions.png" /></p>

<p><strong>Data Structures</strong></p>

<p>To track the state of each process, for example, the OS likely will keep some kind of <strong>process list</strong> for all processes that are ready, as well as some additional information to track which process is currently running.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-the_xv6_proc_structure.png" alt="os-the_xv6_proc_structure.png" /></p>

<p>The <strong>register context</strong> will hold, for a stopped process, the contents of its registers. When a process is stopped, its registers will be saved to this memory location; by restoring these registers (i.e., placing their values back into the actual physical registers), the OS can resume running the process.</p>

<p>Sometimes people refer to the individual structure that stores information about a process as a <strong>Process Control Block (PCB)</strong>.</p>

<h3 id="chapter-5---interlude-process-api">Chapter 5 - Interlude: Process API</h3>

<p>UNIX presents one of the most intriguing ways to create a new process with a pair of system calls:</p>

<p><strong>fork()</strong></p>

<p>The newly-created process (called the <strong>child</strong>, in contrast to the creating <strong>parent</strong>) desn‚Äôt start running at main(), like you might expect (note, the ‚Äúhello, world‚Äù message only got printed out once); rather, it just comes into life as if it had called fork() itself. You might have noticed: the child isn‚Äôt an exact copy. Specifically, al- though it now has its own copy of the address space (i.e., its own private memory), its own registers, its own PC, and so forth, the value it returns to the caller of fork() is different.</p>

<p>The output is <strong>not deterministic</strong>. When the child process is created, there are now two active processes in the system that we care about: the parent and the child.</p>

<p><strong>wait()</strong></p>

<p>Adding a wait() call to the code above makes the output <strong>deterministic</strong>.</p>

<p><strong>exec()</strong></p>

<p>It does not create a new process; rather, it transforms the currently running program (formerly p3) into a different running program (wc). After the exec() in the child, it is almost as if p3.c never ran; a successful call to exec() never returns.</p>

<p><strong>Why? Motivating The API</strong></p>

<p>Why would we build sucho an odd interface to what should be the simple act of creating a new process? Well, as it turns out, the separation of fork() and exec() is essential in building a UNIX shell, because it lets the shell run code after the call to fork() but before the call to exec(); this code can alter the environment of the about-to-be-run program, and thus enables a variety of interesting features to be readily built.</p>

<p><strong>How Does Shell Utilise The API?</strong></p>

<p>The shell is just a user program.</p>

<ol>
  <li>It shows you a prompt and then waits for you to type something into it.</li>
  <li>You then type a command (i.e., the name of an executable program, plus any arguments) into it;</li>
  <li>In most cases, the shell then figures out where in the file system the executable resides</li>
  <li>calls fork() to create a new child process to run the command</li>
  <li>calls some variant of exec() to run the command</li>
  <li>waits for the command to complete by calling wait().</li>
  <li>When the child completes, the shell returns from wait() and prints out a prompt again, ready for your next command.</li>
</ol>

<p>eg. prompt&gt; wc p3.c &gt; newfile.txt</p>

<p>When the child is created, before calling exec(), the shell closes standard output and opens the file newfile.txt.</p>

<h2 id="mechanism">Mechanism</h2>

<h3 id="chapter-6---mechanism-limited-direct-execution">Chapter 6 - Mechanism: Limited Direct Execution</h3>

<p><strong>The Crux</strong></p>

<ul>
  <li>performance: how can we implement virtualization without adding excessive overhead to the system?</li>
  <li>control: how can we run processes efficiently while retaining control over the CPU?</li>
</ul>

<p>Attaining performance while maintaining control is thus one of the central challenges in building an operating system.</p>

<p><strong>Basic Technique: Limited Direct Execution</strong></p>

<p>The basic idea is straightforward: just run the program you want to run on the CPU, but first make sure to set up the hardware so as to limit what the process can do without OS assistance.</p>

<p>In an analogous manner, the OS ‚Äúbaby proofs‚Äù the CPU, by first (during boot time) setting up the <strong>trap handlers</strong> and starting an <strong>interrupt timer</strong>, and then by only running processes in a restricted mode. By doing so, the OS can feel quite assured that processes can run efficiently, only requir- ing OS intervention to perform privileged operations or when they have monopolized the CPU for too long and thus need to be switched out.</p>

<p><strong>Problem #1: Restricted Operations</strong></p>

<p>Use Protected Control Transfer</p>

<p>The hardware assists the OS by providing different modes of execution. In <strong>user mode</strong>, applications do not have full access to hardware resources. In <strong>kernel mode</strong>, the OS has access to the full resources of the machine. When the user process wants to perform some kinds of privileged operation, it can perform a <strong>system call</strong>.</p>

<p><strong>System Call</strong></p>

<p>To execute a system call, a program must execute a special <strong>trap</strong> instruction. This instruction simultaneously jumps into the kernel and raises the privilege level to kernel mode; once in the kernel, the system can now per- form whatever privileged operations are needed (if allowed), and thus do the required work for the calling process. When finished, the OS calls a special <strong>return-from-trap</strong> instruction</p>

<p><strong>Why System Calls Look Like Procedure Calls?</strong></p>

<p>It is a procedure call, but hidden inside that procedure call is the famous trap instruction. More specifically, when you call open() (for example), you are executing a procedure call into the C library. The parts of the C library that make system calls are hand-coded in assembly, as they need to carefully follow convention in order to process arguments and return values correctly, as well as execute the hardware-specific trap instruction. And now you know why you personally don‚Äôt have to write assembly code to trap into an OS; somebody has already written that assembly for you.</p>

<p><strong>How does the trap know which code to run inside the OS?</strong></p>

<p>The kernel does so by setting up a <strong>trap table</strong> at boot time. When the machine boots up, it does so in privileged (kernel) mode, and thus is free to configure machine hardware as need be. The OS informs the hardware of the locations of these <strong>trap handlers</strong>.</p>

<p><strong>Limited Direct Execution Protocol</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-limited_directed_execution_protocol.png" alt="os-limited_directed_execution_protocol.png" /></p>

<p>There are two phases in the LDE protocol:</p>

<p>In the first (at boot time), the kernel initializes the <strong>trap table</strong>, and the CPU remembers its location for subsequent use.</p>

<p>In the second (when running a process), the kernel sets up a few things (e.g., allocating a node on the process list, allocating memory) before using a <strong>return-from-trap</strong> instruction to start the execution of the process; this switches the CPU to user mode and begins running the process.</p>

<p>Normal flow:</p>

<p>When the process wishes to issue a system call, it traps back into the OS, which handles it and once again returns control via a return-from-trap to the process. The process then completes its work, and returns from main(); this usually will return into some stub code which will properly exit the program (say, by calling the exit() system call, which traps into the OS).</p>

<p><strong>Problem #2: Switching Between Processes</strong></p>

<p>How can the operating system regain control of the CPU so that it can switch between processes?</p>

<p>In a <strong>cooperative</strong> scheduling system, the OS regains control of the CPU by waiting for a system call or an illegal operation of some kind to take place.</p>

<p>How can the OS gain control of the CPU even if processes are not being cooperative? What can the OS do to ensure a rogue process does not take over the machine?</p>

<p><strong>Timer Interrupt</strong></p>

<p>A timer device can be programmed to raise an interrupt every so many milliseconds; when the interrupt is raised, the currently running process is halted, and a pre-configured interrupt handler in the OS runs. At this point, the OS has regained control of the CPU, and thus can do what it pleases: stop the current process, and start a different one.</p>

<p>The OS must inform the hardware of which code to run when the timer interrupt occurs; thus, at boot time, the OS does exactly that. Second, also during the boot sequence, the OS must start the timer, which is of course a privileged operation.</p>

<p><strong>Scheduler</strong></p>

<p>Whether to continue running the currently-running process, or switch to a different one. This decision is made by a part of the operating system known as the scheduler.</p>

<p>If the decision is made to switch, the OS then executes a low-level piece of code which we refer to as a <strong>context switch</strong>. A context switch is conceptually simple: all the OS has to do is save a few register values for the currently-executing process (onto its kernel stack, for example) and restore a few for the soon-to-be-executing process (from its kernel stack).</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-timer_interrupt.png" alt="os-timer_interrupt.png" /></p>

<h2 id="scheduling">Scheduling</h2>

<h3 id="chapter-7---scheduling-introduction">Chapter 7 - Scheduling: Introduction</h3>

<p><strong>Scheduling Metrics</strong></p>

<ul>
  <li>performance
    <ul>
      <li>turnaround = T(completion) - T(arrival)</li>
      <li>responsive time = T(first run) - T(arrival)</li>
    </ul>
  </li>
  <li>fairness</li>
</ul>

<p>Performance and fairness are often at odds in scheduling.</p>

<p>The introduction of time-shared machines changed all that. Now users would sit at a terminal and demand interactive performance from the system as well. And thus, a new metric was born: response time.</p>

<p><strong>Assumption</strong></p>

<ol>
  <li>Each job runs for the same amount of time.</li>
  <li>All jobs arrive at the same time.</li>
  <li>Once started, each job runs to completion.</li>
  <li>All jobs only use the CPU (i.e., they perform no I/O)</li>
  <li>The run-time (length) of each job is known.</li>
</ol>

<p><strong>Policy 1-1 FIFO</strong></p>

<p>under assumption: 1,2,3,4,5</p>

<p>Given our assumptions about jobs all arriving at the same time, we could prove that SJF is indeed an optimal scheduling algorithm.</p>

<p><strong>Policy 1-2 SJF (Shortest Job First)</strong></p>

<p>under assumption: <del>1,</del>2,3,4,5</p>

<p>Why is FIFO not good?</p>

<p>If Assumption(1) is false, there will be the <strong>convoy effect</strong>, where a number of relatively-short potential consumers of a resource get queued behind a heavyweight resource consumer.</p>

<p>Is SJF preemptive?</p>

<p>No, it‚Äôs <strong>non-preemptive</strong>. In the old days of batch computing, a number of non-preemptive scheulers were developed; such systems would run each job to completi before considering whether to run a new job. Virtually all modern schedulers are <strong>preemptive</strong>, and quite willing to stop one process from running in order to run another.</p>

<p><strong>Policy 1-3 STCF (Shortest Time-to-Completion First) or PSJF (Preemptive Shortest Job First)</strong></p>

<p>under assumption: <del>1,2,3,</del>4,5</p>

<p>Notice that there a significant difference between SJF and STCF. As SJF is non-preemptive, system would run each job to completion before running other jobs. But STCF prefers the shortest time-to-completion jobs, which should preempt CPU to make sense. That‚Äôs why STCF also has another name, PSFJ, Preemptive Shortest Job First.</p>

<p><strong>Policy 2 RR (Round-Robin)</strong></p>

<p>The basic idea is simple: instead of running jobs to completion, RR runs a job for a <strong>time slice</strong> (sometimes called a scheduling quantum) and then switches to the next job in the run queue.</p>

<p>The length of the time slice is critical for RR. The shorter it is, the better the performance of RR under the response-time metric. However, making the time slice too short is problematic: suddenly the cost of context switching will dominate overall performance. Thus, de- ciding on the length of the time slice presents a trade-off to a system de- signer, making it long enough to amortize the cost of switching without making it so long that the system is no longer responsive.</p>

<p>RR, with a reonasonable time slice, is thus an excellent scheduler if response time is our only metric. It is not surprising, then, that RR is indeed one of the worst policies if turnaround time is our metric.</p>

<p><strong>Policy 1 vs. Policy 2</strong></p>

<p>There is an inherent trade-off: if you are willing to be unfair, you can run shorter jobs to com- pletion, but at the cost of response time; if you instead value fairness, response time is lowered, but at the cost of turnaround time. This type of trade-off is common in systems</p>

<p><strong>Incorporate I/O by overlap</strong></p>

<p>under assumption: 4</p>

<p>We see how a scheduler might incorporate I/O. By treating each CPU burst as a job, the scheduler makes sure processes that are ‚Äúinteractive‚Äù get run frequently. While those interactive jobs are performing I/O, other CPU-intensive jobs run, thus better utilizing the processor.</p>

<h3 id="chapter-8---scheduling-the-multi-level-feedback-queue">Chapter 8 - Scheduling: The Multi-Level Feedback Queue</h3>

<p><strong>MLFQ</strong></p>

<p>it has <strong>multiple levels of queues</strong>, and <strong>uses feedback to determine the priority</strong> of a given job.</p>

<p>Instead of demanding a priori knowledge of the nature of a job, it observes the execution of a job and prioritizes it accordingly. In this way, it manages to achieve the best of both worlds: it can deliver excellent overall performance (similar to SJF/STCF) for short-running interactive jobs, and is fair and makes progress for long-running CPU-intensive workloads.</p>

<p><em>Multi-Level</em></p>

<p>The MLFQ has a number of distinct queues, each assigned a different <strong>priority level</strong>. At any given time, a job that is ready to run is on a single queue. MLFQ uses priorities to decide which job should run at a given time: a job with higher priority (i.e., a job on a higher queue) is chosen to run. Of course, more than one job may be on a given queue, and thus have the same priority. In this case, we will just use round-robin scheduling among those jobs.</p>

<p><em>Feedback</em></p>

<p>Thus, the key to MLFQ scheduling lies in how the scheduler sets priorities. Rather than giving a fixed priority to each job, MLFQ varies the priority of a job based on its observed behavior.</p>

<p><strong>How To Change Priority</strong></p>

<p>Rule 3: When a job enters the system, it is placed at the highest priority (the topmost queue).
Rule 4a: If a job uses up an entire time slice while running, its priority is reduced (i.e., it moves down one queue).
Rule 4b: If a job gives up the CPU before the time slice is up, it stays at the same priority level.</p>

<p><em>Problems</em></p>

<ol>
  <li>Starvation</li>
  <li>Smart user could rewrite their program to game the scheduler.</li>
  <li>A program may change its behavior over time; what was CPU-bound may transition to a phase of interactivity.</li>
</ol>

<p><strong>How to prevent gaming of our scheduler?</strong></p>

<p>Rules 4a and 4b, let a job retain its priority by relinquishing the CPU before the time slice expires. The solution here is to perform better <strong>accounting</strong> of CPU time at each level of the MLFQ. Instead of forgetting how much of a time slice a process used at a given level, the scheduler should keep track; once a process has used its allotment, it is demoted to the next priority queue.</p>

<p>Rule 4: Once a job uses up its time allotment at a given level (regardless of how many times it has given up the CPU), its priority is reduced (i.e., it moves down one queue).</p>

<p><strong>Priority Boost</strong></p>

<p>The simple idea here is to periodically boost the priority of all the jobs in system.</p>

<p>Rule 5: After some time period S, move all the jobs in the system to the topmost queue.</p>

<p><strong>Tuning MLFQ</strong></p>

<p>One big question is how to <strong>parameterize</strong> such a scheduler.</p>

<ul>
  <li>How many queues should there be?</li>
  <li>How big should the time slice be per queue?</li>
  <li>How often should priority be boosted in order to avoid starvation and account for changes in behavior?</li>
</ul>

<p><em>Some Variants</em></p>

<p>Most MLFQ variants allow for <strong>varying time-slice length</strong> across different queues. The high-priority queues are usually given short time slices; the low-priority queues, in contrast, contain long-running jobs that are CPU-bound; hence, longer time slices work well.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-lower_priority_longer_quanta.png" alt="os-lower_priority_longer_quanta.png" /></p>

<p>The FreeBSD scheduler (version 4.3) uses a formula to calculate the current priority level of a job, basing it on how much CPU the process has used.</p>

<p>Some schedulers reserve the highest priority levels for operating system work; thus typical user jobs can never obtain the highest levels of priority in the system. Some systems also allow some user advice to help set priorities; for example, by using the command-line utility nice.</p>

<p><strong>Refined Rules</strong></p>

<ul>
  <li>Rule 1: If Priority(A) &gt; Priority(B), A runs (B doesn‚Äôt).</li>
  <li>Rule 2: If Priority(A) = Priority(B), A &amp; B run in RR.</li>
  <li>Rule 3: When a job enters the system, it is placed at the highest priority (the topmost queue).</li>
  <li>Rule 4: Once a job uses up its time allotment at a given level (re- gardless of how many times it has given up the CPU), its priority is reduced (i.e., it moves down one queue).</li>
  <li>Rule 5: After some time period S, move all the jobs in the system to the topmost queue.</li>
</ul>

<h3 id="chapter-9---scheduling-proportional-share">Chapter 9 - Scheduling: Proportional Share</h3>

<p><strong>0. Basic Idea</strong></p>

<p><strong>Proportional-share scheduler</strong>, also sometimes referred to as a <strong>fair-share scheduler</strong>. Proportional-share is based around a simple concept: instead of optimizing for turnaround or response time, a scheduler might instead try to guarantee that each job obtain a certain percentage of CPU time.</p>

<p><strong>Implementations</strong></p>

<ul>
  <li><strong>lottery</strong> scheduling, lottery uses randomness in a clever way to achieve proportional share</li>
  <li><strong>stride</strong> scheduling, stride does so deterministically</li>
</ul>

<p><strong>Application</strong></p>

<p>One is that such approaches do not particularly mesh well with I/O [AC97]; another is that they leave open the hard problem of ticket assignment, i.e., how do you know how many tickets your browser should be allocated?</p>

<p>As a result, proportional-share schedulers are more useful in domains where some of these problems (such as assignment of shares) are rela- tively easy to solve. For example, in a virtualized data centre.</p>

<p><strong>1. Lottery Scheduling</strong></p>

<p>The basic idea is quite simple: every so often, hold a lottery to determine which process should get to run next; processes that should run more often should be given more chances to win the lottery. One of the most beautiful aspects of lottery scheduling is its use of randomness.</p>

<p><strong>Advantage</strong></p>

<ul>
  <li>randomness
    <ul>
      <li>First, random often avoids strange corner-case behaviors that a more traditional algorithm may have trouble handling.</li>
      <li>Second, random also is lightweight, requiring little state to track alternatives.</li>
      <li>Finally, random can be quite fast.</li>
    </ul>
  </li>
  <li>simplicity of implementation</li>
  <li>no global state</li>
</ul>

<p><strong>Disadvantage</strong></p>

<ul>
  <li>Hard to assign tickets to jobs</li>
  <li>Not deterministic. Only as the jobs run for a significant number of time slices does the lottery scheduler approach the desired outcome.</li>
</ul>

<p><strong>Ticket</strong></p>

<p>Tickets, which are used to represent the share of a resource that a process (or user or whatever) should receive. The percent of tickets that a process has represents its share of the system resource in question.</p>

<p><strong>Ticket Mechanisms</strong></p>

<p>Lottery scheduling also provides a number of mechanisms to manipulate tickets in different and sometimes useful ways.</p>

<ul>
  <li>ticket currency</li>
  <li>ticket transfer</li>
  <li>ticket inflation</li>
</ul>

<p><strong>Implementation</strong></p>

<p>Probably the most amazing thing about lottery scheduling is the simplicity of its implementation.</p>

<ul>
  <li>a good random number generator to pick the winning ticket</li>
  <li>a data structure to track the processes of the system (e.g., a list)</li>
  <li>the total number of tickets.</li>
</ul>

<p><strong>2. Stride Scheduling</strong></p>

<p>a <strong>deterministic</strong> fair-share scheduler.</p>

<p>Respectively, we can compute the stride of each by dividing some large number by the number of tickets each process has been assigned. We call this value the <strong>stride</strong> of each process.</p>

<p>Jobs A, B, and C, with 100, 50, and 250 tickets. if we divide 10,000 by each of those ticket values, we obtain the following stride values for A, B, and C: 100, 200, and 40.</p>

<p>Every time a process runs, we will increment a counter for it (called its <strong>pass</strong> value) by its stride to track its global progress. The scheduler then uses the stride and pass to determine which process should run next.</p>

<p>The basic idea is simple: at any given time, pick the process to run that has the lowest pass value so far; when you run a process, increment its pass counter by its stride.</p>

<p><strong>Advantage</strong></p>

<p>Lottery scheduling achieves the proportions probabilistically over time; stride scheduling gets them exactly right at the end of each scheduling cycle.</p>

<p><strong>Disadvantage</strong></p>

<p>Well, lottery scheduling has one nice property that stride scheduling does not: no global state. Imagine a new job enters in the middle of our stride scheduling example above; what should its pass value be? Should it be set to 0? If so, it will monopolize the CPU. With lottery scheduling, there is no global state per process; we simply add a new process with whatever tickets it has, update the single global variable to track how many total tickets we have, and go from there. In this way, lottery makes it much easier to incorporate new processes in a sensible manner.</p>

<h3 id="chapter-10---multiprocessor-scheduling">Chapter 10 - Multiprocessor Scheduling</h3>

<p><em>TODO after reading Concurrency</em></p>

<h1 id="memory-virtualisation">Memory Virtualisation</h1>

<h2 id="address-space">Address Space</h2>

<h3 id="chapter-13---the-abstraction-address-spaces">Chapter 13 - The Abstraction: Address Spaces</h3>

<p><strong>Multiprogramming</strong> (Â§öÈÅìÁ®ãÂ∫è), in which multiple processes were ready to run at a given time, and the OS would switch between them.</p>

<p><strong>Time sharing</strong>, One way to implement time sharing would be to run one process for a short while, giving it full access to all memory, then stop it, save all of its state to some kind of disk (including all of physical memory), load some other process‚Äôs state, run it for a while, and thus implement some kind of crude sharing of the machine. Unfortunately, this approach has a big problem: it is way too slow, particularly as memory grows.</p>

<p><strong>Address space</strong></p>

<p>Address space, easy to use abstraction of physical memory, and it is the running program‚Äôs view of memory in the system. Understanding this fundamental OS ab- straction of memory is key to understanding how memory is virtualized.</p>

<p>When the OS does this, we say the OS is <strong>virtualizing memory</strong>.</p>

<p><strong>Goals</strong></p>

<p>The VM system is responsible for providing the illusion of a large, sparse, private address space to programs, which hold all of their instructions and data therein.</p>

<ul>
  <li>transparency</li>
  <li>efficiency</li>
  <li>protection (isolation)</li>
</ul>

<p><strong>EVERY ADDRESS YOU SEE IS VIRTUAL</strong></p>

<p>Any address you can see as a programmer of a user-level program is a virtual address, if you print out an address in a program, it‚Äôs a virtual one.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-every_address_you_see_is_virtual.png" alt="os-every_address_you_see_is_virtual.png" /></p>

<h3 id="chapter-14---interlude-memory-api">Chapter 14 - Interlude: Memory API</h3>

<p><strong>Types of Memory</strong></p>

<ul>
  <li><strong>stack memory</strong>, allocations and deallocations of it are managed implicitly by the compiler for you, the programmer.</li>
  <li><strong>heap memory</strong>, it is this need for long-lived memory, where all allocations and deallocations are explicitly handled by you, the programmer.</li>
</ul>

<p>Example</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="c"><span class="line"><span class="kt">void</span> <span class="nf">func</span><span class="p">()</span> <span class="p">{</span>     <span class="kt">int</span> <span class="o">*</span><span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="p">)</span> <span class="n">malloc</span><span class="p">(</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>     <span class="p">...</span> <span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>First, you might no- tice that both stack and heap allocation occur on this line: first the com- piler knows to make room for a pointer to an integer when it sees your declaration of said pointer (int *x); subsequently, when the program calls malloc(), it requests space for an integer on the heap; the routine returns the address of such an integer (upon success, or NULL on failure), which is then stored on the stack for use by the program.</p>

<p><strong>API</strong></p>

<ul>
  <li><strong>malloc()</strong></li>
  <li><strong>free()</strong></li>
</ul>

<p>There are really two levels of memory management in the system. The first is level of memory management is performed by the OS, which hands out memory to processes when they run, and takes them back when processes exit (or otherwise die). The second level of management is within each process, for example within the heap when you call malloc() and free().</p>

<p>They are not system calls, but rather library calls. Thus the malloc library manages space within your virtual address space, but itself is built on top of some system calls.</p>

<ul>
  <li><strong>mmap()</strong></li>
</ul>

<p>You can also obtain memory from the operating system via the <code>mmap()</code> call. By passing in the correct arguments, mmap() can create an anonymous memory region within your program ‚Äî a region which is not associated with any particular file but rather with swap space. This memory can then also be treated like a heap and managed as such.</p>

<ul>
  <li><strong>calloc()</strong></li>
</ul>

<p>Allocates memory and also zeroes it before returning; this prevents some errors where you assume that memory is zeroed and forget to initialize it yourself.</p>

<ul>
  <li><strong>realloc()</strong></li>
</ul>

<p>when you‚Äôve allocated space for something (say, an array), and then need to add something to it: realloc() makes a new larger region of memory, copies the old region into it, and returns the pointer to the new region.</p>

<p><strong>Common Errors</strong></p>

<ul>
  <li>Forgetting To Allocate Memory - <strong>segmentation fault</strong>, which is a fancy term for YOU DID SOMETHING WRONG WITH MEMORY YOU FOOLISH PROGRAMMER AND I AM ANGRY. Forget to allocate memory.</li>
  <li>Not Allocating Enough Memory - <strong>buffer overflow</strong></li>
  <li>Forgetting to Initialize Allocated Memory - <strong>uninitialized read</strong></li>
  <li>Forgetting To Free Memory - <strong>memory leak</strong></li>
  <li>Freeing Memory Before You Are Done With It - <strong>dangling pointer</strong></li>
  <li>Freeing Memory Repeatedly - <strong>double free</strong></li>
</ul>

<p><strong>Tools</strong></p>

<ul>
  <li><strong>gdb</strong>, add -g flag to gcc, then run it with gdb. eg. gcc -g null.c -o null -Wall &amp;&amp; gdb null</li>
  <li><strong>valgrind</strong>, eg. valgrind ‚Äîleak-check=yes null</li>
</ul>

<h2 id="dynamic-allocation-and-segmentation">Dynamic Allocation and Segmentation</h2>

<h3 id="chapter-15---mechanism-address-translation">Chapter 15 - Mechanism: Address Translation</h3>

<p><strong>hardware-based address translation</strong></p>

<p>With address translation, the hardware transforms each memory access (e.g., an instruction fetch, load, or store), changing the <strong>virtual</strong> address provided by the instruction to a <strong>physical</strong> address where the desired information is actually located.</p>

<p>Transforming a virtual address into a physical address is exactly the technique we refer to as address translation.</p>

<p>Key to the efficiency of this technique is hardware support, which performs the translation quickly for each access, turning virtual addresses (the process‚Äôs view of memory) into physical ones (the actual view).</p>

<p><strong>Static (Software-based) Relocation</strong></p>

<p>A piece of software known as the loader takes an executable that is about to be run and rewrites its addresses to the desired offset in physical memory.</p>

<p><strong>Dynamic (Hardware-based) Relocation</strong></p>

<p>The <strong>base and bounds</strong> technique is also referred to as dynamic relocation. With dynamic relocation, a little hardware goes a long way. Namely, a <strong>base</strong> register is used to transform virtual addresses (generated by the program) into physical addresses. A <strong>bounds</strong> (or <strong>limit</strong>) register ensures that such addresses are within the confines of the address space. Together they provide a simple and efficient virtualization of memory.</p>

<p>Because this relocation of the address happens at runtime, and because we can move address spaces even after the process has started running, the technique is often referred to as dynamic relocation.</p>

<p>We should note that the base and bounds registers are hardware stru tures kept on the chip (one pair per CPU). Sometimes people call the part of the processor that helps with address translation the <strong>memory management unit (MMU)</strong>.</p>

<p><strong>Disadvantage</strong></p>

<p>The simple approach of using a base and bounds register pair to virtualize memory is wasteful. It also makes it quite hard to run a program when the entire address space doesn‚Äôt fit into memory; thus, base and bounds is not as flexible as we would like.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-base_and_bounds.png" alt="os-base_and_bounds.png" /></p>

<p><strong>Hardware Support</strong></p>

<p>The hardware should provide special instructions to modify the base and bounds registers, allowing the OS to change them when different processes run. These instructions are privileged; only in kernel (or privileged) mode can the registers be modified.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-dynaimic_relocation_hardware_requirement.png" alt="os-dynaimic_relocation_hardware_requirement.png" /></p>

<p><strong>Operating System Support</strong></p>

<p>The combination of hardware support and OS management leads to the implementation of a simple virtual memory.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-dynamic_relocation_os_responsibility.png" alt="os-dynamic_relocation_os_responsibility.png" /></p>

<p><strong>Limited Direct Execution Protocol (Dynamic Relocation)</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-dynamic_relocation_LDE.png" alt="os-dynamic_relocation_LDE.png" /></p>

<h3 id="chapter-16-segmentation">Chapter 16 Segmentation</h3>

<p><strong>Segmentation: Generalized Base/Bounds</strong></p>

<p>Considering the disadvantage of the simple base and bounds, instead of having just one base and bounds pair in our <strong>MMU</strong>, why not <strong>have a base and bounds pair per logical segment of the address space</strong>? A segment is just a contiguous portion of the address space of a particular length, and in our canonical address space, we have three logically-different segments: code, stack, and heap.</p>

<p>The hardware structure in our <strong>MMU</strong> required to support segmenta- tion is just what you‚Äôd expect: in this case, a set of three base and bounds register pairs.</p>

<p><strong>Advantage</strong></p>

<p>Remove the Inner Fragmentation.</p>

<p>What segmentation allows the OS to do is to place each one of those segments in different parts of physical memory, and thus avoid filling physical memory with unused virtual address space.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-segmentation.png" alt="os-segmentation.png" /></p>

<p><strong>THE SEGMENTATION FAULT</strong></p>

<p>The term segmentation fault or violation arises from a memory access on a segmented machine to an illegal address. Humorously, the term persists, even on machines with no support for segmentation at all. Or not so humorously, if you can‚Äôt figure why your code keeps faulting</p>

<p><strong>Implementation</strong></p>

<p>One common approach, sometimes referred to as an explicit approach, is to chop up the address space into segments based on the top few bits of the virtual address.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-segmentation_implementation.png" alt="os-segmentation_implementation.png" /></p>

<p><strong>Hardware Support</strong></p>

<p>Negative growth for stack, and protection bits for code sharing. (to save memory, sometimes it is useful to share certain memory segments between address spaces. In particular, <strong>code sharing</strong> is common and still in use in systems today.)</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-segmentation_register_with_protection.png" alt="os-segmentation_register_with_protection.png" /></p>

<p><strong>Fine-grained vs. Coarse-grained Segmentation</strong></p>

<ul>
  <li>Coarse-grained, with just a few segments (i.e., code, stack, heap).</li>
  <li>Fine-grained, to consist of a large number smaller segments, with (further hardware support) a <strong>segment table</strong> of some kind stored in memory.</li>
</ul>

<p><strong>Disadvantage</strong></p>

<p>The general problem that arises is that physical memory quickly becomes full of little holes of free space, making it difficult to allocate new segments, or to grow existing ones. We call this problem <strong>external fragmentation</strong>.</p>

<p>Because segments are variablesized, free memory gets chopped up into odd-sized pieces, and thus satisfying a memory-allocation request can be difficult. One can try to use smart algorithms or periodically compact memory, but the problem is fundamental and hard to avoid. (compact physical memory by rearranging the existing segments, is memory-intensive and generally uses a fair amount of processor time.)</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-segmentation_compact_memory.png" alt="os-segmentation_compact_memory.png" /></p>

<p>Segmentation still isn‚Äôt flexible enough to support our fully generalized, sparse address space.</p>

<h3 id="chapter-17---free-space-management">Chapter 17 - Free-Space Management</h3>

<p>Managing free space can certainly be easy, as we will see when we discuss the concept of paging. It is easy when the space you are managing is divided into fixed-sized units; in such a case, you just keep a list of these fixed-sized units; when a client requests one of them, return the first entry.</p>

<p>Where free-space management becomes more difficult (and interesting) is when the free space you are managing consists of variable-sized units; this arises in a user-level memory-allocation library (as in malloc() and free()) and in an OS managing physical memory when using segmentation to implement virtual memory. In either case, the problem that exists is known as <strong>external fragmentation</strong>: the free space gets chopped into little pieces of different sizes and is thus fragmented; subsequent requests may fail because there is no single contiguous space that can satisfy the request, even though the total amount of free space exceeds the size of the request.</p>

<p><strong>Target</strong></p>

<p>The more you know about the exact workload presented to an <strong>allocator</strong>, the more you could do to tune it to work better for that workload.</p>

<p><strong>Assumptions</strong></p>

<p>Focus on the great history of allocators found in user-level memory-allocation libraries. The space that this library manages is known historically as the heap, and the geeric data structure used to manage free space in the heap is some kind of <strong>free list</strong>. This structure contains references to all of the free chunks of space in the managed region of memory.</p>

<p>Example</p>

<p>void free(void *ptr) takes a pointer and frees the corresponding chunk. Note the implication of the interface: the user, when freeing the space, does not inform the library of its size; thus, the library must be able to figure out how big a chunk of memory is when handed just a pointer to it.</p>

<p><strong>Splitting and Coalescing</strong></p>

<ul>
  <li>The split is commonly used in allocators when requests are smaller than the size of any particular free chunk.</li>
  <li>Coalesce free space when a chunk of memory is freed.</li>
</ul>

<p><strong>Tracking The Size Of Allocated Regions</strong></p>

<p>To accomplish this task, most allocators store a little bit of extra information in a <strong>header</strong> block which is kept in memory, usually just before the handed-out chunk of memory.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewenndy.github.io/raw/source/image-repo/os-free_space_management_non_coalesced_free_list.png" alt="os-free_space_management_non_coalesced_free_list.png" /></p>

<h2 id="paging">Paging</h2>

<h3 id="chapter-18---paging-introduction">Chapter 18 - Paging: Introduction</h3>

<p><strong>Background</strong></p>

<p>The operating system takes one of two approaches when solving most any space-management problem.</p>

<ol>
  <li>The first approach is to chop things up into <strong>variable-sized</strong> pieces, as we saw with segmenta- tion in virtual memory.</li>
  <li>To chop up space into <strong>fixed-sized</strong> pieces. In virtual memory, we call this idea paging.</li>
</ol>

<p><strong>Page vs. Page Frame</strong></p>

<ul>
  <li>From perspective of address space, the fixed-sized unit is called page.</li>
  <li>From perspective of physical space, the fixed-sized unit is called page frame.</li>
</ul>

<p>So, the address translation is to translate page to relevant page frame.</p>

<p><strong>32 bits vs. 64 bits</strong></p>

<p>Sometimes we say the OS is 32 bits or 64 bits, we may infer that</p>

<ul>
  <li>32 bits OS has 4GB address space</li>
  <li>64 bits OS has 10mGB address space</li>
</ul>

<p><strong>Advantage</strong></p>

<ul>
  <li>First, it does not lead to external fragmentation, as paging (by design) divides memory into fixed-sized units.</li>
  <li>Second, it is quite flexible, enabling the sparse use of virtual address spaces.</li>
</ul>

<p><strong>Translation</strong></p>

<p>To translate this virtual address that the process generated, we have to first split it into two components: the <strong>virtual page number (VPN)</strong>, and the <strong>offset</strong> within the page.</p>

<p>With our virtual page number, we can now index our page table, to get the <strong>physical frame number (PFN)</strong> (also sometimes called the <strong>physical page number or PPN</strong>).</p>

<p>Note the offset stays the same (i.e., it is not translated), because the offset just tells us which byte within the page we want.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-paging_address_translation_process.png" alt="os-paging_address_translation_process.png" /></p>

<p><strong>Page Table</strong></p>

<p>The operating system usually keeps a per-process data structure known as a page table.</p>

<p>One of the most important data structures in the memory management subsystem of a modern OS is the page table. In general, a page table stores virtual-to-physical address translations</p>

<p>The page table is just a data structure that is used to map virtual addresses (or really, virtual page numbers) to physical addresses (physical frame numbers). The OS indexes the array by the virtual page number (VPN), and looks up the page-table entry (PTE) at that index in order to find the desired physical frame number (PFN).</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-paging_page_table.png" alt="os-paging_page_table.png" /></p>

<p><strong>Storage</strong></p>

<p>Because page tables are so big, we don‚Äôt keep any special on-chip hard- ware in the MMU to store the page table of the currently-running process. Instead, we store the page table for each process in memory somewhere.</p>

<p><strong>Page Table Entry (PTE)</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-paging_x86_pte_example.png" alt="os-paging_x86_pte_example.png" /></p>

<p><strong>Page Table Base Register (PTBR)</strong></p>

<p>PTBR contains the physical address of the starting location of the page table.</p>

<p>Code Example</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-paging_access_memory_code_demo.png" alt="os-paging_access_memory_code_demo.png" /></p>

<h3 id="chapter-19---paging-faster-translations-tlbs">Chapter 19 - Paging: Faster Translations (TLBs)</h3>

<p><strong>Background</strong></p>

<p>Using paging as the core mechanism to support virtual memory can lead to high performance overheads. By chopping the address space into small, fixed-sized units (i.e., pages), paging requires a large amount of mapping information. Going to memory for translation information before every instruction fetch or explicit load or store is prohibitively slow.</p>

<p><strong>Translation Lookaside Buffer (TLB)</strong></p>

<p>To speed address translation, we are going to add what is called (for historical reasons) a <strong>translation-lookaside buffer</strong>, or <strong>TLB</strong>. A TLB is part of the chip‚Äôs <strong>memory-management unit (MMU)</strong>, and is simply a hardware cache of popular virtual-to-physical address translations; thus, a better name would be an <strong>address-translation cache</strong>.</p>

<p><strong>Advantage</strong></p>

<p>By providing a small, dedicated on-chip TLB as an address-translation cache, most memory references will hopefully be handled without having to access the page table in main memory.</p>

<p><strong>Algorithm</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-paging_tlb_control_flow.png" alt="os-paging_tlb_control_flow.png" /></p>

<p>Goal is to improve the TLB <strong>hit rate</strong>.</p>

<p><strong>TLB Content</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-paging_tlb_content.png" alt="os-paging_tlb_content.png" /></p>

<p>TLB contains both VPN and PFN in each entry, in hardware terms, the TLB is known as a <strong>fully-associative</strong> cache.</p>

<p><strong>TLB Miss Handling</strong></p>

<p>Two answers are possible: the hardware, or the software (OS).</p>

<p>A modern system that uses <strong>software-managed TLBs</strong>. On a TLB miss, the hardware simply raises an exception, which pauses the current instruction stream, raises the privilege level to kernel mode, and jumps to a trap handler. As you might guess, this trap handler is code within the OS that is written with the express purpose of handling TLB misses.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-paging_tlb_control_flow_os_handled.png" alt="os-paging_tlb_control_flow_os_handled.png" /></p>

<p><strong>Performance Matters</strong></p>

<p>Like any cache, TLBs rely upon both spatial and temporal locality for success, which are program properties. The idea behind hardware caches is to take advantage of <strong>locality</strong> in instruction and data references. Hardware caches, whether for instructions, data, or address translations (as in our TLB) take advantage of locality by keeping copies of memory in small, fast on-chip memory.</p>

<ol>
  <li><strong>spatial locality</strong>, the idea is that if a program accesses memory at address x, it will likely soon access memory near x.</li>
  <li><strong>temporal locality</strong>, the idea is that an instruction or data item that has been recently accessed will likely be re-accessed soon in the future.</li>
  <li>page size, why don‚Äôt we just make bigger caches and keep all of our data in them? Because any large cache by definition is slow, and thus defeats the purpose.</li>
</ol>

<p><strong>Issue 1: Context Switch</strong></p>

<p>Specifically, the TLB contains virtual-to-physical translations that are only valid for the currently running process; these translations are not meaningful for other processes. As a result, when switching from one process to another, the hardware or OS (or both) must be careful to ensure that the about-to-be-run process does not accidentally use translations from some previously run process.</p>

<ol>
  <li><strong>flush</strong> the TLB on context switches, thus emptying it before running the next process. But there is a cost: each time a process runs, it must incur TLB misses as it touches its data and code pages. If the OS switches between processes frequently, this cost may be high.</li>
  <li><strong>address space identifier (ASID)</strong>, which you can think of the ASID as a process identifier (PID), to enable sharing of the TLB across context switches.</li>
</ol>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-paging_tlb_with_asid.png" alt="os-paging_tlb_with_asid.png" /></p>

<p><strong>Issue 2: Replacement Policy</strong></p>

<p>When we are installing a new entry in the TLB, we have to replace an old one, which one to replace?</p>

<ul>
  <li><strong>least-recently-used (LRU)</strong></li>
  <li><strong>random policy</strong></li>
</ul>

<p>LRU tries to take advantage of locality in the memory-reference stream, and what the random policy exists for?</p>

<p>Random policy is useful due to its simplicity and ability to avoid corner-case behaviors; for example, a ‚Äúreasonable‚Äù policy such as LRU behaves quite unreasonably when a program loops over n + 1 pages with a TLB of size n; in this case, LRU misses upon every access, whereas random does much better.</p>

<p><strong>Disadvantage</strong></p>

<ol>
  <li>
    <p>Exceeding the TLB coverage, and it can be quite a problem for certain programs. Support for large pages is often exploited by programs such as a database management system (a DBMS), which have certain data structures that are both large and randomly-accessed.</p>

    <p><strong>RAM isn‚Äôt always RAM</strong>. Sometimes randomly accessing your address space, particular if the number of pages accessed exceeds the TLB coverage, can lead to severe performance penalties. Because one of our advisors, David Culler, used to always point to the TLB as the source of many performance problems, we name this law in his honor: <strong>Culler‚Äôs Law</strong>.</p>
  </li>
  <li>
    <p>TLB access can easily become a bottleneck in the CPU pipeline, in particular with what is called a <strong>physically-indexed cache</strong>. With such a cache, address translation has to take place before the cache is accessed, which can slow things down quite a bit. A <strong>virtually-indexed cach</strong>e solves some performance problems, but introduces new issues into hardware design as well.</p>
  </li>
</ol>

<h3 id="note-on-cache-management">Note on Cache Management</h3>

<p>Define cache miss and hit, and goal is to improve the cache rate. Normally, better <strong>replacement policy</strong> lead to higher cache rate.</p>

<p><strong>Find the best replacement policy</strong></p>

<ul>
  <li>Find the optimal</li>
  <li>Find the easiest</li>
  <li>Improve toward optimal, considering Principle of Locality</li>
  <li>Think about corner case</li>
</ul>

<p><strong>Reference: Optimal Replacement Policy</strong></p>

<p>Although optimal is not very practical as a real policy, it is incredibly useful as a comparison point in simulation or other studies.</p>

<ul>
  <li>It makes your improvement meaningful, comparing to optimal policy</li>
  <li>It can show you how much improvement still possible</li>
  <li>It can tell you when to stop making your policy better, because it is close enough to the ideal</li>
</ul>

<p><strong>Reference: Easiest Replacement Policy</strong></p>

<p>Random policy, with an extraordinary advantage, can avoid corner case.</p>

<p><strong>Reference: Principle of Locality</strong></p>

<p>Programs tend to access certain code sequences (e.g., in a loop) and data structures (e.g., an array accessed by the loop) quite frequently.</p>

<ul>
  <li>spatial locality</li>
  <li>temporal locality, e.g., LRU</li>
  <li>operation expense, e.g., When swapping out pages, dirty pages are much more expensive</li>
</ul>

<p><strong>Reference: Types of Cache Misses</strong></p>

<p>In the computer architecture world, architects sometimes find it useful to characterize misses by type, into one of three categories, sometimes called the Three C‚Äôs.</p>

<ul>
  <li><strong>Compulsory miss</strong> (cold-start miss) occurs because the cache is empty to begin with and this is the first reference to the item.</li>
  <li><strong>Capacity miss</strong> occurs because the cache ran out of space and had to evict an item to bring a new item into the cache.</li>
  <li><strong>Conflict miss</strong> arises in hardware because of limits on where an item can be placed in a hardware cache, due to something known as set-associativity; it does not arise in the OS page cache because such caches are always fully-associative, i.e., there are no restrictions on where in memory a page can be placed.</li>
</ul>

<h3 id="chapter-20---paging-smaller-tables">Chapter 20 - Paging: Smaller Tables</h3>

<p><strong>Crux</strong></p>

<p>How to get rid of all those invalid regions in the page table instead of keeping them all in memory?</p>

<p><strong>Background</strong></p>

<p>Page tables are t big and thus consume too much memory.</p>

<p>Assume again a 32-bit address space (2^32 bytes), with 4KB (2^12 byte) pages and a 4-byte page-table entry. An address space thus has roughly one million virtual pages in it ( 2^20 ); multiply by the page-table entry size and you see that our page table is 4MB in size. Recall also: we usually have one page table for every process in the system! With a hundred active processes (not uncommon on a modern system), we will be allocating hundreds of megabytes of memory just for page tables!</p>

<p><strong>Solution 1 - Bigger Pages</strong></p>

<p>Big pages lead to waste within each page, a problem known as internal fragmentation. Thus, most systems use relatively small page sizes in the common case: 4KB (as in x86).</p>

<p><strong>Solution 2 - Hybrid Approach: Paging and Segments</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-paging_tlb_hybrid_approach.png" alt="os-paging_tlb_hybrid_approach.png" /></p>

<p><strong>Algorithm</strong></p>

<p>Instead of having a single page table for the entire address soopace of the process, have one per logical segment. In this example, we might thus have three page tables.</p>

<p>Remember with segmentation, we had a <strong>base</strong> register that told us where each segment lived in physical memory, and a <strong>bound</strong> or limit register that told us the size of said segment.</p>

<ol>
  <li>Each logical segment (code, stack, and heap) has one page table.</li>
  <li>Each segment has one pair of base and bounds resisters.</li>
  <li>Base register points to the page table of the segment, and bounds is used to indicate the end of the page table.</li>
</ol>

<p><strong>Advantage</strong></p>

<p>In this manner, our hybrid approach realizes a significant memory savings compared to the linear page table; unallocated pages between the stack and the heap no longer take up space in a page table (just to mark them as not valid).</p>

<p><strong>Disadvantage</strong></p>

<ol>
  <li>It still requires us to use segmentation, as it assumes a certain usage pattern of the address space; if we have a large but sparsely-used heap, for example, we can still end up with a lot of page table waste.</li>
  <li>This hybrid causes external fragmentation to arise again. While most of memory is managed in page-sized units, page tables now can be of arbitrary size (in multiples of PTEs). Thus, finding free space for them in memory is more complicated.</li>
</ol>

<p><strong>Solution 3 - Multi-level Page Tables</strong></p>

<p>It turns the linear page table into something like a tree (<strong>page directory</strong>). This approach is so effective that many modern systems employ it (e.g., x86).</p>

<p><strong>Algorithm</strong></p>

<p>First, chop up the page table into page-sized units; if an entire page of page-table entries (PTEs) is invalid, don‚Äôt allocate that page of the page table at all. To track whether a page of the page table is valid (and if valid, where it is in memory), use a new structure, called the page directory. The page directory thus either can be used to tell you where a page of the page table is, or that the entire page of the page table contains no valid pages.</p>

<p>The page directory, in a simple two-level table, contains one entry per page of the page table. It consists of a number of <strong>page directory entries (PDE)</strong>. A PDE (minimally) has a <strong>valid bit</strong> <strong>and a page frame number (PFN)</strong>, similar to a PTE.</p>

<p>VA contains VPN and offset, and VPN can be splitted into <strong>page directory index</strong> and <strong>page table index</strong>.</p>

<ol>
  <li>Use <strong>page directory index</strong> to search page directory, to get <strong>page directory entry</strong>, to get <strong>page frame number</strong>, to get the specific <strong>page table</strong>.</li>
  <li>Use <strong>page table index</strong> to search the page table, to get <strong>page table entry</strong>, to get the real <strong>physical frame number</strong>.</li>
</ol>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-paging_multi_level_page_table_demo.png" alt="os-paging_multi_level_page_table_demo.png" /></p>

<p>Demo code</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-paging_multi_level_page_table_demo_code.png" alt="os-paging_multi_level_page_table_demo_code.png" /></p>

<p><strong>Advantage</strong></p>

<ol>
  <li>The multi-level table only allocates page-table space in proportion to the amount of address space you are usig; thus it is generally compact and supports sparse address spaces.</li>
  <li>
    <p>If carefully constructed, each portion of the page table fits neatly within a page, making it easier to manage memory; the OS can simply grab the next free page when it needs to allocate or grow a page table.</p>

    <p>Contrast this to a simple (non-paged) linear page table, for a large page table (say 4MB), finding such a large chunk of unused contiguous free physical memory can be quite a challenge. With a multi-level structure, the indirection allows us to place page-table pages wherever we would like in physical memory.</p>
  </li>
</ol>

<p><strong>Disadvantage</strong></p>

<ol>
  <li>Time-space trade-off. It should be noted that there is a cost to multi-level tables; on a TLB miss, two loads from memory will be required to get the right translation information from the page table (one for the page directory, and one for the PTE itself).</li>
  <li>Another obvious negative is complexity. Whether it is the hardware or OS handling the page-table lookup (on a TLB miss), doing so is undoubt- nedly more involved than a simple linear page-table lookup.</li>
</ol>

<p><strong>Example</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-paging_multi_level_page_table_example.png" alt="os-paging_multi_level_page_table_example.png" /></p>

<p>Virtual Address format</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-paging_multi_level_page_table_example_va.png" alt="os-paging_multi_level_page_table_example_va.png" /></p>

<p>Explanation</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-paging_multi_level_page_table_example_explanation.png" alt="os-paging_multi_level_page_table_example_explanation.png" /></p>

<p><strong>Issues</strong></p>

<p><strong><em>What if the page directory gets too big?</em></strong></p>

<p>Make it more than two levels, add index to page directory index.</p>

<p><strong><em>How to make it extreme space savings?</em></strong></p>

<p>Inverted page tables. Instead of having many page tables (one per process of the system), we keep a single page table that has an entry for each physical page of the system. The entry tells us which process is using this page, and which virtual page of that process maps to this physical page.</p>

<p>A hash table is often built over the base structure to speed lookups.</p>

<p><strong><em>How to choose page table size?</em></strong></p>

<p>In a memory-constrained system (like many older systems), small structures make sense; in a system with a reasonable amount of memory and with workloads that actively use a large number of pages, a bigger table that speeds up TLB misses might be the right choice.</p>

<p><strong><em>What if the page tables are too big to fit into memory all at once?</em></strong></p>

<p>Thus far, we have assumed that page tables reside in kernel-owned physical memory. Some systems place such page tables in <strong>kernel virtual memory</strong>, thereby allowing the system to swap some of these page tables to disk when memory pressure gets a little tight.</p>

<h2 id="beyond-physical-memory">Beyond Physical Memory</h2>

<h3 id="chapter-21---beyond-physical-memory-mechanisms">Chapter 21 - Beyond Physical Memory: Mechanisms</h3>

<p><strong>Background</strong></p>

<p>In fact, we‚Äôve been assuming that every address space of every running process fits into memory. We will now relax these big assumptions, and assume that we wish to support many concurrently-running large address spaces.</p>

<p>To support large address spaces, the OS will need a place to stash away portions of address spaces that currently aren‚Äôt in great demand. In modern systems, this role is usually served by a hard disk drive.</p>

<p><strong>Mechanism</strong></p>

<p>To do so requires more complexity in page-table structures, as a <strong>present bit</strong> (of some kind) must be included to tell us whether the page is present in memory or not. When not, the operating system <strong>page-fault handler</strong> runs to service the <strong>page fault</strong>, and thus arranges for the transfer of the desired page from disk to memory, perhaps first replacing some pages in memory to make room for those soon to be swapped in.</p>

<p><strong>Swap Space</strong></p>

<p>To reserve some space on the disk for moving pages back and forth. We will simply assume that the OS can read from and write to the swap space, in page-sized units. To do so, the OS will need to remember the <strong>disk address</strong> of a given page (PTE).</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-swap_example.png" alt="os-swap_example.png" /></p>

<p>The size of the swap space is important, as ultimately it determines the <strong>maximum number of memory pages</strong> that can be in use by a system at a given time.</p>

<p>We should note that swap space is not the only on-disk location for swapping traffic.</p>

<blockquote>
  <p>For example, assume you are running a program binary (e.g., ls, or your own compiled main program). The code pages from this binary are initially found on disk, and when the program runs, they are loaded into memory (either all at once when the program starts execution, or, as in modern systems, one page at a time when needed). However, if the system needs to make room in physical memory for other needs, it can safely re-use the memry space for these code pages, knowing that it can later swap them in again from the on-disk binary in the file system.</p>
</blockquote>

<p><strong>Present Bit</strong></p>

<p>OS use this piece of information in each page-table entry to flag if the page is in physical memory or swap space.</p>

<p>If the present bit is set to one, it means the page is present in physical memory and everything proceeds as above; if it is set to zero, the page is not in memory but rather on disk somewhere.</p>

<p><strong>Page Faut</strong></p>

<p>The act of accessing a page that is not in physical memory is commonly referred to as a <strong>page fault</strong> (it should be called a <strong>page miss</strong>. But when something the hardware doesn‚Äôt know how to handle occurs, the hardware simply transfers control to the OS. In perspective of the hardware it is a page fault).</p>

<p><strong>Page Fault Handler</strong></p>

<p>Upon a page fault, the OS is invoked to service the page fault. A particular piece of code, known as a <strong>page-fault handler</strong>, runs, and must service the page fault.</p>

<p>The appropriately-named <strong>OS page-fault handler</strong> runso to determine what to do. Virtually all systems handle page faults in software; even with a hardware-managed TLB, the hardware trusts the OS to manage this important duty.</p>

<p><strong>Page Fault Control Flow</strong></p>

<p>Hardware</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-swap_page_fault_control_flow.png" alt="os-swap_page_fault_control_flow.png" /></p>

<p>Software</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-swap_page_fault_control_flow_software.png" alt="os-swap_page_fault_control_flow_software.png" /></p>

<p>How to handle or how will the OS know where to find the desired page?</p>

<ol>
  <li>The OS could use the bits in the PTE normally used for data such as the PFN of the page for a disk address. When the OS receives a page fault for a page, it looks in the PTE to find the address, and issues the request to disk to fetch the page into memory.</li>
  <li>When the disk I/O completes, the OS will then update the page table to mark the page as present, update the PFN field of the page-table entry (PTE) to record the in-memory location of the newly-fetched page, and retry the instruction.</li>
  <li>Then generate a TLB miss, which would then be serviced and update the TLB with the translation (one could alternately update the TLB when servicing the page fault to avoid this step)</li>
  <li>Finally, a last restart would find the translation in the TLB and thus proceed to fetch the desired data or instruction from memory at the translated physical address.</li>
</ol>

<p>Note that while the I/O is in flight, the process will be in the blocked state. Thus, the OS will be free to run other ready processes while the page fault is being serviced.</p>

<p><strong><em>What If Memory Is Full?</em></strong></p>

<p>OS might like to first page out one or more pages to make room for the new page(s) the OS is about to bring in. The process of picking a page to kick out, or replace is known as the <strong>page-replacement policy</strong>.</p>

<p><strong><em>When Replacements Really Occur?</em></strong></p>

<p>There are many reasons for the OS to keep a small portion of memory free more proactively. To keep a small amount of memory free, most operating systems thus have some kind of <strong>high watermark (HW)</strong> and <strong>low watermark (LW)</strong> to help decide when to start evicting pages from memory.</p>

<p>When the OS notices that there are fewer than LW pages available, a background thread that is responsible for freeing memory runs. The thread evicts pages until there are HW pages available. The background thread, sometimes called the <strong>swap daemon</strong> or <strong>page daemon</strong>, then goes to sleep, happy that it has freed some memory for running processes and the OS to use.</p>

<p>So, instead of performing a replacement directly, the algorithm would instead simply check if there are any free pages available. If not, it would inform the <strong>page daemon</strong> that free pages are needed; when the thread frees up some pages, it would re-awaken the original thread, which could then page in the desired page and go about its work.</p>

<p><strong><em>How To Make Replacement Efficient?</em></strong></p>

<p>Many systems will cluster or group a number of pages and write them out at once to the swap partition, thus increasing the efficiency of the disk.</p>

<h3 id="chapter-22---beyond-physical-memory-policies">Chapter 22 - Beyond Physical Memory: Policies</h3>

<p><strong>Background</strong></p>

<p>In such a case, this memory pressure forces the OS to start <strong>paging out</strong> pages to make room for actively-used pages. Deciding which page (or pages) to evict is encapsulated within the <strong>replacement policy</strong> of the OS.</p>

<p><strong>Cache Management</strong></p>

<p>Given that main memory holds some subset of all the pages in the system, it can rightly be viewed as a cache for virtual memory pages in the system. And our goal as maximizing the number of <strong>cache hits</strong>.</p>

<p>Knowing the number of cache hits and misses let us calculate the <strong>average memory access time (AMAT)</strong> for a program.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-replacement_amat.png" alt="os-replacement_amat.png" /></p>

<p>Example</p>

<p>Suppose T(M) = 100ns (10^-7), T(D) = 10ms (10^-2)</p>

<ul>
  <li>P(Hit) = 90%, P(Miss) = 10%, AMAT = 1ms + 90ns</li>
  <li>P(Hit) = 99.9%, P(Miss) = 0.1%, AMAT = 0.01ms + 99.9ns</li>
</ul>

<p>The cost of disk access is so high in modern systems that even a tiny miss rate will quickly dominate the overall AMAT of running programs.</p>

<p><strong>Polices</strong></p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-replacement_summary.png" alt="os-replacement_summary.png" /></p>

<p><strong>Policy 1. Optimal Replacement Policy</strong></p>

<p>Replaces the page that will be accessed furthest in the future is the optimal policy, resulting in the fewest-possible cache misses.</p>

<p>In the development of scheduling policies, the future is not generally known; you can‚Äôt build the optimal policy for a general-purpose operating system.</p>

<p>Although optimal is not very practical as a real policy, it is incredibly useful as a comparison point in simulation or other studies.</p>

<ul>
  <li>It makes your improvement meaningful, comparing to optimal policy</li>
  <li>It can show you how much improvement still possible</li>
  <li>It can tell you when to stop making your policy better, because it is close enough to the ideal</li>
</ul>

<p><strong>Policy 2. FIFO</strong></p>

<p>Normal efficiency, easy to implement, and has corner case.</p>

<p>In some cases, when increasing the cache size, hit rate may get lower. This odd behavior is generally referred to as <strong>Belady‚Äôs Anomaly</strong>.</p>

<p><strong>Policy 3. Random</strong></p>

<p>Normal efficiency, easy to implement, but remember, it can avoid corner case.</p>

<p><strong>Policy 4. LRU</strong></p>

<p>LRU has what is known as a stack property. When increasing the cache size, hit rate will either stay the same or improve.</p>

<p><strong>Comparison with Workload</strong></p>

<p>No locality workload</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-replacement_no_locality_workload.png" alt="os-replacement_no_locality_workload.png" /></p>

<p>The 80-20 Workload, 80% of the references are made to 20% of the pages (the ‚Äúhot‚Äù pages).</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-replacement_80_20_workload.png" alt="os-replacement_80_20_workload.png" /></p>

<p>The Looping-Sequential Workload</p>

<p>Looping sequential workload, as in it, we refer to 50 pages in sequence, starting at 0, then 1, ‚Ä¶, up to page 49, and then we lp, repeating those accesses.</p>

<p>It represents a worst-case for both LRU and FIFO, but no influence on Random. Turns out that random has some nice properties; one such property is not having weird corner-case behaviors.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-replacement_looping_sequential_workload.png" alt="os-replacement_looping_sequential_workload.png" /></p>

<p><strong>Implementation - Approximating LRU</strong></p>

<p>To keep track of which pages have been least- and most-recently used, the system has to do some accounting work on every memory reference. Unfortunately, as the number of pages in a system grows, scanning a huge array of times just to find the absolute least-recently-used page is prohibitively expensive.</p>

<p>Idea</p>

<p>Approximating LRU is more feasible from a computational-overhead standpoint, and indeed it is what many modern systems do. The idea requires some hardware support, in the form of a <strong>use bit</strong> (sometimes called the <strong>reference bit</strong>).</p>

<ul>
  <li>Whenever a page is referenced (i.ooe., read or written), the use bit is set by hardware to 1.</li>
  <li>The hardware never clears the bit, though (i.e., sets it to 0); that is the responsibility of the OS.</li>
</ul>

<p>Implementation by Clock Algorithm</p>

<ul>
  <li>Imagine all the pages of the system arranged in a circular list. A clock hand points to some particular page to begin with.</li>
  <li>When a replacement must occur, the OS iterating the circular list checking on use bit.
    <ul>
      <li>If 1, clear use bit to 0, and find next</li>
      <li>If 0, use it</li>
    </ul>
  </li>
</ul>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-replacement_80_20_workload_with_clock.png" alt="os-replacement_80_20_workload_with_clock.png" /></p>

<p><strong>Considering Dirty Pages</strong></p>

<p>Consider the locality by the expense on swapping out pages.</p>

<ul>
  <li>If a page has been <strong>modified</strong> and is thus <strong>dirty</strong>, it must be written back to disk to evict it, which is expensive.</li>
  <li>If it has not been modified (and is thus clean), the eviction is free; the physical frame can simply be reused for other purposes without additional I/O.
Idea</li>
</ul>

<p>To support this behavior, the hardware should include a <strong>modified bit</strong> (a.k.a. <strong>dirty bit</strong>).</p>

<p>Implementation by Clock Algorithm</p>

<p>The clock algorithm, for example, could be changed to scan for pages that are both unused and clean to evict first; failing to find those, then for unused pages that are dirty, and so forth.</p>

<p><strong>Other VM Policies</strong></p>

<p><strong><em>When the OS bring a page into memory?</em></strong></p>

<p>Page selection policy. The OS simply uses <strong>demand paging</strong>, which means the OS brings the page into memory when it is accessed, ‚Äúon demand‚Äù as it were. Of course, the OS could guess that a page is about to be used, and thus bring it in ahead of time; this behavior is known as <strong>prefetching</strong>.</p>

<p><strong><em>How the OS writes pages out to disk?</em></strong></p>

<p>Any systems instead collect a number of pending writes together in memory and write them to disk in one (more efficient) write. This behavior is usually called <strong>clustering</strong> or simply <strong>grouping</strong> of writes, and is effective because of the nature of disk drives.</p>

<p><strong><em>What about
 the memory demands of the set of running processes simply exceeds the available physical memory? (condition sometimes referred to as thrashing)</em></strong></p>

<p>Given a set of processes, a system could decide not to run a subset of processes, with the hope that the reduced set of processes working sets (the pages that they are using actively) fit in memory and thus can make progress. This approach, generally known as <strong>admission control</strong>, states that it is sometimes better to do less work well than to try to do everything at once poorly.</p>

<p>Some versions of Linux run an <strong>out-of-memory killer</strong> when memory is oversubscribed; this daemon chooses a memory- intensive process and kills it, thus reducing memory in a none-too-subtle manner.</p>

<h3 id="chapter-23---the-vaxvms-virtual-memory-system">Chapter 23 - The VAX/VMS Virtual Memory System</h3>

<p><strong>Background</strong></p>

<p>The VAX-11 minicomputer architecture was introduced in the late 1970‚Äôs by Digital Equipment Corporation (DEC).</p>

<p>As an additional issue, VMS is an excellent example of software innovations used to hide some of the inheret flaws of the architecture.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/os-vax_vms_address_space.png" alt="os-vax_vms_address_space.png" /></p>

<p><strong>Reduce Page Table Pressure</strong></p>

<p>First, by segmenting the user address space into two, the VAX-11 provides a page table for each of these regions (P0 and P1) per process; thus, no page-table space is needed for the unused portion of the address space between the stack and the heap.</p>

<p>Second, the OS reduces memory pressure even further by placing user page tables (for P0 and P1, thus two per process) in kernel virtual memory. Thus, when allocating or growing a page table, the kernel allocates space out of its own virtual memory, in segment S. If memory comes undersevere pressure, the kernel can swap pages of these page tables out to disk, thus making physical memory available for other uses.</p>

<p><strong>Replacement policy: Segmented FIFO with Page Clustering</strong></p>

<p>Each process has a maximum number of pages it can keep in memory, known as its <strong>residentn set size (RSS)</strong>. Each of these pages is kept on a FIFO list; when a process exceeds its RSS, the ‚Äúfirst-in‚Äù page is evicted. FIFO clearly does not need any support from the hardware (no use bit), and is thus easy to implement.</p>

<p>To improve FIFO‚Äôs performance, VMS introduced two <strong>second-chance lists</strong> where pages are placed before getting evicted from memory, specifically a global clean-page free list and dirty-page list. The bigger these global second-chance lists are, the closer the segmented FIFO algorithm performs to LRU.</p>

<p>Clustering is used in most modern systems, as the freedom to place pages anywhere within swap space lets the OS group pages, perform fewer and bigger writes, and thus improve performance.</p>

<p><strong>Optimisation: Be Lazy</strong></p>

<p>Laziness can put off work until later, which is beneficial within an OS for a number of reasons.</p>

<ul>
  <li>First, putting off work might reduce the latency of the current operation, thus improving responsiveness; for example, operating systems often report that writes to a file succeeded immediately, and only write them to disk later in the background.</li>
  <li>Second, and more importantly, laziness sometimes obviates the need to do the work at all; for example, delaying a write until the file is deleted removes the need to do the write at all.</li>
</ul>

<p><strong>Lazy Optimisation: Demanding Zero</strong></p>

<p>With demand zeroing, the OS instead does very little work when the page is added to your address space; it puts an entry in the page table that marks the page inaccessible. If the process then reads or writes the page, a trap into the OS takes place. When handling the trap, the OS notices that this is actually a demand-zero page; at this point, the OS then does the needed work of finding a physical page, zeroing it, and mapping it into the process‚Äôs address space. If the process never accesses the page, all of this work is avoided, and thus the virtue of demand zeroing.</p>

<p><strong>Lazy Optimisation: Copy-on-write</strong></p>

<p>When the OS needs to copy a page from one address space to another, instead of copying it, it can map it into the target address space and mark it read-only in both address spaces.</p>

<ul>
  <li>If both address spaces only read the page, no further action is taken, and thus the OS has realized a fast copy without actually moving any data.</li>
  <li>If, however, one of the address spaces does indeed try to write to the page, it will trap into the OS. The OS will then notice that the page is a COW page, and thus (lazily) allocate a new page, fill it with the data, and map this new page into the address space of the faulting process. The process then continues and now has its own private copy of the page.</li>
</ul>

<p>In UNIX systems, COW is even more critical, due to the semantics of <code>fork()</code> and <code>exec()</code>. <code>fork()</code> creates an exact copy of the address space of the caller; with a large address space, making such a copy is slow and data intensive. Even worse, most of the address space is immediately over-written by a subsequent call to <code>exec()</code>, which overlays the calling process‚Äôs address space with that of the soon-to-be-exec‚Äôd program. By instead performing a copy-on-write <code>fork()</code>, the OS avoids much of the needless copying and thus retains the correct semantics while improving performance.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[preload, eager_load, includes, references, and joins in Rails]]></title>
    <link href="http://blog.ifyouseewendy.com/blog/2015/11/11/preload-eager_load-includes-references-joins/"/>
    <updated>2015-11-11T23:25:17+08:00</updated>
    <id>http://blog.ifyouseewendy.com/blog/2015/11/11/preload-eager_load-includes-references-joins</id>
    <content type="html"><![CDATA[<p>There is always a confusion about these query methods. And after some digging, I‚Äôve made my conclusion here: <code>includes</code> is the outstanding one.</p>

<p>Here comes the demonstation.</p>

<p><strong>Preparation</strong></p>

<p>Environment</p>

<ul>
  <li>Ruby: 2.2.2</li>
  <li>Rails: 4.2.2</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="c1"># model and reference</span>
</span><span class="line"><span class="k">class</span> <span class="nc">Blog</span> <span class="o">&lt;</span> <span class="ss">ActiveRecord</span><span class="p">:</span><span class="ss">:Base</span>
</span><span class="line">  <span class="n">has_many</span> <span class="ss">:posts</span>
</span><span class="line">
</span><span class="line">  <span class="c1"># t.string   &quot;name&quot;</span>
</span><span class="line">  <span class="c1"># t.string   &quot;author&quot;</span>
</span><span class="line"><span class="k">end</span>
</span><span class="line">
</span><span class="line"><span class="k">class</span> <span class="nc">Post</span> <span class="o">&lt;</span> <span class="ss">ActiveRecord</span><span class="p">:</span><span class="ss">:Base</span>
</span><span class="line">  <span class="n">belongs_to</span> <span class="ss">:blog</span>
</span><span class="line">
</span><span class="line">  <span class="c1"># t.string   &quot;title&quot;</span>
</span><span class="line"><span class="k">end</span>
</span><span class="line">
</span><span class="line"><span class="c1"># seed</span>
</span><span class="line"><span class="p">(</span><span class="mi">1</span><span class="o">.</span><span class="n">.</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">b_id</span><span class="o">|</span>
</span><span class="line">  <span class="n">blog</span> <span class="o">=</span> <span class="no">Blog</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;Blog </span><span class="si">#{</span><span class="n">b_id</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="ss">author</span><span class="p">:</span> <span class="s1">&#39;someone&#39;</span><span class="p">)</span>
</span><span class="line">  <span class="p">(</span><span class="mi">1</span><span class="o">.</span><span class="n">.</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">each</span> <span class="p">{</span> <span class="o">|</span><span class="n">p_id</span><span class="o">|</span> <span class="n">blog</span><span class="o">.</span><span class="n">posts</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="ss">title</span><span class="p">:</span> <span class="s2">&quot;Post </span><span class="si">#{</span><span class="n">b_id</span><span class="si">}</span><span class="s2">-</span><span class="si">#{</span><span class="n">p_id</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="p">}</span>
</span><span class="line"><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="preload">preload</h3>

<p>Always firing two separate queries.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">&gt; Blog.preload<span class="o">(</span>:posts<span class="o">)</span>
</span><span class="line">  Blog Load <span class="o">(</span>3.2ms<span class="o">)</span>  SELECT <span class="s2">&quot;blogs&quot;</span>.* FROM <span class="s2">&quot;blogs&quot;</span>
</span><span class="line">  Post Load <span class="o">(</span>1.2ms<span class="o">)</span>  SELECT <span class="s2">&quot;posts&quot;</span>.* FROM <span class="s2">&quot;posts&quot;</span> WHERE <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> IN <span class="o">(</span>1, 2, 3<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="eagerload">eager_load</h3>

<ul>
  <li>One query, LEFT OUTER JOINed in any query rather than loaded separately.</li>
  <li>JOIN first, then query by where clause. So you can query on referenced table, without an iteration of  <code>Enumerable#select</code>.</li>
  <li>Works just the same as <code>includes</code> + <code>references</code>.</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">&gt; Blog.eager_load<span class="o">(</span>:posts<span class="o">)</span>
</span><span class="line">  SQL <span class="o">(</span>0.4ms<span class="o">)</span>  SELECT <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;id&quot;</span> AS t0_r0, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;name&quot;</span> AS t0_r1, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;author&quot;</span> AS t0_r2, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;created_at&quot;</span> AS t0_r3, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;updated_at&quot;</span> AS t0_r4, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;id&quot;</span> AS t1_r0, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;title&quot;</span> AS t1_r1, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;created_at&quot;</span> AS t1_r2, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;updated_at&quot;</span> AS t1_r3, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> AS t1_r4 FROM <span class="s2">&quot;blogs&quot;</span> LEFT OUTER JOIN <span class="s2">&quot;posts&quot;</span> ON <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> <span class="o">=</span> <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;id&quot;</span>
</span><span class="line">
</span><span class="line">&gt; Blog.eager_load<span class="o">(</span>:posts<span class="o">)</span>.where<span class="o">(</span>name: <span class="s1">&#39;Blog 1&#39;</span><span class="o">)</span>
</span><span class="line">  SQL <span class="o">(</span>0.4ms<span class="o">)</span>  SELECT <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;id&quot;</span> AS t0_r0, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;name&quot;</span> AS t0_r1, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;author&quot;</span> AS t0_r2, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;created_at&quot;</span> AS t0_r3, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;updated_at&quot;</span> AS t0_r4, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;id&quot;</span> AS t1_r0, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;title&quot;</span> AS t1_r1, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;created_at&quot;</span> AS t1_r2, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;updated_at&quot;</span> AS t1_r3, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> AS t1_r4 FROM <span class="s2">&quot;blogs&quot;</span> LEFT OUTER JOIN <span class="s2">&quot;posts&quot;</span> ON <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> <span class="o">=</span> <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;id&quot;</span> WHERE <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;name&quot;</span> <span class="o">=</span> ?  <span class="o">[[</span><span class="s2">&quot;name&quot;</span>, <span class="s2">&quot;Blog 1&quot;</span><span class="o">]]</span>
</span><span class="line">
</span><span class="line">&gt; Blog.eager_load<span class="o">(</span>:posts<span class="o">)</span>.where<span class="o">(</span>name: <span class="s1">&#39;Blog 1&#39;</span><span class="o">)</span>.where<span class="o">(</span>posts: <span class="o">{</span>title: <span class="s1">&#39;Post 1-1&#39;</span><span class="o">})</span>
</span><span class="line">  SQL <span class="o">(</span>0.4ms<span class="o">)</span>  SELECT <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;id&quot;</span> AS t0_r0, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;name&quot;</span> AS t0_r1, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;author&quot;</span> AS t0_r2, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;created_at&quot;</span> AS t0_r3, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;updated_at&quot;</span> AS t0_r4, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;id&quot;</span> AS t1_r0, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;title&quot;</span> AS t1_r1, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;created_at&quot;</span> AS t1_r2, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;updated_at&quot;</span> AS t1_r3, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> AS t1_r4 FROM <span class="s2">&quot;blogs&quot;</span> LEFT OUTER JOIN <span class="s2">&quot;posts&quot;</span> ON <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> <span class="o">=</span> <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;id&quot;</span> WHERE <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;name&quot;</span> <span class="o">=</span> ? AND <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;title&quot;</span> <span class="o">=</span> ?  <span class="o">[[</span><span class="s2">&quot;name&quot;</span>, <span class="s2">&quot;Blog 1&quot;</span><span class="o">]</span>, <span class="o">[</span><span class="s2">&quot;title&quot;</span>, <span class="s2">&quot;Post 1-1&quot;</span><span class="o">]]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="includes">includes</h3>

<p>Behaves based on situations, intelligent!</p>

<p>Situation 1, just like <code>preload</code></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">&gt; Blog.includes<span class="o">(</span>:posts<span class="o">)</span>
</span><span class="line">  Blog Load <span class="o">(</span>2.8ms<span class="o">)</span>  SELECT <span class="s2">&quot;blogs&quot;</span>.* FROM <span class="s2">&quot;blogs&quot;</span>
</span><span class="line">  Post Load <span class="o">(</span>0.7ms<span class="o">)</span>  SELECT <span class="s2">&quot;posts&quot;</span>.* FROM <span class="s2">&quot;posts&quot;</span> WHERE <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> IN <span class="o">(</span>1, 2, 3<span class="o">)</span>
</span><span class="line">
</span><span class="line">&gt; Blog.includes<span class="o">(</span>:posts<span class="o">)</span>.where<span class="o">(</span>name: <span class="s1">&#39;Blog 1&#39;</span><span class="o">)</span>
</span><span class="line">  Blog Load <span class="o">(</span>0.7ms<span class="o">)</span>  SELECT <span class="s2">&quot;blogs&quot;</span>.* FROM <span class="s2">&quot;blogs&quot;</span> WHERE <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;name&quot;</span> <span class="o">=</span> ?  <span class="o">[[</span><span class="s2">&quot;name&quot;</span>, <span class="s2">&quot;Blog 1&quot;</span><span class="o">]]</span>
</span><span class="line">  Post Load <span class="o">(</span>0.3ms<span class="o">)</span>  SELECT <span class="s2">&quot;posts&quot;</span>.* FROM <span class="s2">&quot;posts&quot;</span> WHERE <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> IN <span class="o">(</span>1<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Situation 2, just like <code>eager_load</code>, <strong>fired by querying referenced table</strong></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">&gt; Blog.includes<span class="o">(</span>:posts<span class="o">)</span>.where<span class="o">(</span>name: <span class="s1">&#39;Blog 1&#39;</span><span class="o">)</span>.where<span class="o">(</span>posts: <span class="o">{</span>title: <span class="s1">&#39;Post 1-1&#39;</span><span class="o">})</span>
</span><span class="line">  SQL <span class="o">(</span>0.2ms<span class="o">)</span>  SELECT <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;id&quot;</span> AS t0_r0, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;name&quot;</span> AS t0_r1, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;author&quot;</span> AS t0_r2, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;created_at&quot;</span> AS t0_r3, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;updated_at&quot;</span> AS t0_r4, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;id&quot;</span> AS t1_r0, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;title&quot;</span> AS t1_r1, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;created_at&quot;</span> AS t1_r2, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;updated_at&quot;</span> AS t1_r3, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> AS t1_r4 FROM <span class="s2">&quot;blogs&quot;</span> LEFT OUTER JOIN <span class="s2">&quot;posts&quot;</span> ON <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> <span class="o">=</span> <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;id&quot;</span> WHERE <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;name&quot;</span> <span class="o">=</span> ? AND <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;title&quot;</span> <span class="o">=</span> ?  <span class="o">[[</span><span class="s2">&quot;name&quot;</span>, <span class="s2">&quot;Blog 1&quot;</span><span class="o">]</span>, <span class="o">[</span><span class="s2">&quot;title&quot;</span>, <span class="s2">&quot;Post 1-1&quot;</span><span class="o">]]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><strong><em><code>includes</code> or <code>eager_load</code></em></strong></p>

<p>Consider this snippet:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">&gt; Blog.includes<span class="o">(</span>:posts<span class="o">)</span>.each<span class="o">{</span>|blog| puts blog.posts.map<span class="o">(</span>&amp;:title<span class="o">)</span>.join<span class="o">(</span><span class="s1">&#39;,&#39;</span><span class="o">)</span> <span class="o">}</span>
</span><span class="line">  Blog Load <span class="o">(</span>0.3ms<span class="o">)</span>  SELECT <span class="s2">&quot;blogs&quot;</span>.* FROM <span class="s2">&quot;blogs&quot;</span>
</span><span class="line">  Post Load <span class="o">(</span>0.3ms<span class="o">)</span>  SELECT <span class="s2">&quot;posts&quot;</span>.* FROM <span class="s2">&quot;posts&quot;</span> WHERE <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> IN <span class="o">(</span>1, 2, 3<span class="o">)</span>
</span><span class="line">
</span><span class="line">&gt; Blog.eager_load<span class="o">(</span>:posts<span class="o">)</span>.each<span class="o">{</span>|blog| puts blog.posts.map<span class="o">(</span>&amp;:title<span class="o">)</span>.join<span class="o">(</span><span class="s1">&#39;,&#39;</span><span class="o">)</span> <span class="o">}</span>                                                                                                                    SQL <span class="o">(</span>0.9ms<span class="o">)</span>
</span><span class="line">  SELECT <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;id&quot;</span> AS t0_r0, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;name&quot;</span> AS t0_r1, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;author&quot;</span> AS t0_r2, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;created_at&quot;</span> AS t0_r3, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;updated_at&quot;</span> AS t0_r4, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;id&quot;</span> AS t1_r0, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;title&quot;</span> AS t1_r1, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;created_at&quot;</span> AS t1_r2, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;updated_at&quot;</span> AS t1_r3, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> AS t1_r4 FROM <span class="s2">&quot;blogs&quot;</span> LEFT OUTER JOIN <span class="s2">&quot;posts&quot;</span> ON <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> <span class="o">=</span> <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;id&quot;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Both expressions return the same result, so should we prefer two seperated queries by <code>includes</code> (also <code>preload</code>) or the LEFT OUTER JOINed query by <code>eager_load</code>?</p>

<p>There is a <a href="http://www.akitaonrails.com/2008/5/26/rolling-with-rails-2-1-the-first-full-tutorial-part-2">blog post</a> by Fabio Akita talks about the change of Rails 2.1 (see the section entitled ‚ÄúOptimized Eager Loading‚Äù). Here are some references:</p>

<blockquote>
  <p>For some situations, the monster outer join becomes slower than many smaller queries.
The bottom line is: generally it seems better to split a monster join into smaller ones, as you‚Äôve seen in the above example. This avoid the cartesian product overload problem.</p>
</blockquote>

<p>Example for SQL data returned from LEFT OUTER JOIN query</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">sqlite&gt;  SELECT <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;id&quot;</span> AS t0_r0, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;name&quot;</span> AS t0_r1, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;author&quot;</span> AS t0_r2, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;created_at&quot;</span> AS t0_r3, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;updated_at&quot;</span> AS t0_r4, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;id&quot;</span> AS t1_r0, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;title&quot;</span> AS t1_r1, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;created_at&quot;</span> AS t1_r2, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;updated_at&quot;</span> AS t1_r3, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> AS t1_r4 FROM <span class="s2">&quot;blogs&quot;</span> LEFT OUTER JOIN <span class="s2">&quot;posts&quot;</span> ON <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> <span class="o">=</span> <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;id&quot;</span>;
</span><span class="line">1|Blog 1|someone|2015-11-11 15:22:35.015095|2015-11-11 15:22:35.015095|1|Post 1-1|2015-11-11 15:22:35.053689|2015-11-11 15:22:35.053689|1
</span><span class="line">1|Blog 1|someone|2015-11-11 15:22:35.015095|2015-11-11 15:22:35.015095|2|Post 1-2|2015-11-11 15:22:35.058113|2015-11-11 15:22:35.058113|1
</span><span class="line">1|Blog 1|someone|2015-11-11 15:22:35.015095|2015-11-11 15:22:35.015095|3|Post 1-3|2015-11-11 15:22:35.062776|2015-11-11 15:22:35.062776|1
</span><span class="line">1|Blog 1|someone|2015-11-11 15:22:35.015095|2015-11-11 15:22:35.015095|4|Post 1-4|2015-11-11 15:22:35.065994|2015-11-11 15:22:35.065994|1
</span><span class="line">1|Blog 1|someone|2015-11-11 15:22:35.015095|2015-11-11 15:22:35.015095|5|Post 1-5|2015-11-11 15:22:35.069632|2015-11-11 15:22:35.069632|1
</span><span class="line">2|Blog 2|someone|2015-11-11 15:22:35.072871|2015-11-11 15:22:35.072871|6|Post 2-1|2015-11-11 15:22:35.078644|2015-11-11 15:22:35.078644|2
</span><span class="line">2|Blog 2|someone|2015-11-11 15:22:35.072871|2015-11-11 15:22:35.072871|7|Post 2-2|2015-11-11 15:22:35.081845|2015-11-11 15:22:35.081845|2
</span><span class="line">2|Blog 2|someone|2015-11-11 15:22:35.072871|2015-11-11 15:22:35.072871|8|Post 2-3|2015-11-11 15:22:35.084888|2015-11-11 15:22:35.084888|2
</span><span class="line">2|Blog 2|someone|2015-11-11 15:22:35.072871|2015-11-11 15:22:35.072871|9|Post 2-4|2015-11-11 15:22:35.087778|2015-11-11 15:22:35.087778|2
</span><span class="line">2|Blog 2|someone|2015-11-11 15:22:35.072871|2015-11-11 15:22:35.072871|10|Post 2-5|2015-11-11 15:22:35.090781|2015-11-11 15:22:35.090781|2
</span><span class="line">3|Blog 3|someone|2015-11-11 15:22:35.093902|2015-11-11 15:22:35.093902|11|Post 3-1|2015-11-11 15:22:35.097479|2015-11-11 15:22:35.097479|3
</span><span class="line">3|Blog 3|someone|2015-11-11 15:22:35.093902|2015-11-11 15:22:35.093902|12|Post 3-2|2015-11-11 15:22:35.103512|2015-11-11 15:22:35.103512|3
</span><span class="line">3|Blog 3|someone|2015-11-11 15:22:35.093902|2015-11-11 15:22:35.093902|13|Post 3-3|2015-11-11 15:22:35.108775|2015-11-11 15:22:35.108775|3
</span><span class="line">3|Blog 3|someone|2015-11-11 15:22:35.093902|2015-11-11 15:22:35.093902|14|Post 3-4|2015-11-11 15:22:35.112654|2015-11-11 15:22:35.112654|3
</span><span class="line">3|Blog 3|someone|2015-11-11 15:22:35.093902|2015-11-11 15:22:35.093902|15|Post 3-5|2015-11-11 15:22:35.117601|2015-11-11 15:22:35.117601|3
</span></code></pre></td></tr></table></div></figure></notextile></div>

<blockquote>
  <p>The longer and more complex the result set, the more this matters because the more objects Rails would have to deal with. Allocating and deallocating several hundreds or thousands of small duplicated objects is never a good deal.</p>
</blockquote>

<p>As <code>includes</code> can behave the same as <code>eager_load</code> in one case, but better in the other case. My conclusion is, <strong>prefer <code>includes</code> over <code>eager_load</code></strong>.</p>

<h3 id="references">references</h3>

<ul>
  <li>Works only with <code>includes</code>, makes <code>includes</code> behaves like <code>eager_load</code></li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">&gt; Blog.includes<span class="o">(</span>:posts<span class="o">)</span>.where<span class="o">(</span>name: <span class="s1">&#39;Blog 1&#39;</span><span class="o">)</span>.references<span class="o">(</span>:posts<span class="o">)</span>
</span><span class="line">  SQL <span class="o">(</span>0.2ms<span class="o">)</span>  SELECT <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;id&quot;</span> AS t0_r0, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;name&quot;</span> AS t0_r1, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;author&quot;</span> AS t0_r2, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;created_at&quot;</span> AS t0_r3, <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;updated_at&quot;</span> AS t0_r4, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;id&quot;</span> AS t1_r0, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;title&quot;</span> AS t1_r1, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;created_at&quot;</span> AS t1_r2, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;updated_at&quot;</span> AS t1_r3, <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> AS t1_r4 FROM <span class="s2">&quot;blogs&quot;</span> LEFT OUTER JOIN <span class="s2">&quot;posts&quot;</span> ON <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> <span class="o">=</span> <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;id&quot;</span> WHERE <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;name&quot;</span> <span class="o">=</span> ?  <span class="o">[[</span><span class="s2">&quot;name&quot;</span>, <span class="s2">&quot;Blog 1&quot;</span><span class="o">]]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="joins">joins</h3>

<p><em>INNER JOIN</em>, compared to <code>eager_load</code> (<em>LEFT OUTER JOIN</em>).</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">&gt; Blog.joins<span class="o">(</span>:posts<span class="o">)</span>
</span><span class="line">  Blog Load <span class="o">(</span>0.2ms<span class="o">)</span>  SELECT <span class="s2">&quot;blogs&quot;</span>.* FROM <span class="s2">&quot;blogs&quot;</span> INNER JOIN <span class="s2">&quot;posts&quot;</span> ON <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> <span class="o">=</span> <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;id&quot;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><strong>compared to <code>eager_load</code></strong></p>

<p>Query by <code>joins</code> just returns the raw data, whereas the data from <code>eager_load</code> is filtered by Rails.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">&gt; Blog.joins<span class="o">(</span>:posts<span class="o">)</span>.count
</span><span class="line">   <span class="o">(</span>0.3ms<span class="o">)</span>  SELECT COUNT<span class="o">(</span>*<span class="o">)</span> FROM <span class="s2">&quot;blogs&quot;</span> INNER JOIN <span class="s2">&quot;posts&quot;</span> ON <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> <span class="o">=</span> <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;id&quot;</span>
</span><span class="line"> <span class="o">=</span>&gt; 15
</span><span class="line">&gt; Blog.eager_load<span class="o">(</span>:posts<span class="o">)</span>.count
</span><span class="line">   <span class="o">(</span>0.4ms<span class="o">)</span>  SELECT COUNT<span class="o">(</span>DISTINCT <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;id&quot;</span><span class="o">)</span> FROM <span class="s2">&quot;blogs&quot;</span> LEFT OUTER JOIN <span class="s2">&quot;posts&quot;</span> ON <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> <span class="o">=</span> <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;id&quot;</span>
</span><span class="line"> <span class="o">=</span>&gt; 3
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>So you need to take caution about iteration on <code>joins</code> query.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
<span class="line-number">34</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">&gt; Blog.joins<span class="o">(</span>:posts<span class="o">)</span>.each <span class="k">do</span> |blog|
</span><span class="line">&gt;   puts blog.posts.map<span class="o">(</span>&amp;:title<span class="o">)</span>.join<span class="o">(</span><span class="s1">&#39;, &#39;</span><span class="o">)</span>
</span><span class="line">&gt; end
</span><span class="line">  Blog Load <span class="o">(</span>0.2ms<span class="o">)</span>  SELECT <span class="s2">&quot;blogs&quot;</span>.* FROM <span class="s2">&quot;blogs&quot;</span> INNER JOIN <span class="s2">&quot;posts&quot;</span> ON <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> <span class="o">=</span> <span class="s2">&quot;blogs&quot;</span>.<span class="s2">&quot;id&quot;</span>
</span><span class="line">  Post Load <span class="o">(</span>0.3ms<span class="o">)</span>  SELECT <span class="s2">&quot;posts&quot;</span>.* FROM <span class="s2">&quot;posts&quot;</span> WHERE <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> <span class="o">=</span> ?  <span class="o">[[</span><span class="s2">&quot;blog_id&quot;</span>, 1<span class="o">]]</span>
</span><span class="line">Post 1-1, Post 1-2, Post 1-3, Post 1-4, Post 1-5
</span><span class="line">  Post Load <span class="o">(</span>0.1ms<span class="o">)</span>  SELECT <span class="s2">&quot;posts&quot;</span>.* FROM <span class="s2">&quot;posts&quot;</span> WHERE <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> <span class="o">=</span> ?  <span class="o">[[</span><span class="s2">&quot;blog_id&quot;</span>, 1<span class="o">]]</span>
</span><span class="line">Post 1-1, Post 1-2, Post 1-3, Post 1-4, Post 1-5
</span><span class="line">  Post Load <span class="o">(</span>0.1ms<span class="o">)</span>  SELECT <span class="s2">&quot;posts&quot;</span>.* FROM <span class="s2">&quot;posts&quot;</span> WHERE <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> <span class="o">=</span> ?  <span class="o">[[</span><span class="s2">&quot;blog_id&quot;</span>, 1<span class="o">]]</span>
</span><span class="line">Post 1-1, Post 1-2, Post 1-3, Post 1-4, Post 1-5
</span><span class="line">  Post Load <span class="o">(</span>0.1ms<span class="o">)</span>  SELECT <span class="s2">&quot;posts&quot;</span>.* FROM <span class="s2">&quot;posts&quot;</span> WHERE <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> <span class="o">=</span> ?  <span class="o">[[</span><span class="s2">&quot;blog_id&quot;</span>, 1<span class="o">]]</span>
</span><span class="line">Post 1-1, Post 1-2, Post 1-3, Post 1-4, Post 1-5
</span><span class="line">  Post Load <span class="o">(</span>0.1ms<span class="o">)</span>  SELECT <span class="s2">&quot;posts&quot;</span>.* FROM <span class="s2">&quot;posts&quot;</span> WHERE <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> <span class="o">=</span> ?  <span class="o">[[</span><span class="s2">&quot;blog_id&quot;</span>, 1<span class="o">]]</span>
</span><span class="line">Post 1-1, Post 1-2, Post 1-3, Post 1-4, Post 1-5
</span><span class="line">  Post Load <span class="o">(</span>0.1ms<span class="o">)</span>  SELECT <span class="s2">&quot;posts&quot;</span>.* FROM <span class="s2">&quot;posts&quot;</span> WHERE <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> <span class="o">=</span> ?  <span class="o">[[</span><span class="s2">&quot;blog_id&quot;</span>, 2<span class="o">]]</span>
</span><span class="line">Post 2-1, Post 2-2, Post 2-3, Post 2-4, Post 2-5
</span><span class="line">  Post Load <span class="o">(</span>0.1ms<span class="o">)</span>  SELECT <span class="s2">&quot;posts&quot;</span>.* FROM <span class="s2">&quot;posts&quot;</span> WHERE <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> <span class="o">=</span> ?  <span class="o">[[</span><span class="s2">&quot;blog_id&quot;</span>, 2<span class="o">]]</span>
</span><span class="line">Post 2-1, Post 2-2, Post 2-3, Post 2-4, Post 2-5
</span><span class="line">  Post Load <span class="o">(</span>0.1ms<span class="o">)</span>  SELECT <span class="s2">&quot;posts&quot;</span>.* FROM <span class="s2">&quot;posts&quot;</span> WHERE <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> <span class="o">=</span> ?  <span class="o">[[</span><span class="s2">&quot;blog_id&quot;</span>, 2<span class="o">]]</span>
</span><span class="line">Post 2-1, Post 2-2, Post 2-3, Post 2-4, Post 2-5
</span><span class="line">  Post Load <span class="o">(</span>0.1ms<span class="o">)</span>  SELECT <span class="s2">&quot;posts&quot;</span>.* FROM <span class="s2">&quot;posts&quot;</span> WHERE <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> <span class="o">=</span> ?  <span class="o">[[</span><span class="s2">&quot;blog_id&quot;</span>, 2<span class="o">]]</span>
</span><span class="line">Post 2-1, Post 2-2, Post 2-3, Post 2-4, Post 2-5
</span><span class="line">  Post Load <span class="o">(</span>0.1ms<span class="o">)</span>  SELECT <span class="s2">&quot;posts&quot;</span>.* FROM <span class="s2">&quot;posts&quot;</span> WHERE <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> <span class="o">=</span> ?  <span class="o">[[</span><span class="s2">&quot;blog_id&quot;</span>, 2<span class="o">]]</span>
</span><span class="line">Post 2-1, Post 2-2, Post 2-3, Post 2-4, Post 2-5
</span><span class="line">  Post Load <span class="o">(</span>0.1ms<span class="o">)</span>  SELECT <span class="s2">&quot;posts&quot;</span>.* FROM <span class="s2">&quot;posts&quot;</span> WHERE <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> <span class="o">=</span> ?  <span class="o">[[</span><span class="s2">&quot;blog_id&quot;</span>, 3<span class="o">]]</span>
</span><span class="line">Post 3-1, Post 3-2, Post 3-3, Post 3-4, Post 3-5
</span><span class="line">  Post Load <span class="o">(</span>0.2ms<span class="o">)</span>  SELECT <span class="s2">&quot;posts&quot;</span>.* FROM <span class="s2">&quot;posts&quot;</span> WHERE <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> <span class="o">=</span> ?  <span class="o">[[</span><span class="s2">&quot;blog_id&quot;</span>, 3<span class="o">]]</span>
</span><span class="line">Post 3-1, Post 3-2, Post 3-3, Post 3-4, Post 3-5
</span><span class="line">  Post Load <span class="o">(</span>0.1ms<span class="o">)</span>  SELECT <span class="s2">&quot;posts&quot;</span>.* FROM <span class="s2">&quot;posts&quot;</span> WHERE <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> <span class="o">=</span> ?  <span class="o">[[</span><span class="s2">&quot;blog_id&quot;</span>, 3<span class="o">]]</span>
</span><span class="line">Post 3-1, Post 3-2, Post 3-3, Post 3-4, Post 3-5
</span><span class="line">  Post Load <span class="o">(</span>0.1ms<span class="o">)</span>  SELECT <span class="s2">&quot;posts&quot;</span>.* FROM <span class="s2">&quot;posts&quot;</span> WHERE <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> <span class="o">=</span> ?  <span class="o">[[</span><span class="s2">&quot;blog_id&quot;</span>, 3<span class="o">]]</span>
</span><span class="line">Post 3-1, Post 3-2, Post 3-3, Post 3-4, Post 3-5
</span><span class="line">  Post Load <span class="o">(</span>0.1ms<span class="o">)</span>  SELECT <span class="s2">&quot;posts&quot;</span>.* FROM <span class="s2">&quot;posts&quot;</span> WHERE <span class="s2">&quot;posts&quot;</span>.<span class="s2">&quot;blog_id&quot;</span> <span class="o">=</span> ?  <span class="o">[[</span><span class="s2">&quot;blog_id&quot;</span>, 3<span class="o">]]</span>
</span><span class="line">Post 3-1, Post 3-2, Post 3-3, Post 3-4, Post 3-5
</span></code></pre></td></tr></table></div></figure></notextile></div>

<hr />

<p><strong>Reference</strong></p>

<ul>
  <li><a href="http://blog.diatomenterprises.com/remove-n1-queries-in-your-ruby-on-rails-app/?utm_source=rubyweekly&amp;utm_medium=email">Remove N+1 queries in your Ruby on Rails app</a></li>
  <li><a href="http://stackoverflow.com/questions/1208636/rails-include-vs-joins?rq=1">Rails :include vs. :joins</a></li>
  <li><a href="http://blog.bigbinary.com/2013/07/01/preload-vs-eager-load-vs-joins-vs-includes.html">Preload, Eagerload, Includes and Joins</a></li>
  <li><a href="http://www.akitaonrails.com/2008/5/26/rolling-with-rails-2-1-the-first-full-tutorial-part-2">Rolling with Rails 2.1 - The First Full Tutorial - Part 2</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Data Types in Rails]]></title>
    <link href="http://blog.ifyouseewendy.com/blog/2015/08/10/data-types-in-rails/"/>
    <updated>2015-08-10T17:45:53+08:00</updated>
    <id>http://blog.ifyouseewendy.com/blog/2015/08/10/data-types-in-rails</id>
    <content type="html"><![CDATA[<p><strong><em>Have you ever got annoyed with data types when you are creating Rails migrations?</em></strong></p>

<p><strong><em>What‚Äôs the full list of data types in Rails? Does it differ from MySQL to PostgreSQL?</em></strong></p>

<p><strong><em>When adding a <code>title</code> field to <code>Post</code> table, should we use <code>title</code> as a <code>string</code> or <code>text</code>? Same answer with MySQL and PostgreSQL?</em></strong></p>

<p>You may want to check the Rails guides of <a href="http://edgeguides.rubyonrails.org/active_record_migrations.html">Active Record Migrations</a>, but all you get is disappointment because its lacking of essential information about data types.</p>

<p>Here is a quick entry about data types which I extracts from Rails API and Stack Overflow.</p>

<h2 id="general-data-type">General Data Type</h2>

<blockquote>
  <p>From <a href="http://api.rubyonrails.org/classes/ActiveRecord/ConnectionAdapters/TableDefinition.html#method-i-column">ActiveRecord::ConnectionAdapters::TableDefinition#column</a></p>
</blockquote>

<p>Instantiates a new column for the table. The type parameter is normally one of the migrations native types, which is one of the following: </p>

<ul>
  <li><code>:primary_key</code></li>
  <li><code>:string</code></li>
  <li><code>:text</code></li>
  <li><code>:integer</code></li>
  <li><code>:float</code></li>
  <li><code>:decimal</code></li>
  <li><code>:datetime</code></li>
  <li><code>:time</code></li>
  <li><code>:date</code></li>
  <li><code>:binary</code></li>
  <li><code>:boolean</code></li>
</ul>

<h2 id="specific-dbms-data-type">Specific DBMS Data Type</h2>

<blockquote>
  <p>From Psylone‚Äôs answer on <a href="http://stackoverflow.com/a/17279395/1331774">Where is the documentation page for ActiveRecord data types?</a></p>
</blockquote>

<p>Check the specific DB adaptor in source code.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>MySQL Data Types</span><a href="https://github.com/rails/rails/blob/master/activerecord/lib/active_record/connection_adapters/abstract_mysql_adapter.rb#L244-L256">link</a></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="no">NATIVE_DATABASE_TYPES</span> <span class="o">=</span> <span class="p">{</span>
</span><span class="line">  <span class="ss">:primary_key</span> <span class="o">=&gt;</span> <span class="s2">&quot;int(11) auto_increment PRIMARY KEY&quot;</span><span class="p">,</span>
</span><span class="line">  <span class="ss">:string</span>      <span class="o">=&gt;</span> <span class="p">{</span> <span class="ss">:name</span> <span class="o">=&gt;</span> <span class="s2">&quot;varchar&quot;</span><span class="p">,</span> <span class="ss">:limit</span> <span class="o">=&gt;</span> <span class="mi">255</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">:text</span>        <span class="o">=&gt;</span> <span class="p">{</span> <span class="ss">:name</span> <span class="o">=&gt;</span> <span class="s2">&quot;text&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">:integer</span>     <span class="o">=&gt;</span> <span class="p">{</span> <span class="ss">:name</span> <span class="o">=&gt;</span> <span class="s2">&quot;int&quot;</span><span class="p">,</span> <span class="ss">:limit</span> <span class="o">=&gt;</span> <span class="mi">4</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">:float</span>       <span class="o">=&gt;</span> <span class="p">{</span> <span class="ss">:name</span> <span class="o">=&gt;</span> <span class="s2">&quot;float&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">:decimal</span>     <span class="o">=&gt;</span> <span class="p">{</span> <span class="ss">:name</span> <span class="o">=&gt;</span> <span class="s2">&quot;decimal&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">:datetime</span>    <span class="o">=&gt;</span> <span class="p">{</span> <span class="ss">:name</span> <span class="o">=&gt;</span> <span class="s2">&quot;datetime&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">:time</span>        <span class="o">=&gt;</span> <span class="p">{</span> <span class="ss">:name</span> <span class="o">=&gt;</span> <span class="s2">&quot;time&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">:date</span>        <span class="o">=&gt;</span> <span class="p">{</span> <span class="ss">:name</span> <span class="o">=&gt;</span> <span class="s2">&quot;date&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">:binary</span>      <span class="o">=&gt;</span> <span class="p">{</span> <span class="ss">:name</span> <span class="o">=&gt;</span> <span class="s2">&quot;blob&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">:boolean</span>     <span class="o">=&gt;</span> <span class="p">{</span> <span class="ss">:name</span> <span class="o">=&gt;</span> <span class="s2">&quot;tinyint&quot;</span><span class="p">,</span> <span class="ss">:limit</span> <span class="o">=&gt;</span> <span class="mi">1</span> <span class="p">}</span>
</span><span class="line"><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>PostgreSQL Data Types</span><a href="https://github.com/rails/rails/blob/master/activerecord/lib/active_record/connection_adapters/postgresql_adapter.rb#L77-L112">link</a></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
<span class="line-number">34</span>
<span class="line-number">35</span>
<span class="line-number">36</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="no">NATIVE_DATABASE_TYPES</span> <span class="o">=</span> <span class="p">{</span>
</span><span class="line">  <span class="n">primary_key</span><span class="p">:</span> <span class="s2">&quot;serial primary key&quot;</span><span class="p">,</span>
</span><span class="line">  <span class="ss">bigserial</span><span class="p">:</span> <span class="s2">&quot;bigserial&quot;</span><span class="p">,</span>
</span><span class="line">  <span class="ss">string</span><span class="p">:</span>      <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;character varying&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">text</span><span class="p">:</span>        <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;text&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">integer</span><span class="p">:</span>     <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;integer&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">float</span><span class="p">:</span>       <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;float&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">decimal</span><span class="p">:</span>     <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;decimal&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">datetime</span><span class="p">:</span>    <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;timestamp&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">time</span><span class="p">:</span>        <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;time&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">date</span><span class="p">:</span>        <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;date&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">daterange</span><span class="p">:</span>   <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;daterange&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">numrange</span><span class="p">:</span>    <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;numrange&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">tsrange</span><span class="p">:</span>     <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;tsrange&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">tstzrange</span><span class="p">:</span>   <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;tstzrange&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">int4range</span><span class="p">:</span>   <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;int4range&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">int8range</span><span class="p">:</span>   <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;int8range&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">binary</span><span class="p">:</span>      <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;bytea&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">boolean</span><span class="p">:</span>     <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;boolean&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">bigint</span><span class="p">:</span>      <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;bigint&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">xml</span><span class="p">:</span>         <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;xml&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">tsvector</span><span class="p">:</span>    <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;tsvector&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">hstore</span><span class="p">:</span>      <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;hstore&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">inet</span><span class="p">:</span>        <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;inet&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">cidr</span><span class="p">:</span>        <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;cidr&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">macaddr</span><span class="p">:</span>     <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;macaddr&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">uuid</span><span class="p">:</span>        <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;uuid&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">json</span><span class="p">:</span>        <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;json&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">jsonb</span><span class="p">:</span>       <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;jsonb&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">ltree</span><span class="p">:</span>       <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;ltree&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">citext</span><span class="p">:</span>      <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;citext&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">point</span><span class="p">:</span>       <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;point&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">bit</span><span class="p">:</span>         <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;bit&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="n">bit_varying</span><span class="p">:</span> <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;bit varying&quot;</span> <span class="p">},</span>
</span><span class="line">  <span class="ss">money</span><span class="p">:</span>       <span class="p">{</span> <span class="nb">name</span><span class="p">:</span> <span class="s2">&quot;money&quot;</span> <span class="p">},</span>
</span><span class="line"><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Or, use <code>ActiveRecord::Base.connection.native_database_types.keys</code> to get all valid data types based on your database adaptor.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
<span class="line-number">34</span>
<span class="line-number">35</span>
<span class="line-number">36</span>
<span class="line-number">37</span>
<span class="line-number">38</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="c1"># PostgreSQL</span>
</span><span class="line"><span class="o">[</span><span class="mi">1</span><span class="o">]</span> <span class="n">pry</span><span class="p">(</span><span class="n">main</span><span class="p">)</span><span class="o">&gt;</span> <span class="ss">ActiveRecord</span><span class="p">:</span><span class="ss">:Base</span><span class="o">.</span><span class="n">connection</span><span class="o">.</span><span class="n">native_database_types</span><span class="o">.</span><span class="n">keys</span>
</span><span class="line"><span class="o">[</span>
</span><span class="line">  <span class="o">[</span> <span class="mi">0</span><span class="o">]</span> <span class="ss">:primary_key</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span> <span class="mi">1</span><span class="o">]</span> <span class="ss">:bigserial</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span> <span class="mi">2</span><span class="o">]</span> <span class="ss">:string</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span> <span class="mi">3</span><span class="o">]</span> <span class="ss">:text</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span> <span class="mi">4</span><span class="o">]</span> <span class="ss">:integer</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span> <span class="mi">5</span><span class="o">]</span> <span class="ss">:float</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span> <span class="mi">6</span><span class="o">]</span> <span class="ss">:decimal</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span> <span class="mi">7</span><span class="o">]</span> <span class="ss">:datetime</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span> <span class="mi">8</span><span class="o">]</span> <span class="ss">:time</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span> <span class="mi">9</span><span class="o">]</span> <span class="ss">:date</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span><span class="mi">10</span><span class="o">]</span> <span class="ss">:daterange</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span><span class="mi">11</span><span class="o">]</span> <span class="ss">:numrange</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span><span class="mi">12</span><span class="o">]</span> <span class="ss">:tsrange</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span><span class="mi">13</span><span class="o">]</span> <span class="ss">:tstzrange</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span><span class="mi">14</span><span class="o">]</span> <span class="ss">:int4range</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span><span class="mi">15</span><span class="o">]</span> <span class="ss">:int8range</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span><span class="mi">16</span><span class="o">]</span> <span class="ss">:binary</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span><span class="mi">17</span><span class="o">]</span> <span class="ss">:boolean</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span><span class="mi">18</span><span class="o">]</span> <span class="ss">:bigint</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span><span class="mi">19</span><span class="o">]</span> <span class="ss">:xml</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span><span class="mi">20</span><span class="o">]</span> <span class="ss">:tsvector</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span><span class="mi">21</span><span class="o">]</span> <span class="ss">:hstore</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span><span class="mi">22</span><span class="o">]</span> <span class="ss">:inet</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span><span class="mi">23</span><span class="o">]</span> <span class="ss">:cidr</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span><span class="mi">24</span><span class="o">]</span> <span class="ss">:macaddr</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span><span class="mi">25</span><span class="o">]</span> <span class="ss">:uuid</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span><span class="mi">26</span><span class="o">]</span> <span class="ss">:json</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span><span class="mi">27</span><span class="o">]</span> <span class="ss">:jsonb</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span><span class="mi">28</span><span class="o">]</span> <span class="ss">:ltree</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span><span class="mi">29</span><span class="o">]</span> <span class="ss">:citext</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span><span class="mi">30</span><span class="o">]</span> <span class="ss">:point</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span><span class="mi">31</span><span class="o">]</span> <span class="ss">:bit</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span><span class="mi">32</span><span class="o">]</span> <span class="ss">:bit_varying</span><span class="p">,</span>
</span><span class="line">  <span class="o">[</span><span class="mi">33</span><span class="o">]</span> <span class="ss">:money</span>
</span><span class="line"><span class="o">]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>There is another guide about <a href="http://edgeguides.rubyonrails.org/active_record_postgresql.html">Active Record and PostgreSQL</a>.</p>

<blockquote>
  <p>From gotqn‚Äôs answer on <a href="http://stackoverflow.com/a/25702629/1331774">Rails 4 datatypes?</a></p>
</blockquote>

<p>Rails data types mapping to different DB data types:</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/data_types_1.png" alt="Data Types 1" />
<img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/data_types_2.png" alt="Data Types 2" /></p>

<h2 id="data-type-shortcut-when-generating-model">Data Type Shortcut When Generating Model</h2>

<blockquote>
  <p>From tomascharad‚Äôs answer on <a href="http://stackoverflow.com/questions/17918117/rails-4-datatypes">Rails 4 datatypes?</a></p>
</blockquote>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
<span class="line-number">34</span>
<span class="line-number">35</span>
<span class="line-number">36</span>
<span class="line-number">37</span>
<span class="line-number">38</span>
<span class="line-number">39</span>
<span class="line-number">40</span>
<span class="line-number">41</span>
<span class="line-number">42</span>
<span class="line-number">43</span>
<span class="line-number">44</span>
<span class="line-number">45</span>
<span class="line-number">46</span>
<span class="line-number">47</span>
<span class="line-number">48</span>
<span class="line-number">49</span>
<span class="line-number">50</span>
<span class="line-number">51</span>
<span class="line-number">52</span>
<span class="line-number">53</span>
<span class="line-number">54</span>
<span class="line-number">55</span>
<span class="line-number">56</span>
<span class="line-number">57</span>
<span class="line-number">58</span>
<span class="line-number">59</span>
<span class="line-number">60</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>rails generate model -h
</span><span class="line">
</span><span class="line">Available field types:
</span><span class="line">
</span><span class="line">    Just after the field name you can specify a <span class="nb">type </span>like text or boolean.
</span><span class="line">    It will generate the column with the associated SQL type. For instance:
</span><span class="line">
</span><span class="line">        <span class="sb">`</span>rails generate model post title:string body:text<span class="sb">`</span>
</span><span class="line">
</span><span class="line">    will generate a title column with a varchar <span class="nb">type </span>and a body column with a text
</span><span class="line">    type. If no <span class="nb">type </span>is specified the string <span class="nb">type </span>will be used by default.
</span><span class="line">    You can use the following types:
</span><span class="line">
</span><span class="line">        integer
</span><span class="line">        primary_key
</span><span class="line">        decimal
</span><span class="line">        float
</span><span class="line">        boolean
</span><span class="line">        binary
</span><span class="line">        string
</span><span class="line">        text
</span><span class="line">        date
</span><span class="line">        <span class="nb">time</span>
</span><span class="line"><span class="nb">        </span>datetime
</span><span class="line">
</span><span class="line">    You can also consider <span class="sb">`</span>references<span class="sb">`</span> as a kind of type. For instance, <span class="k">if </span>you run:
</span><span class="line">
</span><span class="line">        <span class="sb">`</span>rails generate model photo title:string album:references<span class="sb">`</span>
</span><span class="line">
</span><span class="line">    It will generate an <span class="sb">`</span>album_id<span class="sb">`</span> column. You should generate these kinds of fields when
</span><span class="line">    you will use a <span class="sb">`</span>belongs_to<span class="sb">`</span> association, <span class="k">for </span>instance. <span class="sb">`</span>references<span class="sb">`</span> also supports
</span><span class="line">    polymorphism, you can <span class="nb">enable </span>polymorphism like this:
</span><span class="line">
</span><span class="line">        <span class="sb">`</span>rails generate model product supplier:references<span class="o">{</span>polymorphic<span class="o">}</span><span class="sb">`</span>
</span><span class="line">
</span><span class="line">    For integer, string, text and binary fields, an integer in curly braces will
</span><span class="line">    be <span class="nb">set </span>as the limit:
</span><span class="line">
</span><span class="line">        <span class="sb">`</span>rails generate model user pseudo:string<span class="o">{</span>30<span class="o">}</span><span class="sb">`</span>
</span><span class="line">
</span><span class="line">    For decimal, two integers separated by a comma in curly braces will be used
</span><span class="line">    <span class="k">for </span>precision and scale:
</span><span class="line">
</span><span class="line">        <span class="sb">`</span>rails generate model product <span class="s1">&#39;price:decimal{10,2}&#39;</span><span class="sb">`</span>
</span><span class="line">
</span><span class="line">    You can add a <span class="sb">`</span>:uniq<span class="sb">`</span> or <span class="sb">`</span>:index<span class="sb">`</span> suffix <span class="k">for </span>unique or standard indexes
</span><span class="line">    respectively:
</span><span class="line">
</span><span class="line">        <span class="sb">`</span>rails generate model user pseudo:string:uniq<span class="sb">`</span>
</span><span class="line">        <span class="sb">`</span>rails generate model user pseudo:string:index<span class="sb">`</span>
</span><span class="line">
</span><span class="line">    You can combine any single curly brace option with the index options:
</span><span class="line">
</span><span class="line">        <span class="sb">`</span>rails generate model user username:string<span class="o">{</span>30<span class="o">}</span>:uniq<span class="sb">`</span>
</span><span class="line">        <span class="sb">`</span>rails generate model product supplier:references<span class="o">{</span>polymorphic<span class="o">}</span>:index<span class="sb">`</span>
</span><span class="line">
</span><span class="line">    If you require a <span class="sb">`</span>password_digest<span class="sb">`</span> string column <span class="k">for </span>use with
</span><span class="line">    has_secure_password, you should specify <span class="sb">`</span>password:digest<span class="sb">`</span>:
</span><span class="line">
</span><span class="line">        <span class="sb">`</span>rails generate model user password:digest<span class="sb">`</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="should-you-choose-string-or-text">Should you choose string or text?</h2>

<p>In <strong>MySQL</strong></p>

<blockquote>
  <p>From tjeezy‚Äôs answer and Omar Qureshi‚Äôs comment on <a href="http://stackoverflow.com/a/3354452/1331774">Difference between string and text in rails?</a></p>
</blockquote>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">:string |                   VARCHAR                | :limit <span class="o">=</span>&gt; 1 to 255 <span class="o">(</span><span class="nv">default</span> <span class="o">=</span> 255<span class="o">)</span>
</span><span class="line">:text   | TINYTEXT, TEXT, MEDIUMTEXT, or LONGTEXT2 | :limit <span class="o">=</span>&gt; 1 to 4294967296 <span class="o">(</span><span class="nv">default</span> <span class="o">=</span> 65536<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>So you‚Äôd better specify the <code>:limit</code> as a reminder to yourself that there is a limit and you should have a validation in the model to ensure that the limit is not exceeded.</p>

<p>And, you can have indexes on <code>varchars</code>, you cannot on <code>text</code>.</p>

<p>In <strong>Postgresql</strong></p>

<blockquote>
  <p>From PostgreSQL Manual <a href="http://www.postgresql.org/docs/9.3/interactive/datatype-character.html">Character Types</a></p>
</blockquote>

<p>There is no performance difference among these three types, apart from increased storage space when using the blank-padded type, and a few extra CPU cycles to check the length when storing into a length-constrained column. While <code>character(n)</code> has performance advantages in some other database systems, there is no such advantage in PostgreSQL; in fact <code>character(n)</code> is usually the slowest of the three because of its additional storage costs. In most situations <code>text</code> or <code>character</code> varying should be used instead.</p>

<blockquote>
  <p>From Omar Qureshi‚Äôs answer on <a href="http://stackoverflow.com/questions/3354330/difference-between-string-and-text-in-rails">Difference between string and text in rails?</a></p>
</blockquote>

<p>If you are using postgres use <code>text</code> wherever you can, unless you have a size constraint since there is no performance penalty for <code>text</code> vs <code>varchar</code>.</p>

<blockquote>
  <p>From mu is too short‚Äôs answer on <a href="http://stackoverflow.com/questions/8129776/rails-3-postgres-how-long-is-a-string-if-you-dont-apply-limit-in-schema">rails 3/postgres - how long is a string if you don‚Äôt apply :limit in schema</a> and <a href="http://stackoverflow.com/questions/8694273/changing-a-column-type-to-longer-strings-in-rails/8694483#8694483">Changing a column type to longer strings in rails</a></p>
</blockquote>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">:string | character varying <span class="o">(</span>255<span class="o">)</span>
</span><span class="line">:text   | text
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>There‚Äôs no reason to use <code>:string</code> (AKA <code>varchar</code>) at all, the database treats <code>text</code> and <code>varchar(n)</code> the same internally except for the extra length constraints for <code>varchar(n)</code>; you should only use <code>varchar(n)</code> (AKA <code>:string</code>) if you have an external constrain on the column size.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ruby Float Point Arithmetic and Truncation]]></title>
    <link href="http://blog.ifyouseewendy.com/blog/2015/04/11/ruby-float-point-arithmetic-and-truncation/"/>
    <updated>2015-04-11T21:17:56+08:00</updated>
    <id>http://blog.ifyouseewendy.com/blog/2015/04/11/ruby-float-point-arithmetic-and-truncation</id>
    <content type="html"><![CDATA[<p><strong><em>How to keep precision on float point arithmetic?</em></strong></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="mi">190000</span> <span class="o">*</span> <span class="p">(</span> <span class="mi">783</span><span class="o">.</span><span class="mi">0</span> <span class="o">/</span> <span class="mi">10000</span> <span class="p">)</span>
</span><span class="line"><span class="c1"># =&gt; 14876.999999999998</span>
</span><span class="line">
</span><span class="line"><span class="p">(</span> <span class="mi">190000</span> <span class="o">*</span> <span class="mi">783</span><span class="o">.</span><span class="mi">0</span> <span class="p">)</span> <span class="o">/</span> <span class="mi">10000</span>
</span><span class="line"><span class="c1"># =&gt; 14877.0</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><strong><em>How to make a 2 point truncation instead of rounding?</em></strong></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="mi">195555</span> <span class="o">*</span> <span class="mi">0</span><span class="o">.</span><span class="mo">07</span><span class="mi">83</span>
</span><span class="line"><span class="c1"># =&gt; 15311.956499999998</span>
</span><span class="line">
</span><span class="line"><span class="p">(</span> <span class="mi">195555</span> <span class="o">*</span> <span class="mi">0</span><span class="o">.</span><span class="mo">07</span><span class="mi">83</span> <span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span class="line"><span class="c1"># =&gt; 15311.96</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="plain-solution">Plain Solution</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
<span class="line-number">34</span>
<span class="line-number">35</span>
<span class="line-number">36</span>
<span class="line-number">37</span>
<span class="line-number">38</span>
<span class="line-number">39</span>
<span class="line-number">40</span>
<span class="line-number">41</span>
<span class="line-number">42</span>
<span class="line-number">43</span>
<span class="line-number">44</span>
<span class="line-number">45</span>
<span class="line-number">46</span>
<span class="line-number">47</span>
<span class="line-number">48</span>
<span class="line-number">49</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="c1"># Public: A calculator aims handling Float operation precision and</span>
</span><span class="line"><span class="c1"># saving the result with truncated 2 point Float.</span>
</span><span class="line"><span class="c1">#</span>
</span><span class="line"><span class="c1"># Examples</span>
</span><span class="line"><span class="c1">#</span>
</span><span class="line"><span class="c1">#   190000 * 0.0783</span>
</span><span class="line"><span class="c1">#   # =&gt; 14876.999999999998</span>
</span><span class="line"><span class="c1">#   190000 * 783 / 10000</span>
</span><span class="line"><span class="c1">#   # =&gt; 14877</span>
</span><span class="line"><span class="c1">#</span>
</span><span class="line"><span class="c1">#   cal = RateCalculator.new(190000, 0.0783)</span>
</span><span class="line"><span class="c1">#   cal.run</span>
</span><span class="line"><span class="c1">#   # =&gt; 14877.0</span>
</span><span class="line"><span class="c1">#</span>
</span><span class="line"><span class="c1">#</span>
</span><span class="line"><span class="c1">#   195555 * 0.0783</span>
</span><span class="line"><span class="c1">#   # =&gt; 15311.956499999998</span>
</span><span class="line"><span class="c1">#</span>
</span><span class="line"><span class="c1">#   cal = RateCalculator.new(195555, 0.0783)</span>
</span><span class="line"><span class="c1">#   # =&gt; 15311.95</span>
</span><span class="line"><span class="c1">#</span>
</span><span class="line"><span class="c1"># Returns a Float</span>
</span><span class="line"><span class="k">class</span> <span class="nc">RateCalculator</span>
</span><span class="line">  <span class="kp">attr_reader</span> <span class="ss">:base</span><span class="p">,</span> <span class="ss">:rate</span>
</span><span class="line">
</span><span class="line">  <span class="c1"># Internal: Handles 6 point rate.</span>
</span><span class="line">  <span class="no">MAGNIFIER</span> <span class="o">=</span> <span class="mi">1000000</span>
</span><span class="line">
</span><span class="line">  <span class="c1"># Public: Initialization</span>
</span><span class="line">  <span class="c1">#</span>
</span><span class="line">  <span class="c1"># base - Integer</span>
</span><span class="line">  <span class="c1"># rate - Numeric</span>
</span><span class="line">  <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="n">rate</span><span class="p">)</span>
</span><span class="line">    <span class="k">raise</span> <span class="s2">&quot;#initialize: &lt;base&gt; needs to be Integer&quot;</span> <span class="k">unless</span> <span class="n">base</span><span class="o">.</span><span class="n">is_a?</span> <span class="nb">Integer</span>
</span><span class="line">
</span><span class="line">    <span class="vi">@base</span> <span class="o">=</span> <span class="n">base</span>
</span><span class="line">    <span class="vi">@rate</span> <span class="o">=</span> <span class="n">rate</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line">
</span><span class="line">  <span class="k">def</span> <span class="nf">run</span>
</span><span class="line">    <span class="n">truncate_2_point</span> <span class="no">MAGNIFIER</span><span class="o">*</span><span class="n">rate</span><span class="o">*</span><span class="n">base</span><span class="o">/</span><span class="no">MAGNIFIER</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line">
</span><span class="line">  <span class="kp">private</span>
</span><span class="line">
</span><span class="line">    <span class="k">def</span> <span class="nf">truncate_2_point</span><span class="p">(</span><span class="n">float</span><span class="p">)</span>
</span><span class="line">      <span class="p">(</span><span class="n">float</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">to_i</span> <span class="o">/</span> <span class="mi">100</span><span class="o">.</span><span class="mi">0</span>
</span><span class="line">    <span class="k">end</span>
</span><span class="line"><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>It works, but with so many worries about the unknown conditions.</p>

<h3 id="bigdecimal">BigDecimal</h3>

<p>First, what the hell happens on the precision of float point arithmetic?</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="mi">0</span><span class="o">.</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">0</span><span class="o">.</span><span class="mi">2</span>
</span><span class="line"><span class="c1"># =&gt; 0.30000000000000004</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>According to <a href="http://floating-point-gui.de/">What Every Programmer Should Know About Floating-Point Arithmetic</a>, the answer is the binary fraction issue.</p>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/binary_fraction.png" alt="Binary Fraction" /></p>

<blockquote>
  <p>Specifically, binary can only represent those numbers as a finite fraction where the denominator is a power of 2. Unfortunately, this does not include most of the numbers that can be represented as finite fraction in base 10, like 0.1.</p>
</blockquote>

<p>To get through the precision problem, Ruby provides the <strong>Arbitrary-Precision Decimal</strong> shipped by <code>BigDecimal</code>. And so sweet, <code>BigDecimal</code> supports several rounding modes, including <code>:truncate</code>.</p>

<p>Here is the final solution.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
<span class="line-number">34</span>
<span class="line-number">35</span>
<span class="line-number">36</span>
<span class="line-number">37</span>
<span class="line-number">38</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="nb">require</span> <span class="s1">&#39;bigdecimal&#39;</span>
</span><span class="line">
</span><span class="line"><span class="c1"># Public: A calculator aims handling arithmatic precision and</span>
</span><span class="line"><span class="c1"># saving the result with 2 points truncated decimal.</span>
</span><span class="line"><span class="c1">#</span>
</span><span class="line"><span class="c1"># Examples</span>
</span><span class="line"><span class="c1">#</span>
</span><span class="line"><span class="c1">#   190000 * 0.0783</span>
</span><span class="line"><span class="c1">#   # =&gt; 14876.999999999998</span>
</span><span class="line"><span class="c1">#   190000 * 783 / 10000</span>
</span><span class="line"><span class="c1">#   # =&gt; 14877</span>
</span><span class="line"><span class="c1">#</span>
</span><span class="line"><span class="c1">#   cal = RateCalculator.new(190000, 0.0783).run</span>
</span><span class="line"><span class="c1">#   # =&gt; 14877.0</span>
</span><span class="line"><span class="c1">#</span>
</span><span class="line"><span class="c1">#</span>
</span><span class="line"><span class="c1">#   195555 * 0.0783</span>
</span><span class="line"><span class="c1">#   # =&gt; 15311.956499999998</span>
</span><span class="line"><span class="c1">#</span>
</span><span class="line"><span class="c1">#   cal = RateCalculator.new(195555, 0.0783).run</span>
</span><span class="line"><span class="c1">#   # =&gt; 15311.95</span>
</span><span class="line"><span class="c1">#</span>
</span><span class="line"><span class="c1"># Returns a BigDecimal</span>
</span><span class="line"><span class="k">class</span> <span class="nc">RateCalculator</span>
</span><span class="line">  <span class="kp">attr_reader</span> <span class="ss">:base</span><span class="p">,</span> <span class="ss">:rate</span>
</span><span class="line">
</span><span class="line">  <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="n">rate</span><span class="p">)</span>
</span><span class="line">    <span class="vi">@base</span> <span class="o">=</span> <span class="no">BigDecimal</span><span class="p">(</span><span class="n">base</span><span class="o">.</span><span class="n">to_s</span><span class="p">)</span>
</span><span class="line">    <span class="vi">@rate</span> <span class="o">=</span> <span class="no">BigDecimal</span><span class="p">(</span><span class="n">rate</span><span class="o">.</span><span class="n">to_s</span><span class="p">)</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line">
</span><span class="line">  <span class="k">def</span> <span class="nf">run</span>
</span><span class="line">    <span class="no">BigDecimal</span><span class="o">.</span><span class="n">save_rounding_mode</span> <span class="k">do</span>
</span><span class="line">      <span class="no">BigDecimal</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="ss">BigDecimal</span><span class="p">:</span><span class="ss">:ROUND_MODE</span><span class="p">,</span> <span class="ss">:truncate</span><span class="p">)</span>
</span><span class="line">      <span class="p">(</span><span class="n">base</span><span class="o">*</span><span class="n">rate</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span class="line">    <span class="k">end</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line"><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h4 id="reference">Reference</h4>

<ul>
  <li><a href="http://floating-point-gui.de/">Float Point Guide</a></li>
  <li><a href="http://ruby-doc.org/stdlib-1.9.3/libdoc/bigdecimal/rdoc/BigDecimal.html">Ruby Doc BigDecimal</a></li>
  <li><a href="http://makandracards.com/makandra/1178-bigdecimal-arithmetic-in-ruby">BigDecimal arithmetic in Ruby</a></li>
  <li><a href="http://makandracards.com/makandra/1505-invoices-how-to-properly-round-and-calculate-totals">Invoices: How to properly round and calculate totals</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ruby Trick: Local Assignment over Method Sending]]></title>
    <link href="http://blog.ifyouseewendy.com/blog/2015/03/30/ruby-trick-local-assignment-over-method-sending/"/>
    <updated>2015-03-30T16:24:59+08:00</updated>
    <id>http://blog.ifyouseewendy.com/blog/2015/03/30/ruby-trick-local-assignment-over-method-sending</id>
    <content type="html"><![CDATA[<p>There is a weird situation I haven‚Äôt noticed before:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="k">class</span> <span class="nc">Counter</span>
</span><span class="line">  <span class="kp">attr_accessor</span> <span class="ss">:processed</span><span class="p">,</span> <span class="ss">:processed_names</span>
</span><span class="line">
</span><span class="line">  <span class="k">def</span> <span class="nf">initialize</span>
</span><span class="line">    <span class="vi">@processed</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class="line">    <span class="vi">@processed_names</span> <span class="o">=</span> <span class="o">[]</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line">
</span><span class="line">  <span class="k">def</span> <span class="nf">foo</span>
</span><span class="line">    <span class="n">processed</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line">
</span><span class="line">  <span class="k">def</span> <span class="nf">bar</span>
</span><span class="line">    <span class="n">processed_names</span> <span class="o">&lt;&lt;</span> <span class="s1">&#39;a&#39;</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line"><span class="k">end</span>
</span><span class="line">
</span><span class="line"><span class="n">w</span> <span class="o">=</span> <span class="no">Counter</span><span class="o">.</span><span class="n">new</span><span class="p">;</span>
</span><span class="line"><span class="n">w</span><span class="o">.</span><span class="n">foo</span> <span class="c1"># =&gt; NoMethodError: undefined method `+&#39; for nil:NilClass`</span>
</span><span class="line"><span class="n">w</span><span class="o">.</span><span class="n">bar</span> <span class="c1"># =&gt; [&#39;a&#39;]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><strong><em>Why the hell?</em></strong></p>

<p><strong>Local assignment always has precedence over method sending</strong>. Assignment happened in <code>w.foo</code>, which not in <code>w.bar</code>.</p>

<p>Check this one:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="k">class</span> <span class="nc">Person</span>
</span><span class="line">  <span class="kp">attr_accessor</span> <span class="ss">:name</span>
</span><span class="line">
</span><span class="line">  <span class="k">def</span> <span class="nf">foo</span>
</span><span class="line">    <span class="nb">name</span> <span class="o">=</span> <span class="s1">&#39;John&#39;</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line"><span class="k">end</span>
</span><span class="line">
</span><span class="line"><span class="n">t</span> <span class="o">=</span> <span class="no">Tao</span><span class="o">.</span><span class="n">new</span>
</span><span class="line"><span class="n">t</span><span class="o">.</span><span class="n">name</span> <span class="c1"># =&gt; nil</span>
</span><span class="line"><span class="n">t</span><span class="o">.</span><span class="n">foo</span>  <span class="c1"># =&gt; &#39;John&#39;</span>
</span><span class="line"><span class="n">t</span><span class="o">.</span><span class="n">name</span> <span class="c1"># =&gt; nil</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><code>name = 'John'</code> only means a definition of a local variable, which won‚Äôt send <code>=</code> to <code>name</code>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Annoying OAuth Issue on HTTP URL Encoding]]></title>
    <link href="http://blog.ifyouseewendy.com/blog/2015/03/04/annoying-oauth-issue-on-http-url-encoding/"/>
    <updated>2015-03-04T17:46:12+08:00</updated>
    <id>http://blog.ifyouseewendy.com/blog/2015/03/04/annoying-oauth-issue-on-http-url-encoding</id>
    <content type="html"><![CDATA[<p>I was developing and maintaining an OAuth service using <code>pelle/oauth-plugin</code> gem. Other than the standard token exchange process, there is a need to authenticate by signature based on user‚Äôs passed in parameters. As custom parameters can include custom charactors, here comes the space encoding issue.</p>

<ul>
  <li>Why the service approves my test script by passing <code>name=wendi</code> but refuses <code>name=Di Wen</code> ?</li>
  <li>Why the <code>CGI.escape('Di Wen')</code> outputs <code>"Di+Wen"</code>, while <code>URI.escape('Di Wen')</code> outpus <code>Di%20Wen</code> ?</li>
</ul>

<p>This is definitely an annoying issue. I‚Äôve run into it sometime before, but today I need to make a clear mind.</p>

<p><strong>What‚Äôs the HTTP standard way to encode space in URL?</strong></p>

<p><code>%20</code>, according to the <a href="http://www.w3schools.com/tags/ref_urlencode.asp">HTML URL Encoding Reference</a> by W3schools.</p>

<p><strong>Why the hell some libary encode space to <code>+</code>?</strong></p>

<p>Because of the <code>application/x-www-form-urlencoded</code> <em>MIME</em> type.</p>

<p>Refered to Wikipedia, <a href="http://en.wikipedia.org/wiki/Percent-encoding#The_application.2Fx-www-form-urlencoded_type">Percent Encoding</a></p>

<blockquote>
  <p>The encoding used by default is based on a very early version of the general URI percent-encoding rules, with a number of modifications such as newline normalization and replacing spaces with ‚Äú+‚Äù instead of ‚Äú%20‚Äù. The Internet media type of data encoded this way is application/x-www-form-urlencoded, and it is currently defined (still in a very outdated manner) in the HTML and XForms specifications.</p>
</blockquote>

<p>And <a href="http://stackoverflow.com/users/634419/anomie">Anomie</a> has a summary <a href="http://stackoverflow.com/a/5433216/1331774">answer</a>,</p>

<blockquote>
  <p>The query string format is actually a different but related encoding, application/x-www-form-urlencoded, defined in RFC 1866 along with HTML 2.0. It was based on RFC 1738, but specified that spaces (not all whitespace, just the character with ASCII code 0x20) are replaced by ‚Äò+‚Äô and that line breaks are to be encoded as CRLF (i.e. %0D%0A). The former is likely because that saves 2 bytes for a very common character in form submissions at the expense of using an extra 2 bytes for a much less common character, and the latter is to avoid problems when transferring between systems using different end-of-line codings. Non-ASCII characters were left unconsidered.</p>
</blockquote>

<blockquote>
  <p>UTF-8 coding in URIs came over a decade later, in RFC 3986, although individual protocols may have specified this or another encoding of non-ASCII characters earlier. To maintain backwards compatibility, all UTF-8 octets must be percent-encoded.</p>
</blockquote>

<p><strong>What‚Äôs the Rule of Thumb in Ruby world?</strong></p>

<p><a href="http://stackoverflow.com/users/409475/ernest">Ernest</a> makes a <a href="http://stackoverflow.com/questions/2824126/whats-the-difference-between-uri-escape-and-cgi-escape">specification</a> about the escape methods over <code>URI</code>, <code>CGI</code>, and <code>Addressable</code>, and gives a conclusion</p>

<blockquote>
  <ul>
    <li>Do not use URI.escape or similar</li>
    <li>Use CGI::escape if you only need form escape</li>
    <li>If you need to work with URIs, use Addressable, it offers url encoding, form encoding and normalizes URLs.</li>
  </ul>
</blockquote>

<p><strong>So, what‚Äôs the solution to my question?</strong></p>

<p>The <code>pelle/oauth-plugin</code> gem failed my test script with <code>CGI</code> by</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="n">pry</span><span class="p">(</span><span class="n">main</span><span class="p">)</span><span class="o">&gt;</span> <span class="no">CGI</span><span class="o">.</span><span class="n">escape</span> <span class="s1">&#39;Di Wen&#39;</span>
</span><span class="line"><span class="o">=&gt;</span> <span class="s2">&quot;Di+Wen&quot;</span>
</span><span class="line">
</span><span class="line"><span class="c1"># expecting &quot;Di%2BWen&quot;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Also failed <code>URI</code> and <code>Addressable</code> by</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="n">pry</span><span class="p">(</span><span class="n">main</span><span class="p">)</span><span class="o">&gt;</span> <span class="no">URI</span><span class="o">.</span><span class="n">escape</span> <span class="s1">&#39;Di@Wen&#39;</span>
</span><span class="line"><span class="o">=&gt;</span> <span class="s2">&quot;Di@Wen&quot;</span>
</span><span class="line">
</span><span class="line"><span class="n">pry</span><span class="p">(</span><span class="n">main</span><span class="p">)</span><span class="o">&gt;</span> <span class="ss">Addressable</span><span class="p">:</span><span class="ss">:URI</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s2">&quot;Di@Wen&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">normalize</span>
</span><span class="line"><span class="o">=&gt;</span> <span class="c1">#&lt;Addressable::URI:0x81f58abc URI:Di@Wen&gt;</span>
</span><span class="line">
</span><span class="line"><span class="c1"># expecting &quot;Di%40Wen&quot;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>After some digging into the gem, I‚Äôve found its encoding method</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="c1"># Escape +value+ by URL encoding all non-reserved character.</span>
</span><span class="line"><span class="c1">#</span>
</span><span class="line"><span class="c1"># See Also: {OAuth core spec version 1.0, section 5.1}[http://oauth.net/core/1.0#rfc.section.5.1]</span>
</span><span class="line"><span class="k">def</span> <span class="nf">escape</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
</span><span class="line">  <span class="ss">URI</span><span class="p">:</span><span class="ss">:escape</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">to_s</span><span class="p">,</span> <span class="ss">OAuth</span><span class="p">:</span><span class="ss">:RESERVED_CHARACTERS</span><span class="p">)</span>
</span><span class="line"><span class="k">rescue</span> <span class="no">ArgumentError</span>
</span><span class="line">  <span class="ss">URI</span><span class="p">:</span><span class="ss">:escape</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">to_s</span><span class="o">.</span><span class="n">force_encoding</span><span class="p">(</span><span class="ss">Encoding</span><span class="p">:</span><span class="ss">:UTF_8</span><span class="p">),</span> <span class="ss">OAuth</span><span class="p">:</span><span class="ss">:RESERVED_CHARACTERS</span><span class="p">)</span>
</span><span class="line"><span class="k">end</span>
</span><span class="line">
</span><span class="line">
</span><span class="line"><span class="ss">OAuth</span><span class="p">:</span><span class="ss">:RESERVED_CHARACTERS</span> <span class="c1"># =&gt; /[^a-zA-Z0-9\-\.\_\~]/</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Following the comment, comes along the OAuth standard specification about <a href="http://oauth.net/core/1.0/#rfc.section.5.1">Parameter Encoding</a></p>

<blockquote>
  <p>All parameter names and values are escaped using the [RFC3986] percent-encoding (%xx) mechanism. Characters not in the unreserved character set ([RFC3986] section 2.3) MUST be encoded. Characters in the unreserved character set MUST NOT be encoded. Hexadecimal characters in encodings MUST be upper case. Text names and values MUST be encoded as UTF-8 octets before percent-encoding them per [RFC3629].</p>
</blockquote>

<blockquote>
  <pre><code>unreserved = ALPHA, DIGIT, '-', '.', '_', '~'
</code></pre>
</blockquote>

<p>Under the standard spec and refering to the gem‚Äôs implementation, I‚Äôve finally solved my stupid issue.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Great Expectations 2015]]></title>
    <link href="http://blog.ifyouseewendy.com/blog/2015/02/27/great-expectations-2015/"/>
    <updated>2015-02-27T12:52:00+08:00</updated>
    <id>http://blog.ifyouseewendy.com/blog/2015/02/27/great-expectations-2015</id>
    <content type="html"><![CDATA[<h2 id="target">Target</h2>

<p><strong>Algorithm</strong></p>

<ul>
  <li>Reading Algorithms 4th thoroughly.</li>
  <li>Algorithm course on Coursera.</li>
</ul>

<p><strong>English</strong></p>

<ul>
  <li>Words, need an efficient way to study new and review regularly</li>
  <li>Listening, keep on Friends or podcast.</li>
</ul>

<p>Key point is to make it a regular stuff.</p>

<p><strong>Source Code Reading</strong></p>

<ul>
  <li>Find or create a written, detailed, repeatable process to follow.</li>
  <li><a href="http://www.justinweiss.com/blog/2015/02/03/finding-your-way-around-a-new-rails-project/?utm_source=Weissblog+Subscribers&amp;utm_campaign=80c8a475a1-The_best_way_to_fight_being_overwhelmed2_5_2015&amp;utm_medium=email&amp;utm_term=0_2494b7d197-80c8a475a1-120246897">Finding Your Way Around a New Rails Project</a></li>
</ul>

<h2 id="habit">Habit</h2>

<p><em>#lift.do</em></p>

<p><strong>Get Up Early</strong></p>

<ul>
  <li>Review yesterday <em>#dayone</em></li>
  <li>Schedule on new day <em>#sunrise</em> <em>#omnifocus</em></li>
</ul>

<p><strong>Record Daily Life</strong></p>

<ul>
  <li>Knowledge <em>#evernote</em></li>
  <li>Life trivia <em>#dayone</em></li>
  <li>Financial status, monthly</li>
</ul>

<p><strong>One Hour Tech Reading</strong></p>

<p>Need to keep quiet and focused, books or source code.</p>

<h2 id="workday">Workday</h2>

<blockquote>
  <p>What should be a workday like?</p>
</blockquote>

<ul>
  <li>08:00 Get up, do the reviewing and scheduling.</li>
  <li>10:00 Company stuff I</li>
  <li>12:00 Lunch</li>
  <li>13:00 Company stuff II</li>
  <li>16:00 Tech read</li>
  <li>17:00 Email subscriptions and browsing </li>
  <li>18:00 Company stuff IIII</li>
  <li>20:00 Back home</li>
  <li>22:30 Dear Diary</li>
  <li>23:00 Go to bed and random read.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Review] Guidance from POODR]]></title>
    <link href="http://blog.ifyouseewendy.com/blog/2015/01/29/guidance-from-poodr/"/>
    <updated>2015-01-29T15:20:13+08:00</updated>
    <id>http://blog.ifyouseewendy.com/blog/2015/01/29/guidance-from-poodr</id>
    <content type="html"><![CDATA[<table class="custom">
  <tbody>
    <tr>
      <td><strong>Book</strong></td>
      <td>Practical Object Oriented Design in Ruby</td>
    </tr>
    <tr>
      <td><strong>Author</strong></td>
      <td>Sandi Metz</td>
    </tr>
    <tr>
      <td><strong>Link</strong></td>
      <td><a href="http://www.poodr.com/">www.poodr.com</a></td>
    </tr>
  </tbody>
</table>

<ul id="markdown-toc">
  <li><a href="#object-oriented-design">Object-Oriented Design</a>    <ul>
      <li><a href="#the-tools-of-design">The Tools of Design</a>        <ul>
          <li><a href="#design-principles">Design Principles</a></li>
          <li><a href="#design-patterns">Design Patterns</a></li>
        </ul>
      </li>
      <li><a href="#the-act-of-design">The Act of Design</a>        <ul>
          <li><a href="#how-design-fails">How Design Fails</a></li>
          <li><a href="#when-to-design">When to Design</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#guidance">Guidance</a>    <ul>
      <li><a href="#designing-classes-with-a-single-responsibility">Designing Classes with a Single Responsibility</a>        <ul>
          <li><a href="#depend-on-behavior-not-data">Depend on Behavior, Not Data</a></li>
          <li><a href="#enforce-single-responsibility-everywhere">Enforce Single Responsibility Everywhere</a></li>
        </ul>
      </li>
      <li><a href="#manage-dependencies">Manage Dependencies</a>        <ul>
          <li><a href="#inject-dependencies">Inject Dependencies</a></li>
          <li><a href="#isolate-dependencies">Isolate Dependencies</a></li>
          <li><a href="#remove-argument-order-dependencies">Remove Argument-Order Dependencies</a></li>
          <li><a href="#managing-dependency-direction">Managing Dependency Direction</a></li>
        </ul>
      </li>
      <li><a href="#creating-flexible-interfaces">Creating Flexible Interfaces</a>        <ul>
          <li><a href="#finding-the-public-interface">Finding the Public Interface</a>            <ul>
              <li><a href="#focus-messages-between-domain-objects">Focus Messages between Domain Objects</a></li>
              <li><a href="#use-sequence-diagrams">Use Sequence Diagrams</a></li>
              <li><a href="#asking-for-what-instead-of-telling-how">Asking for ‚ÄúWhat‚Äù Instead of Telling ‚ÄúHow‚Äù</a></li>
              <li><a href="#seeking-context-independence">Seeking Context Independence</a></li>
            </ul>
          </li>
          <li><a href="#the-law-of-demeter">The Law of Demeter</a></li>
        </ul>
      </li>
      <li><a href="#reduction-costs-with-duck-typing">Reduction Costs with Duck Typing</a>        <ul>
          <li><a href="#polymorphism">Polymorphism</a></li>
          <li><a href="#recognizing-hidden-ducks">Recognizing Hidden Ducks</a></li>
          <li><a href="#guidance-1">Guidance</a></li>
        </ul>
      </li>
      <li><a href="#acquiring-behavior-through-inheritance">Acquiring Behavior Through Inheritance</a>        <ul>
          <li><a href="#inheritance">Inheritance</a></li>
          <li><a href="#recognizing-where-to-use-inheritance">Recognizing Where to Use Inheritance</a>            <ul>
              <li><a href="#finding-the-abstraction">Finding the Abstraction</a></li>
            </ul>
          </li>
          <li><a href="#using-templage-methods">Using Templage Methods</a>            <ul>
              <li><a href="#template-method">Template Method</a></li>
              <li><a href="#implementing-every-template-method">Implementing Every Template Method</a></li>
            </ul>
          </li>
          <li><a href="#manging-coupling">Manging Coupling</a>            <ul>
              <li><a href="#decoupling-subclasses-using-hook-messages">Decoupling Subclasses Using Hook Messages</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#sharing-role-behavior-with-modules">Sharing Role Behavior with Modules</a>        <ul>
          <li><a href="#understanding-roles">Understanding Roles</a></li>
          <li><a href="#writing-inheritable-code">Writing Inheritable Code</a>            <ul>
              <li><a href="#recognize-the-antipatterns">Recognize the Antipatterns</a></li>
              <li><a href="#insist-on-the-abstraction">Insist on the Abstraction</a></li>
              <li><a href="#honor-the-contract">Honor the Contract</a></li>
              <li><a href="#use-the-template-method-pattern">Use the Template Method Pattern</a></li>
              <li><a href="#preemptively-decouple-classes">Preemptively Decouple Classes</a></li>
              <li><a href="#create-shallow-hierarchies">Create Shallow Hierarchies</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#combining-objects-with-composition">Combining Objects with Composition</a>        <ul>
          <li><a href="#aggregation-a-special-kind-of-composition">Aggregation: A Special Kind of Composition</a></li>
          <li><a href="#deciding-between-inheritance-and-composition">Deciding Between Inheritance and Composition</a>            <ul>
              <li><a href="#inheritance-1">Inheritance</a></li>
              <li><a href="#composition">Composition</a></li>
            </ul>
          </li>
          <li><a href="#guidance-2">Guidance</a></li>
        </ul>
      </li>
      <li><a href="#designing-cost-effective-tests">Designing Cost-Effective Tests</a>        <ul>
          <li><a href="#intentional-testing">Intentional Testing</a>            <ul>
              <li><a href="#knowing-your-intentions">Knowing Your Intentions</a></li>
              <li><a href="#knowing-what-to-test">Knowing What to Test</a>                <ul>
                  <li><a href="#remove-the-duplicate">Remove the Duplicate</a></li>
                  <li><a href="#message-model">Message Model</a></li>
                </ul>
              </li>
              <li><a href="#knowing-when-to-test">Knowing When to Test</a></li>
              <li><a href="#knowing-how-to-test">Knowing How to Test</a></li>
            </ul>
          </li>
          <li><a href="#testing-incoming-messages">Testing Incoming Messages</a></li>
          <li><a href="#testing-private-methods">Testing Private Methods</a></li>
          <li><a href="#testing-outgoing-messages">Testing Outgoing Messages</a></li>
          <li><a href="#testing-duck-types">Testing Duck Types</a></li>
          <li><a href="#testing-inherited-code">Testing Inherited Code</a></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h1 id="object-oriented-design">Object-Oriented Design</h1>

<p>Object-oriented design (OOD) requires that you shift from thinking of the world as a collection of predefined procedures to modeling the world as a series of messages that pass between objects.</p>

<p>Object-oriented applications are made up of parts that interact to produce the behavior of the whole. The parts are <em>objects</em>; interactions are embodied in the <em>messages</em> that pass between them.</p>

<p>Object-oriented design is about managing dependencies. In the absence of design, unmanaged dependencies wreak havoc because objects know too much about one another.</p>

<p>Design is thus an art, the art of arranging code, and design is more the art of preserving changeability than it is the act of achieving perfection. You must not only write code for the feature you plan to deliver today, you must also create code that is amenable to being changed later. It doesn‚Äôt guess the future; it preserves your options for accommodating the future. It doesn‚Äôt choose; it leaves you room to move.</p>

<p>The trick to getting the most bang for your design buck is to acquire an understanding of the theories of design and to apply these theories appropriately, at the right time, and in the right amounts. </p>

<p>Well-designed applications are constructed of reusable code. Small, trustworthy self-contained objects with minimal context, clear interfaces, and injected dependencies are inherently reusable.</p>

<h2 id="the-tools-of-design">The Tools of Design</h2>

<h3 id="design-principles">Design Principles</h3>

<ul>
  <li>
    <p><strong>SOLID</strong></p>

    <ul>
      <li>Single Responsibility</li>
      <li>Open-Closed</li>
      <li>Liskov Substitution</li>
      <li>Interface Segregation</li>
      <li>Dependency Inversion</li>
    </ul>
  </li>
  <li><strong>DRY</strong>, Don‚Äôt Repeat Yourself</li>
  <li><strong>LoD</strong>, Law of Demeter</li>
</ul>

<h3 id="design-patterns">Design Patterns</h3>

<p>by Gof</p>

<h2 id="the-act-of-design">The Act of Design</h2>

<h3 id="how-design-fails">How Design Fails</h3>

<ul>
  <li>Lack of it. Successful but undesigned applications carry the seeds of their own destruction; they are easy to write but gradually become impossible to change. ‚ÄúYes, I can add that feature, but it will break everything.‚Äù</li>
  <li>Overdesign. Aware of OO design techniques but do not yet understand how to apply them. ‚ÄúNo, I can‚Äôt add that feature; it wasn‚Äôt designed to do that.‚Äù</li>
  <li>Seperated from the act of programming. Design is a process of progressive discovery that relies on a feedback loop. The iterative techniques of the Agile software movement are thus perfectly suited to the creation of well-designed OO applications. The iterative nature of Agile development allows design to adjust regularly and to evolve naturally. </li>
</ul>

<h3 id="when-to-design">When to Design</h3>

<blockquote>
  <p>Agile believes that your customers can‚Äôt define the software they want before seeing it, so it‚Äôs best to show them sooner rather than later. If this premise is true, then it logically follows that you should build software in tiny increments, gradually iterating your way into an application that meets the customer‚Äôs true need. The Agile experience is that this collaboration produces software that differs from what was initially imagined; the resulting software could not have been anticipated by any other means. </p>
</blockquote>

<p>If Agile is correct, then</p>

<ol>
  <li>there is absolutely no point in doing a Big Up Front Design (BUFD) (because it cannot possibly be correct)</li>
  <li>no one can predict when the application will be done (because you don‚Äôt know in advance what it will eventually do)</li>
</ol>

<p>Agile processes guarantee change and your ability to make these changes depends on your application‚Äôs design. If you cannot write well-designed code you‚Äôll have to rewrite your application during every iteration.</p>

<h1 id="guidance">Guidance</h1>

<p>Focus on object,</p>

<ul>
  <li>Single <strong>Responsibility</strong></li>
  <li>Manage <strong>Dependencies</strong></li>
</ul>

<p>Focus on message,</p>

<ul>
  <li><strong>Interface</strong>, creating flexible interfaces</li>
  <li><strong>Duck Typing</strong>, reducing costs with Duck Typing</li>
  <li><strong>Inheritance</strong>, acquiring behavior through inheritance</li>
  <li><strong>Module</strong>, sharing <strong>role</strong> behavior with modules</li>
  <li><strong>Composition</strong>, combining objects with composition</li>
  <li><strong>Tests</strong>, designing cost-effective tests</li>
</ul>

<h2 id="designing-classes-with-a-single-responsibility">Designing Classes with a Single Responsibility</h2>

<p>SRP requires that a class be <strong>cohesive</strong>, that everything in a class is related to its central purpose, the class is said to be highly cohesive or to have a single responsibility.</p>

<h3 id="depend-on-behavior-not-data">Depend on Behavior, Not Data</h3>

<p>‚ÄúDon‚Äôt Repeat Yourself‚Äù (DRY) is a shortcut for this idea.</p>

<ul>
  <li>Hide instance variables</li>
  <li>Hide data structures</li>
</ul>

<h3 id="enforce-single-responsibility-everywhere">Enforce Single Responsibility Everywhere</h3>

<ul>
  <li>
    <p>Extract extra responsibilities from methods</p>

    <p>Methods, like classes, should have a single responsibility. All of the same reasons apply; having just one responsibility makes them easy to change and easy to reuse.</p>
  </li>
  <li>
    <p>Isolate extra responsibilities in classes</p>

    <p>Postponing decisions until you are absolutely forced to make them. Any decision you make in advance of an explicit requirement is just a guess. Don‚Äôt decide; preserve your ability to make a decision later.</p>
  </li>
</ul>

<h2 id="manage-dependencies">Manage Dependencies</h2>

<p>To collaborate, an object must know something know about others. <em>Knowing</em> creates a dependency, or <em>coupling</em> creates a dependency.</p>

<p>Dependency management is core to creating future-proof applications.</p>

<p>An object has a dependency when it knows</p>

<ul>
  <li>The name of another class.</li>
  <li>The name of a message that it intends to send to someone other than self.</li>
  <li>The arguments that a message requires.</li>
  <li>The order of those arguments.</li>
  <li>Knowing the name of a message you plan to send to someone other than self.</li>
  <li>Tests on code.</li>
</ul>

<h3 id="inject-dependencies">Inject Dependencies</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="c1"># before</span>
</span><span class="line"><span class="k">class</span> <span class="nc">Gear</span>
</span><span class="line">  <span class="o">.</span><span class="n">.</span><span class="o">.</span>
</span><span class="line">
</span><span class="line">  <span class="k">def</span> <span class="nf">gear_inches</span>
</span><span class="line">    <span class="n">ratio</span> <span class="o">*</span> <span class="no">Wheel</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">rim</span><span class="p">,</span> <span class="n">tire</span><span class="p">)</span><span class="o">.</span><span class="n">diameter</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line"><span class="k">end</span>
</span><span class="line">
</span><span class="line"><span class="c1"># after</span>
</span><span class="line"><span class="k">class</span> <span class="nc">Gear</span>
</span><span class="line">  <span class="kp">attr_reader</span> <span class="ss">:chainring</span><span class="p">,</span> <span class="ss">:cog</span><span class="p">,</span> <span class="ss">:wheel</span>
</span><span class="line">  <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="n">chainring</span><span class="p">,</span> <span class="n">cog</span><span class="p">,</span> <span class="n">wheel</span><span class="p">)</span>
</span><span class="line">    <span class="vi">@chainring</span> <span class="o">=</span> <span class="n">chainring</span>
</span><span class="line">    <span class="vi">@cog</span>       <span class="o">=</span> <span class="n">cog</span>
</span><span class="line">    <span class="vi">@wheel</span>     <span class="o">=</span> <span class="n">wheel</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line">
</span><span class="line">  <span class="k">def</span> <span class="nf">gear_inches</span>
</span><span class="line">    <span class="n">ratio</span> <span class="o">*</span> <span class="n">wheel</span><span class="o">.</span><span class="n">diameter</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line"><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Gear previously had explicit dependencies on the Wheel class and on the type and order of its initialization arguments, but through injection these dependencies have been reduced to a single dependency on the diameter method.</p>

<h3 id="isolate-dependencies">Isolate Dependencies</h3>

<p><strong>Isolate Instance Creation</strong></p>

<p>If you are so constrained that you cannot change the code to inject a Wheel into a Gear, you should isolate the creation of a new Wheel inside the Gear class.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="k">class</span> <span class="nc">Gear</span>
</span><span class="line">  <span class="o">.</span><span class="n">.</span><span class="o">.</span>
</span><span class="line">
</span><span class="line">  <span class="k">def</span> <span class="nf">gear_inches</span>
</span><span class="line">    <span class="n">ratio</span> <span class="o">*</span> <span class="n">wheel</span><span class="o">.</span><span class="n">diameter</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line">
</span><span class="line">  <span class="k">def</span> <span class="nf">wheel</span>
</span><span class="line">    <span class="vi">@wheel</span> <span class="o">||=</span> <span class="no">Wheel</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">rim</span><span class="p">,</span> <span class="n">tire</span><span class="p">)</span>
</span><span class="line">  <span class="k">end</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>Isolate Vulnerable External Messages</li>
</ul>

<p>External messages, that is, messages that are ‚Äúsent to someone other than self.‚Äù</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="k">class</span> <span class="nc">Gear</span>
</span><span class="line">  <span class="o">.</span><span class="n">.</span><span class="o">.</span>
</span><span class="line">
</span><span class="line">  <span class="k">def</span> <span class="nf">gear_inches</span>
</span><span class="line">    <span class="n">ratio</span> <span class="o">*</span> <span class="n">diameter</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line">
</span><span class="line">  <span class="k">def</span> <span class="nf">diameter</span>
</span><span class="line">    <span class="n">wheel</span><span class="o">.</span><span class="n">diameter</span>
</span><span class="line">  <span class="k">end</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="remove-argument-order-dependencies">Remove Argument-Order Dependencies</h3>

<ul>
  <li>Use Hashes for Initialization Arguments</li>
  <li>Explicitly Define Defaults</li>
  <li>Isolate Multiparameter Initialization, use a wrapper.</li>
</ul>

<h3 id="managing-dependency-direction">Managing Dependency Direction</h3>

<p>Depend on things that change less often than you do.</p>

<ul>
  <li>Some classes are more likely than others to have changes in requirements.</li>
  <li>Concrete classes are more likely to change than abstract classes.</li>
  <li>Changing a class that has many dependents will result in widespread consequences.</li>
</ul>

<p>Depend on abstractions.</p>

<h2 id="creating-flexible-interfaces">Creating Flexible Interfaces</h2>

<blockquote>
  <p>Interface within a class, make up its public interface.</p>
</blockquote>

<p>Public Interfaces</p>

<ul>
  <li>Reveal its primary responsibility</li>
  <li>Are expected to be invoked by others</li>
  <li>Will not change on a whim</li>
  <li>Are safe for others to depend on</li>
  <li>Are thoroughly documented in the tests</li>
</ul>

<p>Private Interfaces</p>

<ul>
  <li>Handle implementation details</li>
  <li>Are not expected to be sent by other objects</li>
  <li>Can change for any reason whatsoever</li>
  <li>Are unsafe for others to depend on</li>
  <li>May not even be referenced in the tests</li>
</ul>

<p>Well-defined public interfaces consist of stable methods that expose the responsibilities of their underlying classes (public methods should read like a description of responsibilities).</p>

<h3 id="finding-the-public-interface">Finding the Public Interface</h3>

<h4 id="focus-messages-between-domain-objects">Focus Messages between Domain Objects</h4>

<p>Nouns in the application that have both data and behavior are called domain objects. Domain objects are easy to find but they are not at the design center of your application. Design experts notice domain objects without concentrating on them; they focus not on these objects but on the messages that pass between them.</p>

<h4 id="use-sequence-diagrams">Use Sequence Diagrams</h4>

<p>They explicitly specify the messages that pass between objects, and because objects should only communicate using public interfaces, sequence diagrams are a vehicle for exposing, experimenting with, and ultimately defining those interfaces.</p>

<h4 id="asking-for-what-instead-of-telling-how">Asking for ‚ÄúWhat‚Äù Instead of Telling ‚ÄúHow‚Äù</h4>

<h4 id="seeking-context-independence">Seeking Context Independence</h4>

<p>The best possible situation is for an object to be completely independent of its context. An object that could collaborate with others without knowing who they are or what they do could be reused in novel and unanticipated ways.</p>

<p>The technique for collaborating with others without knowing who they are‚Äîdependency injection. </p>

<h3 id="the-law-of-demeter">The Law of Demeter</h3>

<p>It prohibits routing a message to a third object via a second object of a different type. ‚ÄúOnly talk to your immediate neighbors‚Äù or ‚Äúuse only one dot.‚Äù</p>

<p>Delegation is tempting as a solution to the Demeter problem because it removes the visible evidence of violations.</p>

<p>Listening to Demeter means paying attention to your point of view. If you shift to a message-based perspective, the messages you find will become public interfaces in the objects they lead you to discover. However, if you are bound by the shackles of existing domain objects, you‚Äôll end up assembling their existing public interfaces into long message chains and thus will miss the opportunity to find and construct flexible public interfaces.</p>

<h2 id="reduction-costs-with-duck-typing">Reduction Costs with Duck Typing</h2>

<blockquote>
  <p>Interface, across classes and is independent of any single class. The interface represents a set of messages where the messages themselves define the interface. It‚Äôs almost as if the interface defines a virtual class; that is, any class that implements the required methods can act like the interface kind of thing.</p>
</blockquote>

<p><strong>Duck types</strong> are public interfaces that are not tied to any specific class. These across-class interfaces add enormous flexibility to your application by replacing costly dependencies on class with more forgiving dependencies on messages.</p>

<h3 id="polymorphism">Polymorphism</h3>

<p><strong>Polymorphism</strong> in OOP refers to the ability of many different objects to respond to the same message. Senders of the message need not care about the class of the receiver; receivers supply their own specific version of the behavior. Polymorphic methods honor an implicit bargain; they agree to be inter-changeable from the sender‚Äôs point of view.</p>

<p>A single message thus has many (poly) forms (morphs).</p>

<p>There are a number of ways to achieve polymorphism:</p>

<ul>
  <li>Duck Typing</li>
  <li>Inheritance</li>
  <li>Behavior Sharing (module)</li>
</ul>

<h3 id="recognizing-hidden-ducks">Recognizing Hidden Ducks</h3>

<ul>
  <li>Case statements that switch on class</li>
  <li><code>kind_of?</code> and <code>is_a?</code></li>
  <li><code>responds_to?</code></li>
</ul>

<h3 id="guidance-1">Guidance</h3>

<p>When you create duck types you must both document and test their public interfaces. Fortunately, good tests are the best documentation.</p>

<p>The decision to create a new duck type relies on judgment. The purpose of design is to lower costs; bring this measuring stick to every situation. If creating a duck type would reduce unstable dependencies, do so. Use your best judgment.</p>

<h2 id="acquiring-behavior-through-inheritance">Acquiring Behavior Through Inheritance</h2>

<h3 id="inheritance">Inheritance</h3>

<p>Inheritance is, at its core, a mechanism for <strong>automatic message delegation</strong>. It defines a forwarding path for not-understood messages. It creates relationships such that, if one object cannot respond to a received message, it delegates that message to another. You don‚Äôt have to write code to explicitly delegate the message, instead you define an inheritance relationship between two objects and the forwarding happens automatically.</p>

<p>When your problem is one of needing numerous specializations of a stable, common abstraction, inheritance can be an extremely low-cost solution.</p>

<h3 id="recognizing-where-to-use-inheritance">Recognizing Where to Use Inheritance</h3>

<p>The inheritance exactly solves: that of highly related types that share common behavior but differ along some dimension.  </p>

<p>Inheritance provides a way to define two objects as having a relationship such that when the first receives a message that it does not understand, it automatically forwards, or delegates, the message to the second. It‚Äôs as simple as that.  </p>

<p>Duck types cut across classes, they do not use classical inheritance to share common behavior. Duck types share code via Ruby modules.</p>

<h4 id="finding-the-abstraction">Finding the Abstraction</h4>

<p>It almost never makes sense to create an abstract superclass with only one sub-class.  </p>

<p>Creating a hierarchy has costs; the best way to minimize these costs is to maximize your chance of getting the abstraction right before allowing subclasses to depend on it. While the two bikes you know about supply a fair amount of information about the common abstraction, three bikes would supply a great deal more. If you could put this decision off until FastFeet asked for a third kind of bike, your odds of finding the right abstraction would improve dramatically.</p>

<p>When deciding between refactoring strategies, indeed, when deciding between design strategies in general, it‚Äôs useful to ask the question: ‚ÄúWhat will happen if I‚Äôm wrong?‚Äù</p>

<h3 id="using-templage-methods">Using Templage Methods</h3>

<h4 id="template-method">Template Method</h4>

<p>This technique of defining a basic structure in the superclass and sending messages to acquire subclass-specific contributions is known as the template method pattern.</p>

<h4 id="implementing-every-template-method">Implementing Every Template Method</h4>

<p>Any class that uses the template method pattern must supply an implementation for every message it sends, and creating code that fails with reasonable error messages takes minor effort in the present but provides value forever.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="k">class</span> <span class="nc">Bicycle</span>
</span><span class="line">  <span class="c1">#...</span>
</span><span class="line">  <span class="k">def</span> <span class="nf">default_tire_size</span>
</span><span class="line">    <span class="k">raise</span> <span class="no">NotImplementedError</span><span class="p">,</span> <span class="s2">&quot;This </span><span class="si">#{</span><span class="nb">self</span><span class="o">.</span><span class="n">class</span><span class="si">}</span><span class="s2"> cannot respond to:&quot;</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line"><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="manging-coupling">Manging Coupling</h3>

<p>When a subclass sends <code>super</code> it‚Äôs effectively declaring that it knows the algorithm; it depends on this knowledge. If the algorithm changes, then the subclasses may break even if their own specializations are not otherwise affected.</p>

<h4 id="decoupling-subclasses-using-hook-messages">Decoupling Subclasses Using Hook Messages</h4>

<p>Instead of allowing subclasses to know the algorithm and requiring that they send <code>super</code>, superclasses can instead send <code>hook</code> messages, ones that exist solely to provide subclasses a place to contribute information by implementing matching methods. This strategy removes knowledge of the algorithm from the subclass and returns control to the superclass.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="k">class</span> <span class="nc">Bicycle</span>
</span><span class="line">  <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="n">args</span><span class="o">=</span><span class="p">{})</span>
</span><span class="line">    <span class="vi">@size</span> <span class="o">=</span> <span class="n">args</span><span class="o">[</span><span class="ss">:size</span><span class="o">]</span>
</span><span class="line">    <span class="vi">@chain</span> <span class="o">=</span> <span class="n">args</span><span class="o">[</span><span class="ss">:chain</span><span class="o">]</span> <span class="o">||</span> <span class="n">default_chain</span>
</span><span class="line">    <span class="vi">@tire_size</span> <span class="o">=</span> <span class="n">args</span><span class="o">[</span><span class="ss">:tire_size</span><span class="o">]</span> <span class="o">||</span> <span class="n">default_tire_size</span>
</span><span class="line">
</span><span class="line">    <span class="n">post_initialize</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>   <span class="c1"># Bicycle both sends</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line">
</span><span class="line">  <span class="k">def</span> <span class="nf">post_initialize</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="c1"># and implements this </span>
</span><span class="line">    <span class="kp">nil</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line">  <span class="c1"># ...</span>
</span><span class="line"><span class="k">end</span>
</span><span class="line">
</span><span class="line"><span class="k">class</span> <span class="nc">RoadBike</span> <span class="o">&lt;</span> <span class="no">Bicycle</span>
</span><span class="line">
</span><span class="line">  <span class="k">def</span> <span class="nf">post_initialize</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>         <span class="c1"># RoadBike can </span>
</span><span class="line">    <span class="vi">@tape_color</span> <span class="o">=</span> <span class="n">args</span><span class="o">[</span><span class="ss">:tape_color</span><span class="o">]</span> <span class="c1"># optionally</span>
</span><span class="line">  <span class="k">end</span>                               <span class="c1"># override it</span>
</span><span class="line">  <span class="c1"># ...</span>
</span><span class="line"><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>This change allows RoadBike to know less about Bicycle, reducing the coupling between them and making each more flexible in the face of an uncertain future. New subclasses need only implement the <code>hook</code> methods.</p>

<h2 id="sharing-role-behavior-with-modules">Sharing Role Behavior with Modules</h2>

<h3 id="understanding-roles">Understanding Roles</h3>

<p>Modules thus provide a perfect way to allow objects of different classes to play a common role using a single set of code.</p>

<p>The rules for modules are the same as for classical inheritance. If a module sends a message it must provide an implementation, even if that implementation merely raises an error indicating that users of the module must implement the method.</p>

<p>This is-a versus behaves-like-a difference definitely matters, each choice has distinct consequences.</p>

<h3 id="writing-inheritable-code">Writing Inheritable Code</h3>

<p>The usefulness and maintainability of inheritance hierarchies and modules is in direct proportion to the quality of the code. </p>

<h4 id="recognize-the-antipatterns">Recognize the Antipatterns</h4>

<p>There are two antipatterns that indicate that your code might benefit from inheritance.</p>

<ul>
  <li>An object that uses a variable with a name like <code>type</code> or <code>category</code> to determine what message to send to <code>self</code> contains two highly related but slightly different types.</li>
  <li>When a sending object checks the class of a receiving object to determine what message to send, you have overlooked a duck type. In addition to sharing an interface, duck types might also share behavior. When they do, place the shared code in a module and include that module in each class or object that plays the role.</li>
</ul>

<h4 id="insist-on-the-abstraction">Insist on the Abstraction</h4>

<p>Superclasses should not contain code that applies to some, but not all, subclasses. This restriction also applies to modules: the code in a module must apply to all who use it.</p>

<p>Subclasses that override a method to raise an exception like ‚Äúdoes not implement‚Äù are a symptom of this problem. When subclasses override a method to declare that they <em>do not do that thing</em> they come perilously close to declaring that they <em>are not that thing</em>.</p>

<h4 id="honor-the-contract">Honor the Contract</h4>

<p>Subclasses agree to a contract; they promise to be substitutable for their superclasses.</p>

<p>Subclasses that fail to honor their contract are difficult to use. They‚Äôre ‚Äúspecial‚Äù and cannot be freely substituted for their superclasses. These subclasses are declaring that they are not really a kind-of their superclass </p>

<p><strong>Liskov Substitution Principle (LSP)</strong>, which in mathematical terms says that a subtype should be substitutable for its supertype. Named after Barbara Liskov.</p>

<h4 id="use-the-template-method-pattern">Use the Template Method Pattern</h4>

<p>The abstract code defines the algorithms and the concrete inheritors of that abstraction contribute specializations by overriding these template methods.</p>

<p>Modules, therefore, should use the template method pattern to invite those that include them to supply specializations, and should implement hook methods to avoid forcing includers to send <code>super</code>.</p>

<h4 id="preemptively-decouple-classes">Preemptively Decouple Classes</h4>

<p>Avoid writing code that requires its inheritors to send <code>super</code>; instead use hook messages to allow subclasses to participate while absolving them of responsibility for knowing the abstract algorithm. Writing code that requires subclasses to send <code>super</code> adds an additional dependency; avoid this if you can.</p>

<p>Hook methods solve the problem of sending <code>super</code>, but, unfortunately, only for adjacent levels of the hierarchy.</p>

<h4 id="create-shallow-hierarchies">Create Shallow Hierarchies</h4>

<p>The limitations of hook methods are just one of the many reasons to create shallow hierarchies.</p>

<p>Because objects depend on everything above them, a deep hierarchy has a large set of built-in dependencies, each of which might someday change.</p>

<p>Another problem with deep hierarchies is that programmers tend to be familiar with just the classes at their tops and bottoms; that is, they tend to understand only the behavior implemented at the boundaries of the search path.</p>

<h2 id="combining-objects-with-composition">Combining Objects with Composition</h2>

<p>Composition is the act of combining distinct parts into a complex whole such that the whole becomes more than the sum of its parts.</p>

<h3 id="aggregation-a-special-kind-of-composition">Aggregation: A Special Kind of Composition</h3>

<p>Delegation creates dependencies; the receiving object must recognize the message and know where to send it. Composition often involves delegation but the term means something more. A composed object is made up of parts with which it expects to interact via well-defined interfaces.</p>

<p>Composition indicates a <em>has-a</em> relationship where the contained object has no life independent of its container.</p>

<p>Aggregation is exactly like composition except that the contained object has an independent life.</p>

<h3 id="deciding-between-inheritance-and-composition">Deciding Between Inheritance and Composition</h3>

<ul>
  <li>Remember that classical inheritance is a code arrangement technique. For the cost of arranging objects in a hierarchy, you get message delegation for free. </li>
  <li>Composition is an alternative that reverses these costs and benefits. Composition allows objects to have structural independence, but at the cost of explicit message delegation.</li>
</ul>

<p>The general rule is that, faced with a problem that composition can solve, you should be biased towards doing so. If you cannot explicitly defend inheritance as a better solution, use composition.</p>

<h4 id="inheritance-1">Inheritance</h4>

<p><strong>Benefits</strong></p>

<p>Inheritance is a better solution when its use provides high rewards for low risk.</p>

<p>Use of inheritance results in code that can be described as open‚Äìclosed; hierarchies are open for extension while remaining closed for modification. </p>

<p>You need look no farther than the source of object-oriented languages themselves to see the value of organizing code using inheritance.</p>

<p><strong>Costs</strong></p>

<p>You might be fooled into choosing inheritance to solve the wrong kind of problem. If you make this mistake a day will come when you need to add behavior but find there‚Äôs no easy way do so.</p>

<p>Even when inheritance makes sense for the problem, you might be writing code that will be used by others for purposes you did not anticipate.</p>

<p>The very high cost of making changes near the top of an incorrectly modeled hierarchy. In this case, the leveraging effect works to your disadvantage; small changes break everything.</p>

<p>The impossibility of adding behavior when new subclasses represent a mixture of types.</p>

<p>Inheritance, therefore, is a place where the question ‚Äú<em>What will happen when I‚Äôm wrong?</em>‚Äù assumes special importance. Inheritance by definition comes with a deeply embedded set of dependencies. Subclasses depend on the methods defined in their superclasses and on the automatic delegation of messages to those superclasses. This is classical inheritance‚Äôs greatest strength and biggest weakness.</p>

<p><strong>Guidance</strong></p>

<p>Your consideration of the use of inheritance should be tempered by your <em>expectations about the population who will use your code</em>. If you are writing code for an in-house application in a domain with which you are intimately familiar, you may be able to predict the future well enough to be confident that your design problem is one for which inheritance is a cost-effective solution.</p>

<p>Avoid writing frameworks that require users of your code to subclass your objects in order to gain your behavior. Their application‚Äôs objects may already be arranged in a hierarchy; inheriting from your framework may not be possible.</p>

<h4 id="composition">Composition</h4>

<p>Composed objects do not depend on the structure of the class hierarchy, and they delegate their own messages.</p>

<p><strong>Benefits</strong></p>

<p>When using composition, the natural tendency is to create many small objects that contain straightforward responsibilities that are accessible through clearly defined interfaces. These small objects have a single responsibility and specify their own behavior. They are transparent.</p>

<p>By their very nature, objects that participate in composition are small, structurally independent, and have well-defined interfaces. This allows their seamless transition into pluggable, interchangeable components.</p>

<p><strong>Costs</strong></p>

<p>The composed object must explicitly know which messages to delegate and to whom. Identical delegation code may be needed by many different objects. Composition provides no way to share this code.</p>

<p>Composition is excellent at prescribing rules for assembling an object made of parts but doesn‚Äôt provide as much help for the problem of arranging code for a collection of parts that are very nearly identical.</p>

<h3 id="guidance-2">Guidance</h3>

<p>Composition, classical inheritance, and behavior sharing via modules are competing techniques for arranging code.</p>

<ul>
  <li>Use inheritance for <em>is-a</em> Relationships.</li>
  <li>Use Duck Types for <em>behaves-like-a</em> Relationships</li>
  <li>Use Composition for <em>has-a</em> Relationships</li>
</ul>

<h2 id="designing-cost-effective-tests">Designing Cost-Effective Tests</h2>

<p>An understanding of object-oriented design, good refactoring skills, and the ability to write efficient tests form a <strong>three-legged stool</strong> upon which changeable code rests.</p>

<p>Your overall goal is to create well-designed applications that have acceptable test coverage. </p>

<h3 id="intentional-testing">Intentional Testing</h3>

<h4 id="knowing-your-intentions">Knowing Your Intentions</h4>

<p>The true purpose of testing, just like the true purpose of design, is to reduce costs.</p>

<p>It is common for programmers who are new to testing to find themselves in the unhappy state where the tests they write do cost more than the value those tests provide, and who therefore want to argue about the worth of tests. The solution to the problem of costly tests, however, is not to stop testing but instead to get better at it.</p>

<ol>
  <li>Finding Bugs</li>
  <li>Supplying Documentation</li>
  <li>Deferring Design Decisions</li>
  <li>Supporting Abstractions</li>
  <li>Exposing Design Flaws. When the design is bad, testing is hard. The best way to achieve this goal is to write loosely coupled tests about only the things that matter.</li>
</ol>

<h4 id="knowing-what-to-test">Knowing What to Test</h4>

<h5 id="remove-the-duplicate">Remove the Duplicate</h5>

<p>One simple way to get better value from tests is to write fewer of them. The safest way to accomplish this is to test everything just once and in the proper place.</p>

<p>Removing duplication from testing lowers the cost of changing tests in reaction to application changes, and putting tests in the right place guarantees they‚Äôll be forced to change only when absolutely necessary.</p>

<h5 id="message-model">Message Model</h5>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/origins_of_messages.png" alt="origins_of_messages" /></p>

<p>Think of an object-oriented application as a series of messages passing between a set of black boxes. Tests should concentrate on the incoming or outgoing messages that cross an object‚Äôs boundaries.</p>

<ul>
  <li>
    <p>Incoming Message</p>

    <p>Objects should make assertions about <em>state</em> only for messages in their own public interfaces.</p>
  </li>
  <li>
    <p>Outgoing Message</p>

    <ul>
      <li><em>query</em>, outgoing messages have no side effects and thus matter only to their senders.</li>
      <li><em>command</em>, outgoing messages do have side effects (a file gets written, a database record is saved, an action is taken by an observer). It is the responsibility of the sending object to prove that they are properly sent. Proving that a message gets sent is a test of behavior, not state.</li>
    </ul>
  </li>
</ul>

<p><strong>Conclusion</strong></p>

<p>Incoming messages should be tested for the state they return. Outgoing command messages should be tested to ensure they get sent. Outgoing query messages should not be tested.</p>

<h4 id="knowing-when-to-test">Knowing When to Test</h4>

<p>You should write tests first, whenever it makes sense to do so.</p>

<p>Done at the correct time and in the right amounts, testing, and writing code test-first, will lower your overall costs. Gaining these benefits requires applying object-oriented design principles everywhere, both to the code of your application and to the code in your tests.</p>

<p><em>What novices do?</em></p>

<p>Novices often write code that is far too coupled; they combine unrelated responsibilities and bind many dependencies into every object. </p>

<p>It is an unfortunate truth that the most complex code is usually written by the least qualified person.</p>

<p>Novice programmers don‚Äôt yet have the skills to write simple code.</p>

<h4 id="knowing-how-to-test">Knowing How to Test</h4>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/bdd_and_tdd.png" alt="bdd_and_tdd" /></p>

<ul>
  <li><strong>BDD</strong> takes an outside-in approach, creating objects at the boundary of an application and working its way inward, mock-ing as necessary to supply as-yet-unwritten objects.</li>
  <li><strong>TDD</strong> takes an inside-out approach, usually starting with tests of domain objects and then reusing these newly created domain objects in the tests of adjacent layers of code.</li>
</ul>

<p><strong>Testing point-of-view</strong></p>

<p>Your tests could stand completely inside of the object under test, with effective access to all of its internals. This is a bad idea.</p>

<p>It‚Äôs better for tests to assume a viewpoint that sights along the edges of the object under test, where they can know only about messages that come and go.</p>

<h3 id="testing-incoming-messages">Testing Incoming Messages</h3>

<ul>
  <li>
    <p>Deleting Unused Interfaces</p>

    <p>Do not test an incoming message that has no dependents; delete it. </p>
  </li>
  <li>
    <p>Proving the Public Interface</p>
  </li>
  <li>
    <p>Isolating the Object Under Test</p>
  </li>
  <li>
    <p>Injecting Dependencies as Roles</p>

    <p>Object-oriented design tells you to inject dependencies because it believes that specific concrete classes will vary more than these roles, or conversely, roles will be more stable than the classes from which they were abstracted.</p>

    <ul>
      <li>Creating Test Doubles</li>
      <li>Using Tests to Document Roles</li>
    </ul>
  </li>
</ul>

<h3 id="testing-private-methods">Testing Private Methods</h3>

<p>Dealing with private methods requires judgment and flexibility.</p>

<p>The rules-of-thumb for testing private methods are thus: Never write them, and if you do, never ever test them, unless of course it makes sense to do so.</p>

<h3 id="testing-outgoing-messages">Testing Outgoing Messages</h3>

<ul>
  <li>Ignoring Query Messages</li>
  <li>
    <p>Proving Command Messages</p>

    <p>The responsibility for testing a message‚Äôs return value lies with its receiver. <strong>Mocks</strong> are tests of behavior, as opposed to tests of state. Instead of making assertions about what a message returns, mocks define an expectation that a message will get sent. </p>
  </li>
</ul>

<h3 id="testing-duck-types">Testing Duck Types</h3>

<p>The desire to test duck types creates a need for shareable tests for roles, and once you acquire this role-based perspective you can use it to your advantage in many situations. From the point of view of the object under test, every other object is a role and dealing with objects as if they are representatives of the roles they play loosens coupling and increases flexibility, both in your application and in your tests.</p>

<ul>
  <li>Testing Roles. Extract a module, test it and include in every role.</li>
  <li>Using Role Tests to Validate Doubles.</li>
</ul>

<h3 id="testing-inherited-code">Testing Inherited Code</h3>

<ul>
  <li>
    <p>Specifying the Inherited Interface</p>

    <p>Write a shared test for the common contract and include this test in every object.</p>
  </li>
  <li>
    <p>Specifying Subclass Responsibilities</p>

    <ul>
      <li>Confirming Subclass Behavior. The <em>BicycleInterfaceTest</em> and the <em>BicycleSubclassTest</em>, combined, take all of the pain out of testing the common behavior of subclasses. These tests give you confidence that subclasses aren‚Äôt drifting away from the standard.</li>
      <li>Confirming Superclass Enforcement. Test the template method.</li>
    </ul>
  </li>
  <li>
    <p>Testing Unique Behavior</p>

    <ul>
      <li>Testing Concrete Subclass Behavior. It‚Äôs important to test these specializations without embedding knowledge of the superclass into the test.</li>
      <li>Testing Abstract Superclass Behavior. Because Bicycle used template methods to acquire concrete specializations you can stub the behavior that would normally be supplied by subclasses. Even better, because you understand the Liskov Substitution Principle, you can easily manufacture a testable instance of Bicycle by creating a new subclass for use solely by this test.</li>
    </ul>
  </li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Git Reminders]]></title>
    <link href="http://blog.ifyouseewendy.com/blog/2014/12/30/git-reminders/"/>
    <updated>2014-12-30T15:11:29+08:00</updated>
    <id>http://blog.ifyouseewendy.com/blog/2014/12/30/git-reminders</id>
    <content type="html"><![CDATA[<p>After using Git for two years, I‚Äôve finally finished reading these two books, twice. Not only skimming, but also making excerpts and perform experiments in the meantime. These two fabulous books really benefit me a lot, and this is the final notes which construct my Git knowledge base, and comprise the excerpts from both books and experiments on some specific topics.</p>

<table class="custom">
  <tbody>
    <tr>
      <td><strong>Book</strong></td>
      <td>Git Community Book</td>
    </tr>
    <tr>
      <td><strong>Author</strong></td>
      <td>people in the Git community</td>
    </tr>
    <tr>
      <td><strong>Link</strong></td>
      <td><a href="http://alx.github.io/gitbook/">alx.github.io/gitbook</a></td>
    </tr>
  </tbody>
</table>

<table class="custom">
  <tbody>
    <tr>
      <td><strong>Book</strong></td>
      <td>Pro Git</td>
    </tr>
    <tr>
      <td><strong>Author</strong></td>
      <td>Scott Chacon and Ben Straub</td>
    </tr>
    <tr>
      <td><strong>Link</strong></td>
      <td><a href="http://git-scm.com/book/en">git-scm.com/book</a></td>
    </tr>
  </tbody>
</table>

<ul id="markdown-toc">
  <li><a href="#basics">Basics</a>    <ul>
      <li><a href="#meta">Meta</a></li>
      <li><a href="#git-object-model">Git Object Model</a>        <ul>
          <li><a href="#the-sha-1">The SHA-1</a></li>
          <li><a href="#the-objects">The Objects</a></li>
        </ul>
      </li>
      <li><a href="#staged">Staged</a></li>
      <li><a href="#branching">Branching</a></li>
      <li><a href="#tags">Tags</a></li>
    </ul>
  </li>
  <li><a href="#configuration">Configuration</a>    <ul>
      <li><a href="#ignoring-files">Ignoring Files</a></li>
      <li><a href="#commit-template">Commit Template</a></li>
      <li><a href="#git-attributes">Git Attributes</a></li>
    </ul>
  </li>
  <li><a href="#porcelain">Porcelain</a>    <ul>
      <li><a href="#branch">Branch</a>        <ul>
          <li><a href="#inspecting-a-remote">Inspecting a Remote</a></li>
          <li><a href="#checkout-and-track-a-remote-branch">Checkout and Track a Remote Branch</a></li>
        </ul>
      </li>
      <li><a href="#tag">Tag</a>        <ul>
          <li><a href="#share-tags">Share tags</a></li>
          <li><a href="#sign-tags">Sign tags</a></li>
          <li><a href="#distributing-the-public-pgp-key">Distributing the Public PGP Key</a></li>
          <li><a href="#generate-a-build-number">Generate a Build Number</a></li>
          <li><a href="#prepare-a-release">Prepare a Release</a></li>
        </ul>
      </li>
      <li><a href="#rebasing">Rebasing</a></li>
      <li><a href="#merge-base">Merge Base</a></li>
      <li><a href="#merge-stage">Merge Stage</a></li>
      <li><a href="#ancestry-references">Ancestry References</a></li>
      <li><a href="#commit-ranges">Commit Ranges</a></li>
      <li><a href="#log">Log</a>        <ul>
          <li><a href="#summarize-or-get-a-quick-changelog">Summarize or Get a Quick Changelog</a></li>
        </ul>
      </li>
      <li><a href="#stash">Stash</a>        <ul>
          <li><a href="#reapply-the-staged-changes">Reapply the Staged Changes</a></li>
          <li><a href="#create-a-branch-from-stash">Create a Branch from Stash</a></li>
        </ul>
      </li>
      <li><a href="#create-new-empty-branches">Create New Empty Branches</a></li>
      <li><a href="#filter-branch">Filter Branch</a>        <ul>
          <li><a href="#removing-a-file-from-every-commit">Removing a File from Every Commit</a></li>
          <li><a href="#making-a-subdirectory-the-new-root">Making a Subdirectory the New Root</a></li>
          <li><a href="#changing-e-mail-addresses-globally">Changing E-Mail Addresses Globally</a></li>
          <li><a href="#realworld-example">Realworld Example</a></li>
        </ul>
      </li>
      <li><a href="#blame">Blame</a></li>
      <li><a href="#bisect">Bisect</a>        <ul>
          <li><a href="#auto-check-by-script">Auto Check By Script</a></li>
        </ul>
      </li>
      <li><a href="#submodules">Submodules</a>        <ul>
          <li><a href="#maintain-a-repo-which-contains-a-submodule">Maintain a repo which contains a submodule</a></li>
          <li><a href="#maintain-a-cloned-repo-which-contains-a-submodule">Maintain a cloned repo which contains a submodule</a></li>
          <li><a href="#a-demo-workflow">A Demo Workflow</a></li>
          <li><a href="#cautions">Cautions</a></li>
        </ul>
      </li>
      <li><a href="#subtree-merging-a-submodule-substitution">Subtree Merging (A Submodule Substitution)</a>        <ul>
          <li><a href="#use-git-merge-subtree-strategy">Use git-merge Subtree Strategy</a></li>
          <li><a href="#use-git-subtree">Use git-subtree</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#git-internals">Git Internals</a>    <ul>
      <li><a href="#plumbing-objects">Plumbing Objects</a>        <ul>
          <li><a href="#blob-object">Blob Object</a></li>
          <li><a href="#tree-objects">Tree Objects</a></li>
          <li><a href="#commit-objects">Commit Objects</a></li>
          <li><a href="#object-storage">Object Storage</a></li>
        </ul>
      </li>
      <li><a href="#index">Index</a></li>
      <li><a href="#packfile">Packfile</a></li>
      <li><a href="#the-refspec">The Refspec</a>        <ul>
          <li><a href="#fetching">fetching</a></li>
        </ul>
      </li>
      <li><a href="#data-recovery">Data Recovery</a>        <ul>
          <li><a href="#reflog">reflog</a></li>
          <li><a href="#fsck">fsck</a></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="basics">Basics</h2>

<h3 id="meta">Meta</h3>

<p><strong>Snapshots, Not Differences</strong></p>

<p>Every time you commit, or save the state of your project in Git, it basically takes a picture of what all your files look like at that moment and stores a reference to that snapshot.</p>

<p><strong>Git Generally Only Adds Data</strong></p>

<p>It is very difficult to get the system to do anything that is not undoable or to make it erase data in any way.</p>

<h3 id="git-object-model">Git Object Model</h3>

<h4 id="the-sha-1">The SHA-1</h4>

<blockquote>
  <p>checksum, object ID</p>
</blockquote>

<ol>
  <li>Represents object name.</li>
  <li>40-digit long.</li>
  <li>Use SHA1 hash to generate based on the object content.</li>
  <li>Keeps the identity.</li>
</ol>

<h4 id="the-objects">The Objects</h4>

<p>Every object consists of three things: <strong>type, size, content</strong>.</p>

<p>There are four different types of objects: <strong>blob, tree, commit, tag</strong>.</p>

<p><strong>blob</strong> is a chunk of binary data, used to store file data.</p>

<blockquote>
  <p>The blob is entirely defined by its data, totally independent of its location.</p>
</blockquote>

<p><strong>tree</strong> is basically like a directory - it references a bunch of other trees and/or blobs.</p>

<blockquote>
  <p>Since trees and blobs, like all other objects, are named by the SHA1 hash of their contents, two trees have the same SHA1 name if and only if their contents (including, recursively, the contents of all subdirectories) are identical.</p>
</blockquote>

<p><strong>commit</strong>  points to a single tree, marking it as what the project looked like at a certain point in time. It contains meta-information about that point in time, such as a timestamp, the author of the changes since the last commit, a pointer to the previous commit(s), etc.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git show --pretty<span class="o">=</span>raw HEAD
</span><span class="line">commit 6cc1a668111eb54ef4dbe976fff24f2e3d8b95f9
</span><span class="line">tree 36df675d7ae80e7eef0faac893b266801a4fa94a
</span><span class="line">parent d448c30aa03fba2884ab87c21081ef0f74d24f7e
</span><span class="line">author wendi &lt;wendi@umeng.com&gt; 1409022714 +0800
</span><span class="line">committer wendi &lt;wendi@umeng.com&gt; 1409022733 +0800
</span><span class="line">
</span><span class="line">    Update error <span class="nb">type </span>service url
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><strong>tag</strong> is a way to mark a specific commit as special in some way. It is normally used to tag certain commits as specific releases or something along those lines.</p>

<blockquote>
  <p>A tag object contains an object name (called simply ‚Äòobject‚Äô), object type, tag name, the name of the person (‚Äútagger‚Äù) who created the tag, and a message, which may contain a signature</p>
</blockquote>

<h3 id="staged">Staged</h3>

<p>Staged means that you have marked a modified file in its current version to go into your next commit snapshot.</p>

<p>The staging area is a simple file, generally contained in your Git directory, that stores information about what will go into your next commit.</p>

<h3 id="branching">Branching</h3>

<p>A branch in Git is simply a lightweight movable pointer to one of these commits.</p>

<p>How does Git know what branch you‚Äôre currently on? It keeps a special pointer called <em>HEAD</em>.</p>

<p><strong>Remote Branches</strong></p>

<p>Remote branches act as bookmarks to remind you where the branches on your remote repositories were the last time you connected to them.</p>

<h3 id="tags">Tags</h3>

<p>The tag object is very much like a commit object, but <strong>a tag object points to a commit rather than a tree. It‚Äôs like a branch reference, but it never moves</strong> ‚Äî it always points to the same commit but gives it a friendlier name. </p>

<p>You can tag any Git object. For example, the maintainer adds the GPG public key as a blob object and then tagged it.</p>

<p><strong>Lightweight</strong></p>

<p>A lightweight tag is very much like a branch that doesn‚Äôt change ‚Äî it‚Äôs just a pointer to a specific commit.</p>

<p><strong>Annotated</strong></p>

<p>Annotated tags, however, are stored as full objects in the Git database. They‚Äôre checksummed; contain the tagger name, e-mail, and date; have a tagging message; and can be signed and verified with GNU Privacy Guard (GPG). </p>

<h2 id="configuration">Configuration</h2>

<h3 id="ignoring-files">Ignoring Files</h3>

<p>Glob patterns are like simplified regular expressions that shells use.</p>

<p>You can negate a pattern by starting it with an exclamation point (!).</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">*.a       <span class="c"># no .a files</span>
</span><span class="line">!lib.a    <span class="c"># but do track lib.a, even though you‚Äôre ignoring .a files above</span>
</span><span class="line">/TODO     <span class="c"># only ignore the root TODO file, not subdir/TODO</span>
</span><span class="line">build/    <span class="c"># ignore all files in the build/ directory</span>
</span><span class="line">doc/*.txt <span class="c"># ignore doc/notes.txt, but not doc/server/arch.txt</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="commit-template">Commit Template</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git config --global commit.template <span class="nv">$HOME</span>/.gitmessage
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>I‚Äôve defined some experimental rules based on <a href="http://programmers.stackexchange.com/questions/42110/can-you-recommend-a-good-commit-message-template-guidelines-to-enforce-in-the">rangzen‚Äôs recommandation</a> on Stack Exchange. Here is my <a href="https://github.com/ifyouseewendy/dotfiles/blob/master/gitmessage">.gitmessage</a>.</p>

<p>Here is another post for specific usage, <a href="http://blog.ifyouseewendy.com/blog/2014/12/29/readable-git-log-by-using-custom-commit-template/">Readable Git Log by Using Custom Commit Template</a></p>

<h3 id="git-attributes">Git Attributes</h3>

<p>The path-specific settings are called Git attributes and are set either in a <code>.gitattribute</code> file in one of your directories (normally the root of your project) or in the <code>.git/info/attributes</code> file if you don‚Äôt want the attributes file committed with your project.</p>

<ul>
  <li>Identifying Binary Files</li>
  <li>Diffing Binary Files (word, image EXIF)</li>
  <li>Filters (clean and smudge)</li>
  <li>Exorting
    <ul>
      <li>export-ignore</li>
      <li>export-subst</li>
    </ul>
  </li>
  <li>Merge Strategies</li>
</ul>

<h2 id="porcelain">Porcelain</h2>

<h3 id="branch">Branch</h3>

<h4 id="inspecting-a-remote">Inspecting a Remote</h4>

<p><code>git remote show [remote-name]</code></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git remote show origin
</span><span class="line">* remote origin
</span><span class="line">  URL: git://github.com/schacon/ticgit.git
</span><span class="line">  Remote branch merged with ‚Äôgit pull‚Äô <span class="k">while </span>on branch master
</span><span class="line">    master
</span><span class="line">  Tracked remote branches
</span><span class="line">    master
</span><span class="line">    ticgit
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h4 id="checkout-and-track-a-remote-branch">Checkout and Track a Remote Branch</h4>

<p>Two ways.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git checkout -b sf origin/serverfix
</span><span class="line">Branch sf <span class="nb">set </span>up to track remote branch refs/remotes/origin/serverfix.
</span><span class="line">Switched to a new branch <span class="s2">&quot;sf&quot;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git checkout --track origin/serverfix
</span><span class="line">Branch serverfix <span class="nb">set </span>up to track remote branch refs/remotes/origin/serverfix.
</span><span class="line">Switched to a new branch <span class="s2">&quot;serverfix&quot;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="tag">Tag</h3>

<h4 id="share-tags">Share tags</h4>

<p>By default, the git push command doesn‚Äôt transfer tags to remote servers. You will have to explicitly push tags to a shared server after you have created them.</p>

<p><code>git push origin [tagname]</code></p>

<p>If you have a lot of tags that you want to push up at once, you can also use the ‚Äìtags option to the git push command.</p>

<p><code>git push origin --tags</code></p>

<h4 id="sign-tags">Sign tags</h4>

<ul>
  <li>PGP, Pretty Good Privacy, the standard.</li>
  <li>GPG, Gnu Privacy Guard, the implementation.</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="c"># Generate your key</span>
</span><span class="line"><span class="nv">$ </span>gpg --gen-key
</span><span class="line">
</span><span class="line"><span class="nv">$ </span>gpg --list-key
</span><span class="line">/Users/wendi/.gnupg/pubring.gpg
</span><span class="line">-------------------------------
</span><span class="line">pub   2048R/FXXXXXXX 2014-12-19
</span><span class="line">uid                  Di Wen <span class="o">(</span>wendi<span class="o">)</span> &lt;ifyouseewendy@gmail.com&gt;
</span><span class="line">sub   2048R/XXXXXXX 2014-12-19
</span><span class="line">
</span><span class="line"><span class="c"># Set Git config</span>
</span><span class="line"><span class="nv">$ </span>git config --global user.signingkey FXXXXXXX
</span><span class="line">
</span><span class="line"><span class="c"># Sign</span>
</span><span class="line">git tag -s v0.1 -m <span class="s1">&#39;First GPG signed tag&#39;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h4 id="distributing-the-public-pgp-key">Distributing the Public PGP Key</h4>

<p>Import the key into the Git database by exporting it and piping that through <code>git hash-object</code>, which writes a new blob with those contents into Git and gives you back the SHA‚Äì1 of the blob.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>gpg -a --export F721C45A | git <span class="nb">hash</span>-object -w --stdin
</span><span class="line">659ef797d181633c87ec71ac3f9ba29fe5775b92
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Now that you have the contents of your key in Git, you can create a tag that points directly to it by specifying the new SHA‚Äì1 value that the hash-object command gave you:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git tag -a maintainer-pgp-pub 659ef797d181633c87ec71ac3f9ba29fe5775b92
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>If you run <code>git push --tags</code>, the maintainer-pgp-pub tag will be shared with everyone. If anyone wants to verify a tag, they can directly import your PGP key by pulling the blob directly out of the database and importing it into GPG:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git show maintainer-pgp-pub | gpg --import
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>They can use that key to verify all your signed tags. Also, if you include instructions in the tag message, running <code>git show &lt;tag&gt;</code> will let you give the end user more specific instructions about tag verification.</p>

<h4 id="generate-a-build-number">Generate a Build Number</h4>

<p>Git gives you the name of the nearest tag with the number of commits on top of that tag and a partial SHA‚Äì1 value of the commit you‚Äôre describing:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git describe master
</span><span class="line">v1.6.2-rc1-20-g8c5b85c
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The git describe command favors annotated tags.</p>

<h4 id="prepare-a-release">Prepare a Release</h4>

<p>Create <code>tar.gz</code>.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git archive master --prefix<span class="o">=</span>‚Äôproject/‚Äô | gzip &gt; ‚Äògit describe master‚Äò.tar.gz
</span><span class="line"><span class="nv">$ </span>ls *.tar.gz
</span><span class="line">v1.6.2-rc1-20-g8c5b85c.tar.gz
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Create <code>zip</code></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git archive master --prefix<span class="o">=</span>‚Äôproject/‚Äô --format<span class="o">=</span>zip &gt; ‚Äògit describe master‚Äò.zip
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="rebasing">Rebasing</h3>

<p><strong>an advanced example</strong></p>

<p>Now <code>git show-branch master server client</code> shows like this:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">&lt;-- commit0 &lt;-- commit1 &lt;-- commit2                 master
</span><span class="line">                  <span class="se">\</span>
</span><span class="line">                   <span class="se">\-</span>- commit3 &lt;-- commit4          server
</span><span class="line">                          <span class="se">\</span>
</span><span class="line">                           <span class="se">\-</span>- commit5 &lt;-- commit6  client
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>What does <code>git rebase --onto master server client</code> do?</p>

<ol>
  <li>Checkout <em>client</em> branch</li>
  <li>Figure out the patches from the common ancestor of <em>server</em> and <em>client</em> (commits of <code>git log server..client</code>)</li>
  <li>Replay the patches onto <em>master</em></li>
</ol>

<p>Run <code>git show-branch master server client</code> again:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">                        master                  client
</span><span class="line">                           |                       |
</span><span class="line">&lt;-- commit0 &lt;-- commit1 &lt;-- commit2 &lt;-- commit5 &lt;-- commit6
</span><span class="line">              <span class="se">\</span>
</span><span class="line">               <span class="se">\-</span>- commit3 &lt;-- commit4
</span><span class="line">                                  |
</span><span class="line">                                server
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="merge-base">Merge Base</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git merge-base master <span class="nb">test</span>
</span><span class="line">da07c4b40491581a0d6f877373a5cbeb1ea8c800
</span><span class="line">
</span><span class="line"><span class="nv">$ </span>git show <span class="sb">`</span>git merge-base master <span class="nb">test</span><span class="sb">`</span>
</span><span class="line">commit da07c4b40491581a0d6f877373a5cbeb1ea8c800
</span><span class="line">Author: wendi &lt;ifyouseewendy@gmail.com&gt;
</span><span class="line">Date:   Fri Dec 19 12:56:08 2014 +0800
</span><span class="line">
</span><span class="line">    Add README
</span><span class="line">
</span><span class="line">diff --git a/README b/README
</span><span class="line">new file mode 100644
</span><span class="line">index 0000000..e69de29
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="merge-stage">Merge Stage</h3>

<p>When merging, one parent will be <strong>HEAD</strong>, and the other will be the tip of the other branch, which is stored temporarily in <strong>MERGE_HEAD</strong>.</p>

<p>During the merge, the index holds three versions of each file. Each of these three ‚Äúfile stages‚Äù represents a different version of the file:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git show :1:file.txt <span class="c"># the file in a common ancestor of both branches.</span>
</span><span class="line"><span class="nv">$ </span>git show :2:file.txt <span class="c"># the version from HEAD.</span>
</span><span class="line"><span class="nv">$ </span>git show :3:file.txt <span class="c"># the version from MERGE_HEAD.</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Some special diff options allow diffing the working directory against any of these stages:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git diff -1 file.txt <span class="c"># diff against stage 1</span>
</span><span class="line"><span class="nv">$ </span>git diff --base file.txt <span class="c"># same as the above</span>
</span><span class="line"><span class="nv">$ </span>git diff -2 file.txt <span class="c"># diff against stage 2</span>
</span><span class="line"><span class="nv">$ </span>git diff --ours file.txt <span class="c"># same as the above</span>
</span><span class="line"><span class="nv">$ </span>git diff -3 file.txt <span class="c"># diff against stage 3</span>
</span><span class="line"><span class="nv">$ </span>git diff --theirs file.txt <span class="c"># same as the above.</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="ancestry-references">Ancestry References</h3>

<ul>
  <li>^&lt;n&gt; select the nth <em>parent</em> of the commit (relevant in merges).</li>
  <li>~&lt;n&gt; select the nth <em>ancestor</em> commit, always following the first parent.</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">G   H   I   J
</span><span class="line"> <span class="se">\ </span>/     <span class="se">\ </span>/
</span><span class="line">  D   E   F
</span><span class="line">   <span class="se">\ </span> |  / <span class="se">\</span>
</span><span class="line">    <span class="se">\ </span>| /   |
</span><span class="line">     <span class="se">\|</span>/    |
</span><span class="line">      B     C
</span><span class="line">       <span class="se">\ </span>  /
</span><span class="line">        <span class="se">\ </span>/
</span><span class="line">         A
</span><span class="line"><span class="nv">A</span> <span class="o">=</span>      <span class="o">=</span> A^0
</span><span class="line"><span class="nv">B</span> <span class="o">=</span> A^   <span class="o">=</span> A^1     <span class="o">=</span> A~1
</span><span class="line"><span class="nv">C</span> <span class="o">=</span> A^2  <span class="o">=</span> A^2
</span><span class="line"><span class="nv">D</span> <span class="o">=</span> A^^  <span class="o">=</span> A^1^1   <span class="o">=</span> A~2
</span><span class="line"><span class="nv">E</span> <span class="o">=</span> B^2  <span class="o">=</span> A^^2
</span><span class="line"><span class="nv">F</span> <span class="o">=</span> B^3  <span class="o">=</span> A^^3
</span><span class="line"><span class="nv">G</span> <span class="o">=</span> A^^^ <span class="o">=</span> A^1^1^1 <span class="o">=</span> A~3
</span><span class="line"><span class="nv">H</span> <span class="o">=</span> D^2  <span class="o">=</span> B^^2    <span class="o">=</span> A^^^2  <span class="o">=</span> A~2^2
</span><span class="line"><span class="nv">I</span> <span class="o">=</span> F^   <span class="o">=</span> B^3^    <span class="o">=</span> A^^3^
</span><span class="line"><span class="nv">J</span> <span class="o">=</span> F^2  <span class="o">=</span> B^3^2   <span class="o">=</span> A^^3^2
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>recorded in <a href="http://schacon.github.com/git/git-rev-parse">git-rev-parse(1)</a></p>

<h3 id="commit-ranges">Commit Ranges</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="c"># reachable from one commit but aren‚Äôt reachable from another.</span>
</span><span class="line"><span class="nv">$ </span>git log ref1..ref2
</span><span class="line"><span class="nv">$ </span>git log ^ref1 ref2
</span><span class="line"><span class="nv">$ </span>git log ref2 --not ref1
</span><span class="line">
</span><span class="line"><span class="c"># reachable by either of two references but not by both of them.</span>
</span><span class="line"><span class="nv">$ </span>git log master...experiment
</span><span class="line">
</span><span class="line"><span class="nv">$ </span>git log --left-right master...experiment
</span><span class="line">&lt; F
</span><span class="line">&lt; E
</span><span class="line">&gt; D
</span><span class="line">&gt; C
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="log">Log</h3>

<h4 id="summarize-or-get-a-quick-changelog">Summarize or Get a Quick Changelog</h4>

<p>Use <code>git shortlog</code></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git shortlog --no-merges master --not v1.0.1
</span><span class="line">Chris Wanstrath <span class="o">(</span>8<span class="o">)</span>:
</span><span class="line">      Add support <span class="k">for </span>annotated tags to Grit::Tag
</span><span class="line">      Add packed-refs annotated tag support.
</span><span class="line">      Add Grit::Commit#to_patch
</span><span class="line">      Update version and History.txt
</span><span class="line">      Remove stray ‚Äòputs‚Äò
</span><span class="line">      Make ls_tree ignore nils
</span><span class="line">Tom Preston-Werner <span class="o">(</span>4<span class="o">)</span>:
</span><span class="line">      fix dates in <span class="nb">history</span>
</span><span class="line"><span class="nb">      </span>dynamic version method
</span><span class="line">      Version bump to 1.0.2
</span><span class="line">      Regenerated gemspec <span class="k">for </span>version 1.0.2
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="stash">Stash</h3>

<h4 id="reapply-the-staged-changes">Reapply the Staged Changes</h4>

<p>Use <code>git stash apply --index stash@{n}</code></p>

<p>You have stashed changes below,</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">On branch master
</span><span class="line">Changes to be committed:
</span><span class="line">  <span class="o">(</span>use <span class="s2">&quot;git reset HEAD &lt;file&gt;...&quot;</span> to unstage<span class="o">)</span>
</span><span class="line">
</span><span class="line">        modified:   a.rb
</span><span class="line">
</span><span class="line">Changes not staged <span class="k">for </span>commit:
</span><span class="line">  <span class="o">(</span>use <span class="s2">&quot;git add &lt;file&gt;...&quot;</span> to update what will be committed<span class="o">)</span>
</span><span class="line">  <span class="o">(</span>use <span class="s2">&quot;git checkout -- &lt;file&gt;...&quot;</span> to discard changes in working directory<span class="o">)</span>
</span><span class="line">
</span><span class="line">        modified:   todo
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>After checking out to other branch and back, you wanna apply the changes stashed.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git stash apply stash@<span class="o">{</span>0<span class="o">}</span>
</span><span class="line">
</span><span class="line">On branch master
</span><span class="line">Changes not staged <span class="k">for </span>commit:
</span><span class="line">  <span class="o">(</span>use <span class="s2">&quot;git add &lt;file&gt;...&quot;</span> to update what will be committed<span class="o">)</span>
</span><span class="line">  <span class="o">(</span>use <span class="s2">&quot;git checkout -- &lt;file&gt;...&quot;</span> to discard changes in working directory<span class="o">)</span>
</span><span class="line">
</span><span class="line">        modified:   a.rb
</span><span class="line">        modified:   todo
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>So, How to reapply the staged changes?</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git stash apply --index stash@<span class="o">{</span>0<span class="o">}</span>
</span><span class="line">
</span><span class="line">On branch master
</span><span class="line">Changes to be committed:
</span><span class="line">  <span class="o">(</span>use <span class="s2">&quot;git reset HEAD &lt;file&gt;...&quot;</span> to unstage<span class="o">)</span>
</span><span class="line">
</span><span class="line">        modified:   a.rb
</span><span class="line">
</span><span class="line">Changes not staged <span class="k">for </span>commit:
</span><span class="line">  <span class="o">(</span>use <span class="s2">&quot;git add &lt;file&gt;...&quot;</span> to update what will be committed<span class="o">)</span>
</span><span class="line">  <span class="o">(</span>use <span class="s2">&quot;git checkout -- &lt;file&gt;...&quot;</span> to discard changes in working directory<span class="o">)</span>
</span><span class="line">
</span><span class="line">        modified:   todo
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h4 id="create-a-branch-from-stash">Create a Branch from Stash</h4>

<p>Use <code>git stash branch {branch_name}</code>, which creates a new branch, checks out the commit you were on when you stashed your work, reapplies your work there, and then drops the stash if it applies successfully.</p>

<h3 id="create-new-empty-branches">Create New Empty Branches</h3>

<p>Use <strong>symobolic-ref</strong>. A symbolic ref is a regular file that stores a string that begins with ref: refs/. For example, your .git/HEAD is a regular file whose contents is ref: refs/heads/master.</p>

<blockquote>
  <p>In the past, .git/HEAD was a symbolic link pointing at
       refs/heads/master. When we wanted to switch to another branch, we did
       ln -sf refs/heads/newbranch .git/HEAD, and when we wanted to find out
       which branch we are on, we did readlink .git/HEAD. But symbolic links
       are not entirely portable, so they are now deprecated and symbolic refs
       (as described above) are used by default.</p>
</blockquote>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git symbolic-ref HEAD refs/heads/newbranch
</span><span class="line">  <span class="c"># no branch is created,</span>
</span><span class="line">  <span class="c"># and all files are deleted to index.</span>
</span><span class="line"><span class="nv">$ </span>rm .git/index
</span><span class="line">git clean -fdx
</span><span class="line">&lt;<span class="k">do </span>work&gt;
</span><span class="line">git add your files
</span><span class="line">git commit -m <span class="s1">&#39;Initial commit&#39;</span>
</span><span class="line">  <span class="c"># branch &#39;newbranch&#39; is created.</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="filter-branch">Filter Branch</h3>

<h4 id="removing-a-file-from-every-commit">Removing a File from Every Commit</h4>

<p>The <code>--tree-filter</code> option runs the specified command after each checkout of the project and then recommits the results.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git filter-branch --tree-filter ‚Äôrm -f passwords.txt‚Äô HEAD
</span><span class="line">Rewrite 6b9b3cf04e7c5686a9cb838c3f36a8cb6a0fc2bd <span class="o">(</span>21/21<span class="o">)</span>
</span><span class="line">Ref ‚Äôrefs/heads/master‚Äô was rewritten
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h4 id="making-a-subdirectory-the-new-root">Making a Subdirectory the New Root</h4>

<p>Use <code>--subdirectory-filter</code> option.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git filter-branch --subdirectory-filter trunk HEAD
</span><span class="line">Rewrite 856f0bf61e41a27326cdae8f09fe708d679f596f <span class="o">(</span>12/12<span class="o">)</span>
</span><span class="line">Ref ‚Äôrefs/heads/master‚Äô was rewritten
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h4 id="changing-e-mail-addresses-globally">Changing E-Mail Addresses Globally</h4>

<p>Use <code>--commit-filter</code> option.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git filter-branch --commit-filter ‚Äô
</span><span class="line">        <span class="k">if</span> <span class="o">[</span> <span class="s2">&quot;$GIT_AUTHOR_EMAIL&quot;</span> <span class="o">=</span> <span class="s2">&quot;schacon@localhost&quot;</span> <span class="o">]</span>;
</span><span class="line">        <span class="k">then</span>
</span><span class="line"><span class="k">                </span><span class="nv">GIT_AUTHOR_NAME</span><span class="o">=</span><span class="s2">&quot;Scott Chacon&quot;</span>;
</span><span class="line">                <span class="nv">GIT_AUTHOR_EMAIL</span><span class="o">=</span><span class="s2">&quot;schacon@example.com&quot;</span>;
</span><span class="line">                git commit-tree <span class="s2">&quot;$@&quot;</span>;
</span><span class="line">        <span class="k">else</span>
</span><span class="line"><span class="k">        fi</span>‚Äô HEAD
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h4 id="realworld-example">Realworld Example</h4>

<p>Check this post, <a href="http://blog.ifyouseewendy.com/blog/2014/12/25/git-filter-branch-in-practice/">Git Filter Branch in Practice</a></p>

<h3 id="blame">Blame</h3>

<p>If you pass <code>-C</code> to git blame, Git analyzes the file you‚Äôre annotating and tries to figure out where snippets of code within it originally came from if they were copied from elsewhere.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git blame -C -L 141,153 GITPackUpload.m
</span><span class="line">f344f58d GITServerHandler.m <span class="o">(</span>Scott 2009-01-04 141<span class="o">)</span>
</span><span class="line">f344f58d GITServerHandler.m <span class="o">(</span>Scott 2009-01-04 142<span class="o">)</span> - <span class="o">(</span>void<span class="o">)</span> gatherObjectShasFromC
</span><span class="line">f344f58d GITServerHandler.m <span class="o">(</span>Scott 2009-01-04 143<span class="o">)</span> <span class="o">{</span>
</span><span class="line">70befddd GITPackUpload.m    <span class="o">(</span>Scott 2009-03-22 144<span class="o">)</span>     //NSLog<span class="o">(</span>@<span class="err">&quot;</span>GATHER COMMI
</span><span class="line">ad11ac80 GITPackUpload.m    <span class="o">(</span>Scott 2009-03-22 144<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="bisect">Bisect</h3>

<p>First you run <code>git bisect start</code> to get things going, and then you use <code>git bisect bad</code> to tell the system that the current commit you‚Äôre on is broken. Then, you must tell bisect when the last known good state was, using <code>git bisect good [good commit]</code>.</p>

<h4 id="auto-check-by-script">Auto Check By Script</h4>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git bisect run <span class="nb">test</span>-error.sh
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Doing so automatically runs <code>test-error.sh</code> on each checked-out commit until Git finds the first broken commit. You can also run something like make or make tests or whatever you have that runs automated tests for you.</p>

<h3 id="submodules">Submodules</h3>

<h4 id="maintain-a-repo-which-contains-a-submodule">Maintain a repo which contains a submodule</h4>

<blockquote>
  <p>Add a submodule into your existing git repo.</p>
</blockquote>

<p>Add a submodule.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git submodule add git://github.com/chneukirchen/rack.git rack
</span><span class="line">
</span><span class="line"><span class="nv">$ </span>git status
</span><span class="line"><span class="c"># On branch master</span>
</span><span class="line"><span class="c"># Changes to be committed:</span>
</span><span class="line"><span class="c"># # # # #</span>
</span><span class="line"><span class="o">(</span>use <span class="s2">&quot;git reset HEAD &lt;file&gt;...&quot;</span> to unstage<span class="o">)</span>
</span><span class="line">   new file:   .gitmodules
</span><span class="line">   new file:   rack
</span><span class="line">
</span><span class="line"><span class="nv">$ </span>git commit -m <span class="s1">&#39;Add rack submodule&#39;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>As <code>.git/config</code> and <code>.gitmodules</code> have been registered, when you want to update the submodule, just enter into the submodule dir and do git opertations.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span><span class="nb">cd </span>rack
</span><span class="line"><span class="nv">$ </span>touch aa <span class="o">&amp;&amp;</span> git add . <span class="o">&amp;&amp;</span> git commit -m <span class="s1">&#39;Add aa&#39;</span>
</span><span class="line"><span class="o">[</span>master 060998f<span class="o">]</span> Add aa
</span><span class="line"> 1 file changed, 0 insertions<span class="o">(</span>+<span class="o">)</span>, 0 deletions<span class="o">(</span>-<span class="o">)</span>
</span><span class="line"> create mode 100644 aa
</span><span class="line"><span class="nv">$ </span>git push
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>When you make changes and commit in that subdirectory, the superproject notices that the <em>HEAD</em> there has changed and records the exact commit you‚Äôre currently working off of. So, update your superproject from time to time with a pointer to the latest commit in that subproject.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span><span class="nb">cd</span> ..
</span><span class="line"><span class="nv">$ </span>git status
</span><span class="line">On branch master
</span><span class="line">Changes not staged <span class="k">for </span>commit:
</span><span class="line">  <span class="o">(</span>use <span class="s2">&quot;git add &lt;file&gt;...&quot;</span> to update what will be committed<span class="o">)</span>
</span><span class="line">  <span class="o">(</span>use <span class="s2">&quot;git checkout -- &lt;file&gt;...&quot;</span> to discard changes in working directory<span class="o">)</span>
</span><span class="line">
</span><span class="line">        modified:   rack <span class="o">(</span>new commits<span class="o">)</span>
</span><span class="line"><span class="nv">$ </span>git commit -am <span class="s1">&#39;Update rack&#39;</span>
</span><span class="line"><span class="nv">$ </span>git push
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h4 id="maintain-a-cloned-repo-which-contains-a-submodule">Maintain a cloned repo which contains a submodule</h4>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git clone git://github.com/schacon/myproject.git
</span><span class="line"><span class="nv">$ </span><span class="nb">cd </span>myproject/rack
</span><span class="line"><span class="nv">$ </span>ls
</span><span class="line"><span class="c"># empty</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Setup with two commands:</p>

<ol>
  <li><code>git submodule init</code>. Initialize your local configurtaion (<code>.gitmodules</code> to  <code>.git/config</code>)</li>
  <li><code>git submodule update</code>. Fetch all the data from that project and check out the appropriate commit listed in your superproject.</li>
</ol>

<h4 id="a-demo-workflow">A Demo Workflow</h4>

<p>Create the submodules:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>mkdir ~/git
</span><span class="line"><span class="nv">$ </span><span class="nb">cd</span> ~/git
</span><span class="line"><span class="nv">$ </span><span class="k">for </span>i in a b c d
</span><span class="line"><span class="k">do</span>
</span><span class="line"><span class="k">    </span>mkdir <span class="nv">$i</span>
</span><span class="line">    <span class="nb">cd</span> <span class="nv">$i</span>
</span><span class="line">    git init
</span><span class="line">    <span class="nb">echo</span> <span class="s2">&quot;module $i&quot;</span> &gt; <span class="nv">$i</span>.txt
</span><span class="line">    git add <span class="nv">$i</span>.txt
</span><span class="line">    git commit -m <span class="s2">&quot;Initial commit, submodule $i&quot;</span>
</span><span class="line">    <span class="nb">cd</span> ..
</span><span class="line"><span class="k">done</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Create the superproject and add all the submodules:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>mkdir super
</span><span class="line"><span class="nv">$ </span><span class="nb">cd </span>super
</span><span class="line"><span class="nv">$ </span>git init
</span><span class="line"><span class="nv">$ </span><span class="k">for </span>i in a b c d
</span><span class="line"><span class="k">do</span>
</span><span class="line"><span class="k">    </span>git submodule add ~/git/<span class="nv">$i</span>
</span><span class="line"><span class="k">done</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>See what files git-submodule created:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>ls -a
</span><span class="line">.  ..  .git  .gitmodules  a  b  c  d
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The <code>git-submodule add</code> command does a couple of things:</p>

<ul>
  <li>It clones the submodule under the current directory and by default checks out the master branch.</li>
  <li>It adds the submodule‚Äôs clone path to the gitmodules file and adds this file to the index, ready to be committed.</li>
  <li>It adds the submodule‚Äôs current commit ID to the index, ready to be committed.</li>
</ul>

<p>Commit the superproject:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git commit -m <span class="s2">&quot;Add submodules a, b, c and d.&quot;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Clone the superproject:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span><span class="nb">cd</span> ..
</span><span class="line"><span class="nv">$ </span>git clone super cloned
</span><span class="line"><span class="nv">$ </span><span class="nb">cd </span>cloned
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Check submodule status:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git submodule status
</span><span class="line">-d266b9873ad50488163457f025db7cdd9683d88b a
</span><span class="line">-e81d457da15309b4fef4249aba9b50187999670d b
</span><span class="line">-c1536a972b9affea0f16e0680ba87332dc059146 c
</span><span class="line">-d96249ff5d57de5de093e6baff9e0aafa5276a74 d
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Register the submodule into <code>.git/config</code>:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git submodule init
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Clone the submodules and check out the commits specified in the superproject:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git submodule update
</span><span class="line"><span class="nv">$ </span><span class="nb">cd </span>a
</span><span class="line"><span class="nv">$ </span>ls -a
</span><span class="line">.  ..  .git  a.txt
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>One major difference between <code>git-submodule update</code> and <code>git-submodule add</code> is that git-submodule update checks out a specific commit, rather than the tip of a branch. It‚Äôs like checking out a tag: <strong>the head is detached</strong>, so you‚Äôre not working on a branch. </p>

<p>A detached head, means the <em>HEAD</em> file points directly to a commit, not to a symbolic reference.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git branch
</span><span class="line">* <span class="o">(</span>no branch<span class="o">)</span>
</span><span class="line">master
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Check out or create a new branch:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git checkout master
</span></code></pre></td></tr></table></div></figure></notextile></div>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git checkout -b fix-up
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Do work and commit:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span><span class="nb">echo</span> <span class="s2">&quot;adding a line again&quot;</span> &gt;&gt; a.txt
</span><span class="line"><span class="nv">$ </span>git commit -a -m <span class="s2">&quot;Updated the submodule from within the superproject.&quot;</span>
</span><span class="line"><span class="nv">$ </span>git push
</span><span class="line"><span class="nv">$ </span><span class="nb">cd</span> ..
</span><span class="line"><span class="nv">$ </span>git diff
</span><span class="line">diff --git a/a b/a
</span><span class="line">index d266b98..261dfac 160000
</span><span class="line">--- a/a
</span><span class="line">+++ b/a
</span><span class="line">@@ -1 +1 @@
</span><span class="line">-Subproject commit d266b9873ad50488163457f025db7cdd9683d88b
</span><span class="line">+Subproject commit 261dfac35cb99d380eb966e102c1197139f7fa24
</span><span class="line"><span class="nv">$ </span>git add a
</span><span class="line"><span class="nv">$ </span>git commit -m <span class="s2">&quot;Updated submodule a.&quot;</span>
</span><span class="line"><span class="nv">$ </span>git push
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h4 id="cautions">Cautions</h4>

<p><em>Always publish the submodule change before publishing the change to the superproject that references it. If you forget to publish the submodule change, others won‚Äôt be able to clone the repository:</em></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span><span class="nb">cd</span> ~/git/super/a
</span><span class="line"><span class="nv">$ </span><span class="nb">echo </span>i added another line to this file &gt;&gt; a.txt
</span><span class="line"><span class="nv">$ </span>git commit -a -m <span class="s2">&quot;doing it wrong this time&quot;</span>
</span><span class="line"><span class="nv">$ </span><span class="nb">cd</span> ..
</span><span class="line"><span class="nv">$ </span>git add a
</span><span class="line"><span class="nv">$ </span>git commit -m <span class="s2">&quot;Updated submodule a again.&quot;</span>
</span><span class="line"><span class="nv">$ </span>git push
</span><span class="line"><span class="nv">$ </span><span class="nb">cd</span> ~/git/cloned
</span><span class="line"><span class="nv">$ </span>git pull
</span><span class="line"><span class="nv">$ </span>git submodule update
</span><span class="line">error: pathspec <span class="s1">&#39;261dfac35cb99d380eb966e102c1197139f7fa24&#39;</span> did not match any file<span class="o">(</span>s<span class="o">)</span> known to git.
</span><span class="line">Did you forget to <span class="s1">&#39;git add&#39;</span>?
</span><span class="line">Unable to checkout <span class="s1">&#39;261dfac35cb99d380eb966e102c1197139f7fa24&#39;</span> in submodule path <span class="s1">&#39;a&#39;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><em>It‚Äôs not safe to run git submodule update if you‚Äôve made and committed changes within a submodule without checking out a branch first. They will be silently overwritten</em>:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>cat a.txt
</span><span class="line">module a
</span><span class="line"><span class="nv">$ </span><span class="nb">echo </span>line added from private2 &gt;&gt; a.txt
</span><span class="line"><span class="nv">$ </span>git commit -a -m <span class="s2">&quot;line added inside private2&quot;</span>
</span><span class="line"><span class="nv">$ </span><span class="nb">cd</span> ..
</span><span class="line"><span class="nv">$ </span>git submodule update
</span><span class="line">Submodule path <span class="s1">&#39;a&#39;</span>: checked out <span class="s1">&#39;d266b9873ad50488163457f025db7cdd9683d88b&#39;</span>
</span><span class="line"><span class="nv">$ </span><span class="nb">cd </span>a
</span><span class="line"><span class="nv">$ </span>cat a.txt
</span><span class="line">module a
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="subtree-merging-a-submodule-substitution">Subtree Merging (A Submodule Substitution)</h3>

<h4 id="use-git-merge-subtree-strategy">Use git-merge Subtree Strategy</h4>

<p><strong>Add a subtree</strong></p>

<p>First, add the Rack project as a remote reference in your own project and then check it out into its own branch.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git remote add rack_remote git@github.com:schacon/rack.git
</span><span class="line"><span class="nv">$ </span>git fetch rack_remote
</span><span class="line"><span class="nv">$ </span>git checkout -b rack_branch rack_remote/master
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Now you have the root of the Rack project in your <code>rack_branch</code> branch and your own project in the <code>master</code> branch.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>ls
</span><span class="line">AUTHORS        KNOWN-ISSUES   Rakefile
</span><span class="line">COPYING        README         bin
</span><span class="line"><span class="nv">$ </span>git checkout master
</span><span class="line">Switched to branch <span class="s2">&quot;master&quot;</span>
</span><span class="line"><span class="nv">$ </span>ls
</span><span class="line">README
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Use <code>git read-tree</code> to read the root tree of one branch into your current staging area and working directory. You just switched back to your <code>master</code> branch, and you pull the <code>rack_branch</code> into the <em>rack</em> subdirectory of your <code>master</code> branch of your main project.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git <span class="nb">read</span>-tree --prefix<span class="o">=</span>rack/ -u rack_branch
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>When you commit, it looks like you have all the Rack files under that subdirectory ‚Äî as though you copied them in from a tarball. </p>

<p><strong>Update and merge subtree</strong></p>

<p>If the Rack project updates, you can pull in upstream changes by switching to that branch and pulling:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git checkout rack_branch
</span><span class="line"><span class="nv">$ </span>git pull
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Then, you can merge those changes back into your master branch. You can use <code>git merge -s subtree</code> and it will work fine; but Git will also merge the histories together, which you probably don‚Äôt want. To pull in the changes and prepopulate the commit message, use the <code>--squash</code> and <code>--no-commit</code> options as well as the <code>-s subtree</code> strategy option:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git checkout master
</span><span class="line"><span class="nv">$ </span>git merge --squash -s subtree --no-commit rack_branch
</span><span class="line">Squash commit -- not updating HEAD
</span><span class="line">Automatic merge went well; stopped before committing as requested
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>All the changes from your Rack project are merged in and ready to be committed locally. You can also do the opposite ‚Äî make changes in the <code>rack</code> subdirectory of your master branch and then merge them into your <code>rack_branch</code> branch later to submit them to the maintainers or push them upstream.</p>

<p><strong>Diff a subtree</strong></p>

<p>To get a diff between what you have in your rack subdirectory and the code in your rack branch branch ‚Äî to see if you need to merge them ‚Äî you can‚Äôt use the normal diff command. Instead, you must run git diff-tree with the branch you want to compare to:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git diff-tree -p rack_branch
</span><span class="line"><span class="nv">$ </span>git diff-tree -p rack_remote/master
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h4 id="use-git-subtree">Use git-subtree</h4>

<ul>
  <li><a href="http://blogs.atlassian.com/2013/05/alternatives-to-git-submodule-git-subtree/">alternatives-to-git-submodule-git-subtree</a> by Atlassian Blog</li>
  <li><a href="https://hpc.uni.lu/blog/2014/understanding-git-subtree/">Understanding Git Subtree</a> by HPC @ Uni.lu</li>
</ul>

<h2 id="git-internals">Git Internals</h2>

<p>Git is fundamentally a <strong>content-addressable filesystem</strong> with a VCS user interface written on top of it.</p>

<ul>
  <li>Plumbing, verbs that do low-level work and were designed to be chained together UNIX style or called from scripts.</li>
  <li>Porcelain, the more user-friendly commands.</li>
</ul>

<h3 id="plumbing-objects">Plumbing Objects</h3>

<h4 id="blob-object">Blob Object</h4>

<p>Git is a content-addressable filesystem, at the core of Git is a simple key-value data store. You can insert any kind of content into it, and it will give you back a key that you can use to retrieve the content again at any time.</p>

<p><strong>Create</strong></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span><span class="nb">echo</span> <span class="s1">&#39;test content&#39;</span> | git <span class="nb">hash</span>-object -w --stdin
</span><span class="line">d670460b4b4aece5915caf5c68d12f560a9fe3e4
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The <code>-w</code> tells hash-object to store the object; otherwise, the command simply tells you what the key would be.</p>

<p><strong>Check</strong></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>find .git/objects -type f
</span><span class="line">.git/objects/d6/70460b4b4aece5915caf5c68d12f560a9fe3e4
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><strong>View</strong></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git cat-file -p d670460b4b4aece5915caf5c68d12f560a9fe3e4
</span><span class="line"><span class="nb">test </span>content
</span><span class="line">
</span><span class="line"><span class="nv">$ </span>git cat-file -t d670460b4b4aece5915caf5c68d12f560a9fe3e4
</span><span class="line">blob
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h4 id="tree-objects">Tree Objects</h4>

<p>Basically, tree objects are used to specify snapshots.</p>

<p>Tree object solves the problem of storing the filename and also allows you to store a group of files together.</p>

<p><strong>View</strong></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git cat-file -p masterÀÜ<span class="o">{</span>tree<span class="o">}</span>
</span><span class="line">100644 blob a906cb2a4a904a152e80877d4088654daad0c859    README
</span><span class="line">100644 blob 8f94139338f9404f26296befa88755fc2598c289    Rakefile
</span><span class="line">040000 tree 99f1a6d12cb4b6f19c8655fca46c3ecf317074e0    lib
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><strong>Create</strong>.</p>

<p>Git normally creates a tree by taking the state of your staging area or index and writing a tree object from it. </p>

<ul>
  <li>
    <p>Use <code>update-index</code> to create an index.</p>

    <ul>
      <li><code>--add</code>, because the file doesn‚Äôt yet exist in your staging area.</li>
      <li><code>--cacheinfo</code>, because the file you‚Äôre adding isn‚Äôt in your directory but is in your database.</li>
      <li><code>100644</code>, which means it‚Äôs a normal file. Other options are <code>100755</code>, which means it‚Äôs an executable file; and <code>120000</code>, which specifies a symbolic link.</li>
    </ul>
  </li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git update-index --add --cacheinfo 100644 <span class="se">\</span>
</span><span class="line">  83baae61804e65cc73a7201a7252750c76066a30 test.tx
</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>Use <code>read-tree</code> to read an existing tree into your staging area as a subtree by using the <code>--prefix</code> option.</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git cat-file -p d8329fc1cc938780ffdd9f94e0d364e0ea74f579
</span><span class="line">100644 blob 83baae61804e65cc73a7201a7252750c76066a30    test.txt
</span><span class="line">
</span><span class="line"><span class="nv">$ </span>git <span class="nb">read</span>-tree --prefix<span class="o">=</span>bak d8329fc1cc938780ffdd9f94e0d364e0ea74f579
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Use the <code>write-tree</code> command to write the staging area out to a tree object. No <code>-w</code> option is needed ‚Äî calling <code>write-tree</code> automatically creates a tree object from the state of the index if that tree doesn‚Äôt yet exist:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git write-tree
</span><span class="line">d8329fc1cc938780ffdd9f94e0d364e0ea74f579
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h4 id="commit-objects">Commit Objects</h4>

<p>You have three trees that specify the different snapshots of your project that you want to track, but the earlier problem remains: you must remember all three SHA‚Äì1 values in order to recall the snapshots. You also don‚Äôt have any information about who saved the snapshots, when they were saved, or why they were saved. This is the basic information that the commit object stores for you.</p>

<p><strong>Create</strong></p>

<p>Use <code>commit-tree</code>.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span><span class="nb">echo</span> ‚Äôfirst commit‚Äô | git commit-tree d8329f
</span><span class="line">fdf4fc3344e67ab068f836878b6c4951e3b15f3d
</span><span class="line">
</span><span class="line"><span class="nv">$ </span><span class="nb">echo</span> ‚Äôsecond commit‚Äô | git commit-tree 0155eb -p fdf4fc3
</span><span class="line">cac0cab538b970a37ea1e769cbbde608743bc96d
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><strong>View</strong></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git cat-file -p fdf4fc3
</span><span class="line">tree d8329fc1cc938780ffdd9f94e0d364e0ea74f579
</span><span class="line">author Scott Chacon &lt;schacon@gmail.com&gt; 1243040974 -0700
</span><span class="line">committer Scott Chacon &lt;schacon@gmail.com&gt; 1243040974 -0700
</span><span class="line">
</span><span class="line">first commit
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h4 id="object-storage">Object Storage</h4>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>git_object_storage.rb</span><a href="https://gist.github.com/ifyouseewendy/ec7a4d8df55a2de70af1">link</a></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
</pre></td><td class="code"><pre><code class="rb"><span class="line"><span class="nb">require</span> <span class="s1">&#39;digest/sha1&#39;</span>
</span><span class="line"><span class="nb">require</span> <span class="s1">&#39;zlib&#39;</span>
</span><span class="line"><span class="nb">require</span> <span class="s1">&#39;fileutils&#39;</span>
</span><span class="line">
</span><span class="line"><span class="c1"># put_raw_object(&quot;what is up, doc?&quot;, &#39;blob&#39;)</span>
</span><span class="line"><span class="k">def</span> <span class="nf">put_raw_object</span><span class="p">(</span><span class="n">content</span><span class="p">,</span> <span class="n">type</span><span class="p">)</span>
</span><span class="line">  <span class="c1"># Generate SHA-1</span>
</span><span class="line">  <span class="n">header</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">#{</span><span class="n">type</span><span class="si">}</span><span class="s2"> </span><span class="si">#{</span><span class="n">content</span><span class="o">.</span><span class="n">length</span><span class="si">}</span><span class="se">\0</span><span class="s2">&quot;</span>   <span class="c1"># =&gt; &quot;blob 16\000&quot;</span>
</span><span class="line">  <span class="n">store</span> <span class="o">=</span> <span class="n">header</span> <span class="o">+</span> <span class="n">content</span>              <span class="c1"># =&gt; &quot;blob 16\000what is up, doc?&quot;</span>
</span><span class="line">  <span class="n">sha1</span> <span class="o">=</span> <span class="ss">Digest</span><span class="p">:</span><span class="ss">:SHA1</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">(</span><span class="n">store</span><span class="p">)</span>  <span class="c1"># =&gt; &quot;bd9dbf5aae1a3862dd1526723246b20206e5fc37&quot;</span>
</span><span class="line">
</span><span class="line">  <span class="c1"># p sha1</span>
</span><span class="line">
</span><span class="line">  <span class="c1"># Compress with Zlib</span>
</span><span class="line">  <span class="n">zlib_content</span> <span class="o">=</span> <span class="ss">Zlib</span><span class="p">:</span><span class="ss">:Deflate</span><span class="o">.</span><span class="n">deflate</span><span class="p">(</span><span class="n">store</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">  <span class="c1"># Write to disk</span>
</span><span class="line">  <span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;.git/objects/&#39;</span> <span class="o">+</span> <span class="n">sha1</span><span class="o">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="o">]</span> <span class="o">+</span> <span class="s1">&#39;/&#39;</span> <span class="o">+</span> <span class="n">sha1</span><span class="o">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">38</span><span class="o">]</span> <span class="c1"># =&gt; &quot;.git/objects/bd/9dbf5aae1a3862dd1526723246b20206e5fc37&quot;</span>
</span><span class="line">  <span class="no">FileUtils</span><span class="o">.</span><span class="n">mkdir_p</span><span class="p">(</span><span class="no">File</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>                 <span class="c1"># =&gt; &quot;.git/objects/bd&quot;</span>
</span><span class="line">  <span class="no">File</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">){</span><span class="o">|</span><span class="n">f</span><span class="o">|</span> <span class="n">f</span><span class="o">.</span><span class="n">write</span> <span class="n">zlib_content</span> <span class="p">}</span>
</span><span class="line"><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><strong><em>What Git does when you run the git add and git commit commands?</em></strong></p>

<ol>
  <li>stores blobs for the files that have changed</li>
  <li>updates the index</li>
  <li>writes out trees</li>
  <li>writes commit objects that reference the top-level trees and the commits that came immediately before them.</li>
</ol>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>find .git/objects -type f
</span><span class="line">.git/objects/01/55eb4229851634a0f03eb265b69f5a2d56f341 <span class="c"># tree 2</span>
</span><span class="line">.git/objects/1a/410efbd13591db07496601ebc7a059dd55cfe9 <span class="c"># commit 3</span>
</span><span class="line">.git/objects/1f/7a7a472abf3dd9643fd615f6da379c4acb3e3a <span class="c"># test.txt v2</span>
</span><span class="line">.git/objects/3c/4e9cd789d88d8d89c1073707c3585e41b0e614 <span class="c"># tree 3</span>
</span><span class="line">.git/objects/83/baae61804e65cc73a7201a7252750c76066a30 <span class="c"># test.txt v1</span>
</span><span class="line">.git/objects/ca/c0cab538b970a37ea1e769cbbde608743bc96d <span class="c"># commit 2</span>
</span><span class="line">.git/objects/d8/329fc1cc938780ffdd9f94e0d364e0ea74f579 <span class="c"># tree 1</span>
</span><span class="line">.git/objects/fa/49b077972391ad58037050f2a75f74e3671e92 <span class="c"># new.txt</span>
</span><span class="line">.git/objects/fd/f4fc3344e67ab068f836878b6c4951e3b15f3d <span class="c"># commit 1</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><img src="https://github.com/ifyouseewendy/ifyouseewendy.github.io/raw/source/image-repo/pro_git_figure_9_3.png" alt="figure 9.3" /></p>

<h3 id="index">Index</h3>

<p>The index is a binary file (generally kept in .git/index) containing a sorted list of path names.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git ls-files --stage
</span><span class="line">100644 63c918c667fa005ff12ad89437f2fdc80926e21c 0
</span><span class="line">100644 5529b198e8d14decbe4ad99db3f7fb632de0439d 0
</span><span class="line">100644 6ff87c4664981e4397625791c8ea3bbb5f2279a3 0
</span><span class="line">100644 a37b2152bd26be2c2289e1f57a292534a51a93c7 0
</span><span class="line">100644 fbefe9a45b00a54b58d94d06eca48b03d40a50e0 0
</span><span class="line">...
</span><span class="line">100644 2511aef8d89ab52be5ec6a5e46236b4b6bcd07ea 0
</span><span class="line">100644 2ade97b2574a9f77e7ae4002a4e07a6a38e46d07 0
</span><span class="line">100644 d5de8292e05e7c36c4b68857c1cf9855e3d2f70a 0
</span><span class="line">.gitignore
</span><span class="line">.mailmap
</span><span class="line">COPYING
</span><span class="line">Documentation/.gitignore
</span><span class="line">Documentation/Makefile
</span><span class="line">xdiff/xtypes.h
</span><span class="line">xdiff/xutils.c
</span><span class="line">xdiff/xutils.h
</span></code></pre></td></tr></table></div></figure></notextile></div>

<ol>
  <li>
    <p>The index contains all the information necessary to generate a single (uniquely determined) tree object.</p>
  </li>
  <li>
    <p>The index enables fast comparisons between the tree object it defines and the working tree.</p>
  </li>
  <li>
    <p>It can efficiently represent information about merge conflicts between different tree objects.</p>
  </li>
</ol>

<h3 id="packfile">Packfile</h3>

<ul>
  <li><strong>Loose objects</strong> are the simpler format. It is simply the compressed data (snapshots) stored in a single file on disk.</li>
  <li><strong>Packed Objects</strong>. In order to save that space, Git utilizes the packfile. This is a format where Git will only save the part that has changed in the second file, with a pointer to the file it is similar to. Triggered by
    <ul>
      <li>run the <code>git gc</code> command manually</li>
      <li>push to a remote server</li>
    </ul>
  </li>
</ul>

<p>When Git packs objects, it looks for files that are named and sized similarly, and stores just the deltas from one version of the file to the next.</p>

<p>What is also interesting is that the second version of the file is the one that is stored intact, whereas the original version is stored as a delta ‚Äî this is because you‚Äôre most likely to need faster access to the most recent version of the file.</p>

<h3 id="the-refspec">The Refspec</h3>

<p>Recorded in <code>.git/config</code>.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="o">[</span>remote <span class="s2">&quot;origin&quot;</span><span class="o">]</span>
</span><span class="line">    <span class="nv">url</span> <span class="o">=</span> git@github.com:schacon/simplegit-progit.git
</span><span class="line">    <span class="nv">fetch</span> <span class="o">=</span> +refs/heads/*:refs/remotes/origin/*
</span><span class="line">    <span class="nv">push</span> <span class="o">=</span> refs/heads/master:refs/heads/master
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The format of the refspec is an optional <code>+</code>, followed by <code>&lt;src&gt;:&lt;dst&gt;</code>.</p>

<ul>
  <li><code>+</code> tells Git to update the reference even if it isn‚Äôt a fast-forward.</li>
  <li><code>&lt;src&gt;</code> is the pattern for references on the remote side.</li>
  <li><code>&lt;dst&gt;</code> is where those references will be written locally. </li>
</ul>

<h4 id="fetching">fetching</h4>

<p>If you want Git instead to pull down only the master branch each time, and not every other branch on the remote server, you can change the fetch line to</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">fetch</span> <span class="o">=</span> +refs/heads/master:refs/remotes/origin/master
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>You can also specify multiple refspecs for fetching in your configuration file.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">fetch</span> <span class="o">=</span> +refs/heads/master:refs/remotes/origin/master
</span><span class="line"><span class="nv">fetch</span> <span class="o">=</span> +refs/heads/experiment:refs/remotes/origin/experiment
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>You can use namespacing to accomplish something like that. If you have a QA team that pushes a series of branches, and you want to get the master branch and any of the QA team‚Äôs branches but nothing else, you can use a config section like this:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="o">[</span>remote <span class="s2">&quot;origin&quot;</span><span class="o">]</span>
</span><span class="line">    <span class="nv">url</span> <span class="o">=</span> git@github.com:schacon/simplegit-progit.git
</span><span class="line">    <span class="nv">fetch</span> <span class="o">=</span> +refs/heads/master:refs/remotes/origin/master
</span><span class="line">    <span class="nv">fetch</span> <span class="o">=</span> +refs/heads/qa/*:refs/remotes/origin/qa/*
</span><span class="line">
</span><span class="line">    <span class="c"># You can‚Äôt use partial globs in the pattern</span>
</span><span class="line">    <span class="c"># fetch = +refs/heads/qa*:refs/remotes/origin/qa*</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>If you want to do something one time, you can specify the refspec on the command line, too. Multiple refspecs are accepted.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git fetch origin master:refs/remotes/origin/mymaster <span class="se">\</span>
</span><span class="line">   topic:refs/remotes/origin/topic
</span><span class="line">From git@github.com:schacon/simplegit
</span><span class="line"> ! <span class="o">[</span>rejected<span class="o">]</span>        master     -&gt; origin/mymaster  <span class="o">(</span>non fast forward<span class="o">)</span>
</span><span class="line"> * <span class="o">[</span>new branch<span class="o">]</span>      topic      -&gt; origin/topic
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="data-recovery">Data Recovery</h3>

<h4 id="reflog">reflog</h4>

<p>As you‚Äôre working, Git silently records what your HEAD is every time you change it. Each time you commit or change branches, the reflog is updated. The reflog is also updated by the <code>git update-ref</code> command, which is another reason to use it instead of just writing the SHA value to your ref files.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git reflog
</span><span class="line">1a410ef HEAD@<span class="o">{</span>0<span class="o">}</span>: 1a410efbd13591db07496601ebc7a059dd55cfe9: updating HEAD
</span><span class="line">ab1afef HEAD@<span class="o">{</span>1<span class="o">}</span>: ab1afef80fac8e34258ff41fc1b867c702daa24b: updating HEAD
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>To see the same information in a much more useful way, we can run <code>git log -g</code> or <code>git log --walk-reflogs</code>, which will give you a normal log output for your reflog.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git log -g
</span><span class="line">commit 1a410efbd13591db07496601ebc7a059dd55cfe9
</span><span class="line">Reflog: HEAD@<span class="o">{</span>0<span class="o">}</span> <span class="o">(</span>Scott Chacon &lt;schacon@gmail.com&gt;<span class="o">)</span>
</span><span class="line">Reflog message: updating HEAD
</span><span class="line">Author: Scott Chacon &lt;schacon@gmail.com&gt;
</span><span class="line">Date:   Fri May 22 18:22:37 2009 -0700
</span><span class="line">
</span><span class="line">    third commit
</span><span class="line">
</span><span class="line">commit ab1afef80fac8e34258ff41fc1b867c702daa24b
</span><span class="line">Reflog: HEAD@<span class="o">{</span>1<span class="o">}</span> <span class="o">(</span>Scott Chacon &lt;schacon@gmail.com&gt;<span class="o">)</span>
</span><span class="line">Reflog message: updating HEAD
</span><span class="line">Author: Scott Chacon &lt;schacon@gmail.com&gt;
</span><span class="line">Date:   Fri May 22 18:15:24 2009 -0700
</span><span class="line">
</span><span class="line">    modified repo a bit
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h4 id="fsck">fsck</h4>

<blockquote>
  <p>File System Consistency Check</p>
</blockquote>

<p>Suppose your loss was for some reason not in the reflog, you can use the <code>git fsck</code> utility, which checks your database for integrity. If you run it with the <code>--full</code> option, it shows you all objects that aren‚Äôt pointed to by another object:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git fsck --full
</span><span class="line">dangling blob d670460b4b4aece5915caf5c68d12f560a9fe3e4
</span><span class="line">dangling commit ab1afef80fac8e34258ff41fc1b867c702daa24b
</span><span class="line">dangling tree aea790b9a58f6cf6f2804eeac9f0abbe9631e4c9
</span><span class="line">dangling blob 7108f7ecb345ee9d0084193f147cdad4d2998293
</span></code></pre></td></tr></table></div></figure></notextile></div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Readable Git Log by Using Custom Commit Template]]></title>
    <link href="http://blog.ifyouseewendy.com/blog/2014/12/29/readable-git-log-by-using-custom-commit-template/"/>
    <updated>2014-12-29T15:43:39+08:00</updated>
    <id>http://blog.ifyouseewendy.com/blog/2014/12/29/readable-git-log-by-using-custom-commit-template</id>
    <content type="html"><![CDATA[<p>I was thinking of making my git logs more readable for a long time. Sometimes merge log can help to seperate a set of commits as a feature, but <strong>how can we get more info from the sequential log messages inside a set of commits?</strong></p>

<p>After doing a little research, I‚Äôve found <a href="http://programmers.stackexchange.com/questions/42110/can-you-recommend-a-good-commit-message-template-guidelines-to-enforce-in-the">rangzen‚Äôs answer</a> on Stack Exchange sounds reasonable.</p>

<blockquote>
  <p>With Add, Mod(ify), Ref(actoring), Fix, Rem(ove) and Rea(dability) then it‚Äôs easy to extract logfile.
Example :<br />
+ Add: New function to rule the world.<br />
+ Mod: Add women factor in Domination.ruleTheWorld().<br />
+ Ref: Extract empathy stuff to an abstract class.<br />
+ Fix: RUL-42 or #42 Starvation need to be initialised before Energy to avoid the nullpointer in People.<br />
+ Rem: freeSpeech is not used anymore.<br />
+ Rea: Removed old TODO and extra space in header.  </p>
</blockquote>

<p>And I want to give it a try by,</p>

<ol>
  <li>Setting <code>git config commit.template</code> to my customized commit template.</li>
  <li>Using git <code>commit-msg</code> hook to enforce the pattern, validating on commit message.</li>
</ol>

<p>Here is the details.</p>

<h2 id="customize-commit-template">Customize Commit Template</h2>

<p>Write a <code>.gitmessage</code> template.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
</pre></td><td class="code"><pre><code class=""><span class="line">
</span><span class="line"># = Rule 1, use meta operation
</span><span class="line">
</span><span class="line"># Add: new function to rule the world
</span><span class="line"># Mod: query_date logic
</span><span class="line"># Rem: user.rake is not used anymore
</span><span class="line"># Ren: hello-world to hell-world
</span><span class="line"># Fix: #1900, stupid typo
</span><span class="line"># Ref: extract to an abstract class.
</span><span class="line"># Opt: cache in get_active_table
</span><span class="line">
</span><span class="line"># = Rule 2, leave a "*" at the end to flag folding
</span><span class="line">
</span><span class="line"># Mod: query_date logic*
</span><span class="line">#
</span><span class="line"># Use chronic to guess date.
</span><span class="line">#
</span><span class="line"># Chronic.parse('may 27th', :guess =&gt; false)
</span><span class="line"># #=&gt; Sun May 27 00:00:00 PDT 2007..Mon May 28 00:00:00 PDT 2007
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Make git serve it.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git config --global commit.template ~/.gitmessage
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Now when committing, git enables the template:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git touch README <span class="o">&amp;&amp;</span> git commit
</span><span class="line">
</span><span class="line">
</span><span class="line"><span class="c"># = Rule 1, use meta operation</span>
</span><span class="line">
</span><span class="line"><span class="c"># Add: new function to rule the world</span>
</span><span class="line"><span class="c"># Mod: query_date logic</span>
</span><span class="line"><span class="c"># Rem: user.rake is not used anymore</span>
</span><span class="line"><span class="c"># Ren: hello-world to hell-world</span>
</span><span class="line"><span class="c"># Fix: #1900, stupid typo</span>
</span><span class="line"><span class="c"># Ref: extract to an abstract class.</span>
</span><span class="line"><span class="c"># Opt: cache in get_active_table</span>
</span><span class="line">
</span><span class="line"><span class="c"># = Rule 2, leave a &quot;*&quot; at the end to flag folding</span>
</span><span class="line">
</span><span class="line"><span class="c"># Mod: query_date logic*</span>
</span><span class="line"><span class="c">#</span>
</span><span class="line"><span class="c"># Use chronic to guess date.</span>
</span><span class="line"><span class="c">#</span>
</span><span class="line"><span class="c"># Chronic.parse(&#39;may 27th&#39;, :guess =&gt; false)</span>
</span><span class="line"><span class="c"># #=&gt; Sun May 27 00:00:00 PDT 2007..Mon May 28 00:00:00 PDT 2007</span>
</span><span class="line">
</span><span class="line"><span class="c"># Please enter the commit message for your changes. Lines starting</span>
</span><span class="line"><span class="c"># with &#39;#&#39; will be ignored, and an empty message aborts the commit.</span>
</span><span class="line"><span class="c"># On branch master</span>
</span><span class="line"><span class="c"># Changes to be committed:</span>
</span><span class="line"><span class="c">#	new file:   README</span>
</span><span class="line"><span class="c">#</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="validate-on-rules">Validate on Rules</h2>

<p>Write a Ruby script, naming <code>commit-msg</code> under <code>.git/hooks</code>, and make it executable.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="c1">#!/usr/bin/env ruby</span>
</span><span class="line">
</span><span class="line"><span class="c1"># Init repo</span>
</span><span class="line"><span class="nb">exit</span> <span class="mi">0</span> <span class="k">if</span> <span class="sb">`git log --oneline -1 2&gt;/dev/null`</span><span class="o">.</span><span class="n">empty?</span>
</span><span class="line">
</span><span class="line"><span class="n">message_file</span> <span class="o">=</span> <span class="no">ARGV</span><span class="o">[</span><span class="mi">0</span><span class="o">]</span>
</span><span class="line"><span class="n">lines</span> <span class="o">=</span> <span class="no">File</span><span class="o">.</span><span class="n">readlines</span><span class="p">(</span><span class="n">message_file</span><span class="p">)</span><span class="o">.</span><span class="n">reject</span><span class="p">{</span><span class="o">|</span><span class="n">l</span><span class="o">|</span> <span class="n">l</span> <span class="o">=~</span> <span class="sr">/^#/</span><span class="p">}</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="o">&amp;</span><span class="ss">:strip</span><span class="p">)</span><span class="o">.</span><span class="n">reject</span><span class="p">(</span><span class="o">&amp;</span><span class="ss">:empty?</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">subject_regex</span> <span class="o">=</span> <span class="s1">&#39;[Add|Mod|Rem|Ren|Fix|Ref|Opt]:\s\S+&#39;</span>
</span><span class="line"><span class="n">regex</span> <span class="o">=</span> <span class="n">lines</span><span class="o">.</span><span class="n">count</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="o">?</span> <span class="sr">/</span><span class="si">#{</span><span class="n">subject_regex</span><span class="si">}</span><span class="sr">\*$/</span> <span class="p">:</span> <span class="sr">/</span><span class="si">#{</span><span class="n">subject_regex</span><span class="si">}</span><span class="sr">/</span>
</span><span class="line">
</span><span class="line"><span class="k">unless</span> <span class="n">lines</span><span class="o">[</span><span class="mi">0</span><span class="o">]</span> <span class="o">=~</span> <span class="n">regex</span>
</span><span class="line">  <span class="nb">puts</span> <span class="s2">&quot;[POLICY] Your message is not formatted correctly&quot;</span>
</span><span class="line">  <span class="nb">puts</span> <span class="s2">&quot;[POLICY] Please check ~/.gitmessage.txt&quot;</span>
</span><span class="line">  <span class="nb">exit</span> <span class="mi">1</span>
</span><span class="line"><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Now committing has validations.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="c"># Rule 1</span>
</span><span class="line">
</span><span class="line"><span class="nv">$ </span>git commit -m <span class="s1">&#39;Add README&#39;</span>
</span><span class="line"><span class="o">[</span>POLICY<span class="o">]</span> Your message is not formatted correctly
</span><span class="line"><span class="o">[</span>POLICY<span class="o">]</span> Please check ~/.gitmessage
</span><span class="line">
</span><span class="line"><span class="nv">$ </span>git commit -m <span class="s1">&#39;Add: README&#39;</span>
</span><span class="line"><span class="o">[</span>master e492ec1<span class="o">]</span> Add: README
</span><span class="line"> 1 file changed, 0 insertions<span class="o">(</span>+<span class="o">)</span>, 0 deletions<span class="o">(</span>-<span class="o">)</span>
</span><span class="line"> create mode 100644 README
</span><span class="line">
</span><span class="line"><span class="c"># Rule 2</span>
</span><span class="line">
</span><span class="line"><span class="nv">$ </span>git commit -m <span class="s1">&#39;Add: README</span>
</span><span class="line"><span class="s1">quote&gt; </span>
</span><span class="line"><span class="s1">quote&gt; some content&#39;</span>
</span><span class="line"><span class="o">[</span>POLICY<span class="o">]</span> Your message is not formatted correctly
</span><span class="line"><span class="o">[</span>POLICY<span class="o">]</span> Please check ~/.gitmessage
</span><span class="line">
</span><span class="line"><span class="nv">$ </span>git commit -m <span class="s1">&#39;Add: README*</span>
</span><span class="line"><span class="s1">quote&gt; </span>
</span><span class="line"><span class="s1">quote&gt; some content&#39;</span>
</span><span class="line"><span class="o">[</span>master 5fdd0f4<span class="o">]</span> Add: README*
</span><span class="line"> 1 file changed, 0 insertions<span class="o">(</span>+<span class="o">)</span>, 0 deletions<span class="o">(</span>-<span class="o">)</span>
</span><span class="line"> create mode 100644 README
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Here is the final <code>git log --oneline</code> look,</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">* 0435fa9 2014-12-29 Ref: code smells like..teen spirit <span class="o">[</span>wendi<span class="o">]</span>
</span><span class="line">* 13423ff 2014-12-29 Fix: <span class="c">#1984 big bro 404 error* [wendi]</span>
</span><span class="line">* 0c5b9f9 2014-12-29 Add: pygments.rb to <span class="nb">enable </span>highlight* <span class="o">[</span>wendi<span class="o">]</span>
</span><span class="line">* e99d1b5 2014-12-29 Mod: heading sytle <span class="o">[</span>wendi<span class="o">]</span>
</span><span class="line">* 95576cc 2014-12-29 Ren: README.md <span class="o">[</span>wendi<span class="o">]</span>
</span><span class="line">* 2f5c632 2014-12-29 Add: README <span class="o">[</span>wendi<span class="o">]</span>
</span><span class="line">* 6673bd7 2014-12-29 Init <span class="o">[</span>wendi<span class="o">]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><strong><em>How to make self-defined hook ship with every project?</em></strong></p>

<p>Use <code>init.templatedir</code> config option.</p>

<p>Check this post, <a href="https://coderwall.com/p/jp7d5q/create-a-global-git-commit-hook">Create a global git commit hook</a> by Matt Venables.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Git Filter Branch in Practice]]></title>
    <link href="http://blog.ifyouseewendy.com/blog/2014/12/25/git-filter-branch-in-practice/"/>
    <updated>2014-12-25T20:54:49+08:00</updated>
    <id>http://blog.ifyouseewendy.com/blog/2014/12/25/git-filter-branch-in-practice</id>
    <content type="html"><![CDATA[<p>For some reasons, our company team is migrating our codebase from Github Enterprise to Gitlab. One of the annoying things we should do is to update the invalid author names and emails in our git commits. Specifically, we should</p>

<p><strong>Filter out the author emails which are not ending <code>umeng.com</code>, modify meta info of these commits by a self-defined rule, and update the inconsistent author and committer info.</strong></p>

<p>I‚Äôve used <code>git-filter-branch</code> once to do a similar but simpler job, which updated my own name and email, by using <code>env-filter</code> option in a few lines to complete.</p>

<p>Things are getting a little complicated this time. Our repo has several branches, numbers of collaborators and almost 18,000 commits. I must be careful and patient, to find a safe way before reaching the ultimate horrible ‚Äúforce update‚Äù.</p>

<h2 id="major-idea">Major Idea</h2>

<p>Use <code>git filter-branch --commit-filter</code> to update each commit‚Äôs author info.</p>

<p>Psuedo-code of updating logic</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="n">email</span> <span class="o">=</span> <span class="s2">&quot;$GIT_AUTHOR_EMAIL&quot;</span>
</span><span class="line">
</span><span class="line"><span class="k">if</span> <span class="n">email</span><span class="o">.</span><span class="n">match</span> <span class="sr">/@umeng.com/</span>
</span><span class="line">  <span class="n">commit</span><span class="o">-</span><span class="n">tree</span>
</span><span class="line"><span class="k">else</span>
</span><span class="line">  <span class="n">email</span><span class="o">.</span><span class="n">match</span> <span class="sr">/(?&lt;name&gt;*)@(?&lt;domain&gt;*).com/</span> <span class="c1"># psuedo</span>
</span><span class="line">
</span><span class="line">  <span class="n">mapping</span> <span class="o">=</span> <span class="p">{</span>
</span><span class="line">    <span class="s1">&#39;wendy&#39;</span> <span class="o">=&gt;</span> <span class="s1">&#39;wendi&#39;</span><span class="p">,</span>
</span><span class="line">    <span class="s1">&#39;ifyouseewendy&#39;</span> <span class="o">=&gt;</span> <span class="s1">&#39;wendi&#39;</span><span class="p">,</span>
</span><span class="line">    <span class="o">.</span><span class="n">.</span><span class="o">.</span>
</span><span class="line">  <span class="p">}</span>
</span><span class="line">
</span><span class="line">  <span class="k">if</span> <span class="n">mapping</span><span class="o">[</span><span class="nb">name</span><span class="o">].</span><span class="n">presents?</span>
</span><span class="line">    <span class="n">commit_email</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">#{</span><span class="n">mapping</span><span class="o">[</span><span class="nb">name</span><span class="o">]</span><span class="si">}</span><span class="s2">@umeng.com&quot;</span>
</span><span class="line">  <span class="k">else</span>
</span><span class="line">    <span class="n">commit_email</span> <span class="o">=</span> <span class="s2">&quot;umeng_</span><span class="si">#{</span><span class="nb">name</span><span class="si">}</span><span class="s2">-</span><span class="si">#{</span><span class="n">domain</span><span class="si">}</span><span class="s2">@umeng.com&quot;</span>
</span><span class="line">  <span class="k">end</span>
</span><span class="line">
</span><span class="line">  <span class="n">commit</span><span class="o">-</span><span class="n">tree</span>
</span><span class="line"><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="step-by-step">Step by Step</h2>

<p><strong>1. Checkout a test branch</strong></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>git checkout -b update_git_info
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><strong>2. Filter author emails</strong></p>

<p>Use <a href="https://gist.github.com/ifyouseewendy/9bdf7ad7173f9c78026c#file-generate_stats-rb">generate_stats.rb</a> to</p>

<ol>
  <li>Gather commits info of <em>author_name</em>, <em>author_email</em>, and <em>committer_email</em>.</li>
  <li>Run again after finishing the whole job to verify.</li>
</ol>

<p><strong>3. Prepare a mapping file</strong></p>

<p>For authors whose email domain is not <code>umeng</code>, write the mapping file under this rule:</p>

<ol>
  <li>Seperated by <code>\s</code></li>
  <li>First is the valid Umeng name</li>
  <li>Second to the end, are the names of the invalid email</li>
</ol>

<p>Sample:</p>

<p>change <code>wendy@xx.com</code> and <code>ifyouseewendy@xx.com</code> to <code>wendi@umeng.com</code>.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">wendi wendy ifyouseewendy
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><strong>4. Leverage mapping file</strong></p>

<p>Write a Ruby script to map names, used in the final script.</p>

<p><a href="https://gist.github.com/ifyouseewendy/9bdf7ad7173f9c78026c#file-update_name-rb">update_name.rb</a>, read a name to change, output the corresponding Umeng author name.</p>

<p><strong>5. Git filter-branch bash script</strong></p>

<p>Here is the final working script, <a href="https://gist.github.com/ifyouseewendy/9bdf7ad7173f9c78026c#file-git_filter_branch-sh">git_filter_branch.sh</a>. The bash email pattern matching part was tweaked based on <a href="http://stackoverflow.com/questions/14170873/bash-regex-email-matching">glenn jackman‚Äôs answer</a> on Stack Overflow.</p>

<h2 id="things-to-take-caution">Things to Take Caution</h2>

<p>When running <code>git filter-branch --commit-filter &lt;commad&gt;</code>, logic in <code>&lt;command&gt;</code> was the core part to finish my job. Remenber, <strong>DO NOT write <code>echo</code> in command part</strong> for debug use or whatever, as <code>echo</code> will interrupt the filter branch workflow.</p>

<p>Better use a seperate script when debugging. I use <a href="https://gist.github.com/ifyouseewendy/9bdf7ad7173f9c78026c#file-update_email-sh">update_email.rb</a> to develop on email pattern matching, and copy paste into the final <a href="https://gist.github.com/ifyouseewendy/9bdf7ad7173f9c78026c#file-git_filter_branch-sh">git_filter_branch.sh</a>.</p>

]]></content>
  </entry>
  
</feed>
